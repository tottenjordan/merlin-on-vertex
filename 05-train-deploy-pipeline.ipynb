{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fb7941-cf7c-4ff4-aab3-86f68879e618",
   "metadata": {},
   "source": [
    "# Train and Deploy Merlin models with Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a796242f-4f0e-454e-aba0-5eb6ba87f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip3 install --upgrade --user -q google-cloud-aiplatform\n",
    "# ! pip3 install --upgrade --user -q google-cloud-storage\n",
    "# ! pip3 install --upgrade --user -q kfp\n",
    "# ! pip3 install --upgrade --user -q google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5337f359-59e6-4bff-a1cd-3504e500c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.19\n",
      "google_cloud_pipeline_components version: 1.0.40\n",
      "aiplatform SDK version: 1.23.0\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550909fb-6604-4907-8cb9-14395fd2b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "! gcloud config set project $PROJECT_ID\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42c134e-2fef-49e9-aaa2-c33906673e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abff2a0-3022-4d0e-9423-4cc067da146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'train_pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e50ebd1-4f72-41b1-89e1-3be35d62bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2d38e-459a-4ccd-9ae8-928a86ed2474",
   "metadata": {},
   "source": [
    "# Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5c12ae-40ef-485a-aa02-c0fc116ca33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98a7ed-ec46-43b6-aad0-18e4edc040fb",
   "metadata": {},
   "source": [
    "## Build Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c8639e-d29a-4441-a315-1ce0b1c33ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/build_custom_image.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/build_custom_image.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"gcr.io/google.com/cloudsdktool/cloud-sdk:latest\",\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-build\"\n",
    "    ],\n",
    ")\n",
    "def build_custom_image(\n",
    "    project: str,\n",
    "    artifact_gcs_path: str,\n",
    "    docker_name: str,\n",
    "    app_dir_name: str,\n",
    "    custom_image_uri: str,\n",
    "    use_existing: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('custom_image_uri', str),\n",
    "]):\n",
    "    # TODO: make output Artifact for image_uri\n",
    "    \"\"\"\n",
    "    custom pipeline component to build custom image using\n",
    "    Cloud Build, the training/serving application code, and dependencies\n",
    "    defined in the Dockerfile\n",
    "    \"\"\"\n",
    "    \n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    from google.cloud.devtools import cloudbuild_v1 as cloudbuild\n",
    "    from google.protobuf.duration_pb2 import Duration\n",
    "    \n",
    "    if use_existing=='False':\n",
    "        # here\n",
    "\n",
    "        # initialize client for cloud build\n",
    "        logging.getLogger().setLevel(logging.INFO)\n",
    "        build_client = cloudbuild.services.cloud_build.CloudBuildClient()\n",
    "\n",
    "        # parse step inputs to get path to Dockerfile and training application code\n",
    "        _gcs_dockerfile_path = os.path.join(artifact_gcs_path, f\"{docker_name}\") # Dockerfile.XXXXX\n",
    "        _gcs_script_dir_path = os.path.join(artifact_gcs_path, f\"{app_dir_name}/\") # \"trainer/\"\n",
    "\n",
    "        logging.info(f\"_gcs_dockerfile_path: {_gcs_dockerfile_path}\")\n",
    "        logging.info(f\"_gcs_script_dir_path: {_gcs_script_dir_path}\")\n",
    "\n",
    "        # define build steps to pull the training code and Dockerfile\n",
    "        # and build/push the custom training container image\n",
    "        build = cloudbuild.Build()\n",
    "        build.steps = [\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "                \"args\": [\"cp\", \"-r\", _gcs_script_dir_path, \".\"],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "                \"args\": [\"cp\", _gcs_dockerfile_path, \"Dockerfile\"],\n",
    "            },\n",
    "            # enabling Kaniko cache in a Docker build that caches intermediate\n",
    "            # layers and pushes image automatically to Container Registry\n",
    "            # https://cloud.google.com/build/docs/kaniko-cache\n",
    "            # {\n",
    "            #     \"name\": \"gcr.io/kaniko-project/executor:latest\",\n",
    "            #     # \"name\": \"gcr.io/kaniko-project/executor:v1.8.0\",        # TODO; downgraded to avoid error in build\n",
    "            #     # \"args\": [f\"--destination={training_image_uri}\", \"--cache=true\"],\n",
    "            #     \"args\": [f\"--destination={training_image_uri}\", \"--cache=false\"],\n",
    "            # },\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "                \"args\": ['build','-t', f'{custom_image_uri}', '.'],\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "                \"args\": ['push', f'{custom_image_uri}'], \n",
    "            },\n",
    "        ]\n",
    "        # override default timeout of 10min\n",
    "        timeout = Duration()\n",
    "        timeout.seconds = 7200\n",
    "        build.timeout = timeout\n",
    "\n",
    "        # create build\n",
    "        operation = build_client.create_build(project_id=project, build=build)\n",
    "        logging.info(\"IN PROGRESS:\")\n",
    "        logging.info(operation.metadata)\n",
    "\n",
    "        # get build status\n",
    "        result = operation.result()\n",
    "        logging.info(\"RESULT:\", result.status)\n",
    "        \n",
    "    else:\n",
    "        logging.info(f\"Using existing (prebuilt) image: {custom_image_uri}\")\n",
    "\n",
    "    # return step outputs\n",
    "    return (\n",
    "        custom_image_uri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0829825-7934-4bdd-8a77-70c619348164",
   "metadata": {},
   "source": [
    "## Create Managed Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18f73845-146b-4b5b-9f95-99a26b864c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_tensorboard.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_tensorboard.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image='python:3.9',\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        'numpy',\n",
    "        'google-cloud-storage',\n",
    "    ],\n",
    "    # output_component_file=\"./pipelines/train_custom_model.yaml\",\n",
    ")\n",
    "def create_tensorboard(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    model_version: str,\n",
    "    pipeline_version: str,\n",
    "    # model_name: str, \n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('tensorboard_resource_name', str),\n",
    "    ('tensorboard_display_name', str),\n",
    "]):\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from google.cloud import storage\n",
    "    \n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        # experiment=experiment_name,\n",
    "    )\n",
    "    \n",
    "    logging.info(f'experiment_name: {experiment_name}')\n",
    "    \n",
    "    # # create new TB instance\n",
    "    TENSORBOARD_DISPLAY_NAME=f\"{experiment_name}-v1\"\n",
    "    tensorboard = vertex_ai.Tensorboard.create(display_name=TENSORBOARD_DISPLAY_NAME, project=project, location=location)\n",
    "    TB_RESOURCE_NAME = tensorboard.resource_name\n",
    "    \n",
    "    logging.info(f'TENSORBOARD_DISPLAY_NAME: {TENSORBOARD_DISPLAY_NAME}')\n",
    "    logging.info(f'TB_RESOURCE_NAME: {TB_RESOURCE_NAME}')\n",
    "    \n",
    "    return (\n",
    "        f'{TB_RESOURCE_NAME}',\n",
    "        f'{TENSORBOARD_DISPLAY_NAME}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9cd2-58a1-4b75-a608-cbc1888ad921",
   "metadata": {},
   "source": [
    "## Train Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d882a90-2445-463e-9005-f83a87f78682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/train_merlin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/train_merlin.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def train_merlin(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    train_image_uri: str,     # TODO: Artifact\n",
    "    train_output_gcs_bucket: str,\n",
    "    tb_resource: str,\n",
    "    batch_size: int, \n",
    "    train_epochs: int,\n",
    "    train_dir: str,\n",
    "    valid_dir: str,\n",
    "    workflow_dir: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    "    service_account: str,\n",
    "    worker_pool_specs: dict,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('merlin_model_gcs_dir', str),\n",
    "    ('query_tower_gcs_dir', str),\n",
    "    ('candidate_tower_gcs_uri', str),\n",
    "    ('candidate_embeddings_gcs_uri', str),\n",
    "    ('working_dir_gcs_path', str),\n",
    "]):\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "    \n",
    "    TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    \n",
    "    BASE_OUTPUT_DIR = f'gs://{train_output_gcs_bucket}/{experiment_name}/{experiment_run}'\n",
    "    STAGING_BUCKET = f'{BASE_OUTPUT_DIR}/staging'\n",
    "    \n",
    "    logging.info(f'BASE_OUTPUT_DIR: {BASE_OUTPUT_DIR}')\n",
    "    logging.info(f'STAGING_BUCKET: {STAGING_BUCKET}')\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        experiment=experiment_name,\n",
    "    )\n",
    "    \n",
    "    # ====================================================\n",
    "    # # DEFINE ARGS\n",
    "    # ====================================================\n",
    "    # TODO: parameterize\n",
    "    # worker_pool_specs[0]['container_spec']['command'].append(f'--tb_name={tb_resource}')\n",
    "    JOB_NAME = f'mm-2t-pipe-train-{version}'\n",
    "    \n",
    "    logging.info(f'tensorboard_resource_name: {tb_resource}')\n",
    "    logging.info(f'service_account: {service_account}')\n",
    "    logging.info(f'worker_pool_specs: {worker_pool_specs}')\n",
    "    logging.info(f'JOB_NAME: {JOB_NAME}')\n",
    "    # logging.info(f'gpu_type: {gpu_type}')\n",
    "    # ==============================================================================\n",
    "    # Submit Train Job \n",
    "    # ==============================================================================\n",
    "\n",
    "    job = vertex_ai.CustomJob(\n",
    "        display_name=JOB_NAME,\n",
    "        worker_pool_specs=worker_pool_specs,\n",
    "        base_output_dir=BASE_OUTPUT_DIR,\n",
    "        staging_bucket=STAGING_BUCKET,\n",
    "    )\n",
    "    \n",
    "    job.run(\n",
    "        sync=False, \n",
    "        service_account=service_account,\n",
    "        tensorboard=tb_resource,\n",
    "        restart_job_on_worker_restart=False,\n",
    "        enable_web_access=True,\n",
    "    )\n",
    "    \n",
    "    # uris set during train script\n",
    "    WORKING_DIR_GCS_URI = f'gs://{train_output_gcs_bucket}/{experiment_name}/{experiment_run}'\n",
    "    MODEL_DIR = f\"{WORKING_DIR_GCS_URI}/model_dir\"\n",
    "    QUERY_TOWER_PATH = f\"{MODEL_DIR}/query_tower\"\n",
    "    CANDIDATE_TOWER_PATH = f\"{MODEL_DIR}/candidate_tower\"\n",
    "    EMBEDDINGS_PATH = f\"{MODEL_DIR}/candidate_embeddings\"\n",
    "    \n",
    "    logging.info(f'WORKING_DIR_GCS_URI: {WORKING_DIR_GCS_URI}')\n",
    "    logging.info(f'MODEL_DIR: {MODEL_DIR}')\n",
    "    logging.info(f'QUERY_TOWER_PATH: {QUERY_TOWER_PATH}')\n",
    "    logging.info(f'CANDIDATE_TOWER_PATH: {CANDIDATE_TOWER_PATH}')\n",
    "    logging.info(f'EMBEDDINGS_PATH: {EMBEDDINGS_PATH}')\n",
    "    \n",
    "    return (\n",
    "        f'{MODEL_DIR}',\n",
    "        f'{QUERY_TOWER_PATH}',\n",
    "        f'{CANDIDATE_TOWER_PATH}',\n",
    "        f'{EMBEDDINGS_PATH}',\n",
    "        f'{WORKING_DIR_GCS_URI}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2fbb9-497b-4bcd-9f0c-89b9afee36f1",
   "metadata": {},
   "source": [
    "## Custom Model Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95c88ec3-bca9-4edb-8b43-7f63f5198a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/upload_custom_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/upload_custom_model.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def upload_custom_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    display_name: str,\n",
    "    artifact_uri: str,\n",
    "    unmanaged_container_model: Input[Artifact],\n",
    "    serving_container_image_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('model', Artifact),\n",
    "    ('model_resource_name', str),\n",
    "]):\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    logging.info(f\" display_name: {display_name}\")\n",
    "    logging.info(f\" artifact_uri: {artifact_uri}\")\n",
    "    logging.info(f\" unmanaged_container_model: {unmanaged_container_model}\")\n",
    "    logging.info(f\" serving_container_image_uri: {serving_container_image_uri}\")\n",
    "    \n",
    "    logging.info(f\"Uploading model to Vertex...\")\n",
    "    model = vertex_ai.Model.upload(\n",
    "        display_name=display_name,\n",
    "        artifact_uri=artifact_uri,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        # parent_model=PARENT_MODEL,\n",
    "        sync=True,\n",
    "    )\n",
    "    \n",
    "    MODEL_RESOURCE_NAME = model.resource_name\n",
    "    logging.info(f\" MODEL_RESOURCE_NAME: {MODEL_RESOURCE_NAME}\")\n",
    "    \n",
    "    return (\n",
    "        model,\n",
    "        f'{MODEL_RESOURCE_NAME}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6c711-328f-4779-bcec-91bcefff76dc",
   "metadata": {},
   "source": [
    "## Create ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf39168b-735f-447a-bcf4-d58474879c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str, \n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    ann_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    leaf_node_embedding_count: int,\n",
    "    leaf_nodes_to_search_percent: int, \n",
    "    ann_index_description: str,\n",
    "    # ann_index_labels: Dict, \n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('ann_index', Artifact),\n",
    "]):\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(f\"ENDPOINT: {ENDPOINT}\")\n",
    "    logging.info(f\"project: {project}\")\n",
    "    logging.info(f\"location: {location}\")\n",
    "    logging.info(f\"INDEX_DIR_GCS: {INDEX_DIR_GCS}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "        \n",
    "    tree_ah_index = vertex_ai.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=f'{ann_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        leaf_node_embedding_count=leaf_node_embedding_count,\n",
    "        leaf_nodes_to_search_percent=leaf_nodes_to_search_percent,\n",
    "        description=ann_index_description,\n",
    "        # labels=ann_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = round((end - start), 2)\n",
    "    logging.info(f'Elapsed time creating index: {elapsed_time} seconds\\n')\n",
    "    \n",
    "    ann_index_resource_uri = tree_ah_index.resource_name\n",
    "    logging.info(\"ann_index_resource_uri:\", ann_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{ann_index_resource_uri}',\n",
    "      tree_ah_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26d57a-354a-4083-86aa-cafdcbe284fa",
   "metadata": {},
   "source": [
    "## Create brute force index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78389c19-9a24-439d-aa43-ca5a06c3ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_brute_force_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_force_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "    ],\n",
    ")\n",
    "def create_brute_force_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    brute_force_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    brute_force_index_description: str,\n",
    "    # brute_force_index_labels: Dict,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('brute_force_index', Artifact),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "    logging.info(\"PROJECT_ID: {}\".format(project))\n",
    "    logging.info(\"REGION: {}\".format(location))\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    brute_force_index = vertex_ai.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name=f'{brute_force_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        # approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        description=brute_force_index_description,\n",
    "        # labels=brute_force_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_force_index.resource_name\n",
    "    print(\"brute_force_index_resource_uri:\",brute_force_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      brute_force_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d56f08-c92a-405f-8432-9866add59005",
   "metadata": {},
   "source": [
    "## Create ANN index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd0c7a4c-6270-43b8-83a9-e11f82aaaea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_ann_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index_endpoint_vpc(\n",
    "    ann_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    ann_index_endpoint_display_name: str,\n",
    "    ann_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('ann_index_endpoint_resource_uri', str),\n",
    "    ('ann_index_endpoint', Artifact),\n",
    "    ('ann_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    ann_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{ann_index_endpoint_display_name}',\n",
    "        description=ann_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    ann_index_endpoint_resource_uri = ann_index_endpoint.resource_name\n",
    "    logging.info(f\"ann_index_endpoint_resource_uri: {ann_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "        f'{vpc_network_resource_uri}',\n",
    "        f'{ann_index_endpoint_resource_uri}',\n",
    "        ann_index_endpoint,\n",
    "        f'{ann_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12337261-4471-49de-af2d-7c09f5196fa5",
   "metadata": {},
   "source": [
    "## Create brute force index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6478a8e7-da31-46f1-9f7b-22b90a38a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_brute_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "    ],\n",
    ")\n",
    "def create_brute_index_endpoint_vpc(\n",
    "    bf_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    brute_index_endpoint_display_name: str,\n",
    "    brute_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('brute_index_endpoint_resource_uri', str),\n",
    "    ('brute_index_endpoint', Artifact),\n",
    "    ('brute_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    brute_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{brute_index_endpoint_display_name}',\n",
    "        description=brute_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    brute_index_endpoint_resource_uri = brute_index_endpoint.resource_name\n",
    "    logging.info(f\"brute_index_endpoint_resource_uri: {brute_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "      f'{vpc_network_resource_uri}',\n",
    "      f'{brute_index_endpoint_resource_uri}',\n",
    "      brute_index_endpoint,\n",
    "      f'{brute_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875fbd6-a4f4-42f0-8186-65a8f4bc9156",
   "metadata": {},
   "source": [
    "## Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6af0825f-68a1-4baa-afce-2a9375c5c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/deploy_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "    ]\n",
    ")\n",
    "def deploy_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    deployed_ann_index_name: str,\n",
    "    ann_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('deployed_ann_index_name', str),\n",
    "    ('deployed_ann_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    VERSION = version\n",
    "    \n",
    "    ann_index = vertex_ai.MatchingEngineIndex(\n",
    "      index_name=ann_index_resource_uri\n",
    "    )\n",
    "    ann_index_resource_uri = ann_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(\n",
    "      index_endpoint_resource_uri\n",
    "    )\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "      index=ann_index, \n",
    "      deployed_index_id=f'{deployed_ann_index_name}' #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    logging.info(f\"index_endpoint.deployed_indexes: {index_endpoint.deployed_indexes}\")\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{ann_index_resource_uri}',\n",
    "      f'{deployed_ann_index_name}',\n",
    "      ann_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376252ba-4728-4406-8e7f-aa54b2a4d240",
   "metadata": {},
   "source": [
    "## Deploy brute force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d9149f-fbaf-4703-8850-4bc975d266c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/deploy_brute_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_brute_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "    ],\n",
    ")\n",
    "def deploy_brute_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    deployed_brute_force_index_name: str,\n",
    "    brute_force_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('deployed_brute_force_index_name', str),\n",
    "    ('deployed_brute_force_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    brute_index = vertex_ai.MatchingEngineIndex(\n",
    "        index_name=brute_force_index_resource_uri\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(index_endpoint_resource_uri)\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "        index=brute_index, \n",
    "        deployed_index_id=f'{deployed_brute_force_index_name}', #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    logging.info(f\"index_endpoint.deployed_indexes: {index_endpoint.deployed_indexes}\")\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      f'{deployed_brute_force_index_name}', #-{TIMESTAMP}',\n",
    "      brute_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1aeafc-9831-40bc-a3bd-cd6c2e904b0b",
   "metadata": {},
   "source": [
    "## Test query deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1889dff-5bd0-4160-9d1c-93c270db4fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/test_deployed_query_model_v7.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/test_deployed_query_model_v7.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        # 'google-api-core==2.10.0',\n",
    "        'google-cloud-pipeline-components'\n",
    "    ],\n",
    ")\n",
    "def test_deployed_query_model(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    deployed_endpoint: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    test_instance_gcs_blob_name: str,\n",
    "    # instances: list,\n",
    "    metrics: Output[Metrics],\n",
    "):\n",
    "    # here\n",
    "    import base64\n",
    "    import logging\n",
    "\n",
    "    from google.cloud import aiplatform\n",
    "    from google.protobuf.json_format import Parse\n",
    "    from google_cloud_pipeline_components.proto.gcp_resources_pb2 import \\\n",
    "        GcpResources\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    from google.cloud.storage.bucket import Bucket\n",
    "    from google.cloud.storage.blob import Blob\n",
    "    \n",
    "    import pickle as pkl\n",
    "    import time\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    aiplatform.init(project=project)\n",
    "    storage_client = storage.Client(project=project)\n",
    "\n",
    "    # parse endpoint resource\n",
    "    logging.info(f\"Endpoint = {deployed_endpoint}\")\n",
    "    gcp_resources = Parse(deployed_endpoint, GcpResources())\n",
    "    endpoint_uri = gcp_resources.resources[0].resource_uri\n",
    "    endpoint_id = \"/\".join(endpoint_uri.split(\"/\")[-8:-2])\n",
    "    logging.info(f\"Endpoint ID = {endpoint_id}\")\n",
    "\n",
    "    # define endpoint client\n",
    "    _endpoint = aiplatform.Endpoint(endpoint_id)\n",
    "    \n",
    "    # ====================================================\n",
    "    # Load test instance\n",
    "    # ====================================================\n",
    "    LOCAL_INSTANCE_FILE = 'merlin_last5_test_instance.pkl'\n",
    "    logging.info(f\"LOCAL_INSTANCE_FILE: {LOCAL_INSTANCE_FILE}\")\n",
    "    \n",
    "    bucket = storage_client.bucket(data_dir_bucket_name)\n",
    "    blob = bucket.blob(test_instance_gcs_blob_name)\n",
    "    blob.download_to_filename(LOCAL_INSTANCE_FILE)\n",
    "\n",
    "    filehandler = open(LOCAL_INSTANCE_FILE, 'rb')\n",
    "    test_instances_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    logging.info(f'test_instances_dict: {test_instances_dict}')\n",
    "    \n",
    "    # ====================================================\n",
    "    # prediction request\n",
    "    # ====================================================\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    playlist_emb = _endpoint.predict(instances=[test_instances_dict])\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed_time = end - start\n",
    "    elapsed_time = round(elapsed_time, 4)\n",
    "    logging.info(f'Deployed query model latency: {elapsed_time} seconds')\n",
    "    logging.info(f'query embeddings: {playlist_emb.predictions}')\n",
    "    \n",
    "    metrics.log_metric(\"endpoint latency\", elapsed_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca255156-63f5-45f5-ba4d-a251884a3164",
   "metadata": {},
   "source": [
    "## Test index deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e85707c9-f90d-43eb-9600-c0d7fc6fc59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train_pipes/test_model_index_endpoint_v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/test_model_index_endpoint_v5.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.23.0',\n",
    "        'google-cloud-pipeline-components',\n",
    "        'google-cloud-storage',\n",
    "        'numpy'\n",
    "    ],\n",
    ")\n",
    "def test_model_index_endpoint(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    data_dir_bucket_name: str,\n",
    "    test_instance_gcs_blob_name: str,\n",
    "    ann_index_endpoint_resource_uri: str,\n",
    "    brute_index_endpoint_resource_uri: str,\n",
    "    endpoint: str, # Input[Artifact],\n",
    "    metrics: Output[Metrics],\n",
    "    # metrics: Output[Metrics],\n",
    "    # metrics: Output[Metrics],\n",
    "    # metrics: Output[Metrics],\n",
    "):\n",
    "    import logging\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import pickle as pkl\n",
    "    \n",
    "    import base64\n",
    "\n",
    "    from typing import Dict, List, Union\n",
    "\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from google.protobuf.json_format import Parse\n",
    "    from google_cloud_pipeline_components.proto.gcp_resources_pb2 import \\\n",
    "        GcpResources\n",
    "    \n",
    "    from google.cloud import storage\n",
    "    from google.cloud.storage.bucket import Bucket\n",
    "    from google.cloud.storage.blob import Blob\n",
    "\n",
    "    # import tensorflow as tf\n",
    "\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    storage_client = storage.Client(project=project)\n",
    "    \n",
    "    # ====================================================\n",
    "    # get deployed model endpoint\n",
    "    # ====================================================\n",
    "    logging.info(f\"Endpoint = {endpoint}\")\n",
    "    gcp_resources = Parse(endpoint, GcpResources())\n",
    "    logging.info(f\"gcp_resources = {gcp_resources}\")\n",
    "    \n",
    "    _endpoint_resource = gcp_resources.resources[0].resource_uri\n",
    "    logging.info(f\"_endpoint_resource = {_endpoint_resource}\")\n",
    "    \n",
    "    _endpoint_uri = \"/\".join(_endpoint_resource.split(\"/\")[-8:-2])\n",
    "    logging.info(f\"_endpoint_uri = {_endpoint_uri}\")\n",
    "    \n",
    "    # define endpoint resource in component\n",
    "    _endpoint = vertex_ai.Endpoint(_endpoint_uri)\n",
    "    logging.info(f\"_endpoint defined\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # Get indexes\n",
    "    # ====================================================\n",
    "    logging.info(f\"ann_index_endpoint_resource_uri: {ann_index_endpoint_resource_uri}\")\n",
    "    logging.info(f\"brute_index_endpoint_resource_uri: {brute_index_endpoint_resource_uri}\")\n",
    "\n",
    "    deployed_ann_index = vertex_ai.MatchingEngineIndexEndpoint(ann_index_endpoint_resource_uri)\n",
    "    deployed_bf_index = vertex_ai.MatchingEngineIndexEndpoint(brute_index_endpoint_resource_uri)\n",
    "\n",
    "    DEPLOYED_ANN_ID = deployed_ann_index.deployed_indexes[0].id\n",
    "    DEPLOYED_BF_ID = deployed_bf_index.deployed_indexes[0].id\n",
    "    logging.info(f\"DEPLOYED_ANN_ID: {DEPLOYED_ANN_ID}\")\n",
    "    logging.info(f\"DEPLOYED_BF_ID: {DEPLOYED_BF_ID}\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # Load test instance\n",
    "    # ====================================================\n",
    "    LOCAL_INSTANCE_FILE = 'merlin_last5_test_instance.pkl'\n",
    "    logging.info(f\"LOCAL_INSTANCE_FILE: {LOCAL_INSTANCE_FILE}\")\n",
    "    \n",
    "    bucket = storage_client.bucket(data_dir_bucket_name)\n",
    "    blob = bucket.blob(test_instance_gcs_blob_name)\n",
    "    blob.download_to_filename(LOCAL_INSTANCE_FILE)\n",
    "\n",
    "    filehandler = open(LOCAL_INSTANCE_FILE, 'rb')\n",
    "    test_instances_dict = pkl.load(filehandler)\n",
    "    filehandler.close()\n",
    "    \n",
    "    logging.info(f'test_instances_dict: {test_instances_dict}')\n",
    "    \n",
    "    # ====================================================\n",
    "    # get query response\n",
    "    # ====================================================\n",
    "    start = time.time()\n",
    "\n",
    "    playlist_emb = _endpoint.predict(instances=[test_instances_dict])\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    elapsed_query_time = end - start\n",
    "    elapsed_query_time = round(elapsed_query_time, 4)\n",
    "    logging.info(f'Query endpoint latency: {elapsed_query_time} seconds')\n",
    "    \n",
    "    # ====================================================\n",
    "    # call matching engine with predicted emb vectors\n",
    "    # ====================================================\n",
    "    logging.info('Retreiving neighbors from ANN index...')\n",
    "    start = time.time()\n",
    "    ANN_response = deployed_ann_index.match(\n",
    "        deployed_index_id=DEPLOYED_ANN_ID,\n",
    "        queries=playlist_emb.predictions,\n",
    "        num_neighbors=50\n",
    "    )\n",
    "    end = time.time()\n",
    "    elapsed_ann_time = end - start\n",
    "    elapsed_ann_time = round(elapsed_ann_time, 4)\n",
    "    logging.info(f'ANN latency: {elapsed_ann_time} seconds')\n",
    "    \n",
    "    \n",
    "    logging.info('Retreiving neighbors from BF index...')\n",
    "    start = time.time()\n",
    "    BF_response = deployed_bf_index.match(\n",
    "        deployed_index_id=DEPLOYED_BF_ID,\n",
    "        queries=playlist_emb.predictions,\n",
    "        num_neighbors=50\n",
    "    )\n",
    "    end = time.time()\n",
    "    elapsed_bf_time = end - start\n",
    "    elapsed_bf_time = round(elapsed_bf_time, 4)\n",
    "    logging.info(f'Bruteforce latency: {elapsed_bf_time} seconds')\n",
    "    \n",
    "    # TODO: write results to file -> GCS\n",
    "    \n",
    "    # ====================================================\n",
    "    # Calculate recall by determining how many neighbors were correctly retrieved \n",
    "    # compare with brute-force search\n",
    "    # ====================================================\n",
    "    recalled_neighbors = 0\n",
    "    for tree_ah_neighbors, brute_force_neighbors in zip(\n",
    "        ANN_response, BF_response\n",
    "    ):\n",
    "        tree_ah_neighbor_ids = [neighbor.id for neighbor in tree_ah_neighbors]\n",
    "        brute_force_neighbor_ids = [neighbor.id for neighbor in brute_force_neighbors]\n",
    "\n",
    "        recalled_neighbors += len(\n",
    "            set(tree_ah_neighbor_ids).intersection(brute_force_neighbor_ids)\n",
    "        )\n",
    "\n",
    "    recall = recalled_neighbors / len(\n",
    "        [neighbor for neighbors in BF_response for neighbor in neighbors]\n",
    "    )\n",
    "\n",
    "    logging.info(\"Recall: {}\".format(recall))\n",
    "    logging.info(f'playlist_emb: {playlist_emb.predictions}')\n",
    "    logging.info(f'ANN_response: {ANN_response}')\n",
    "    logging.info(f'BF_response: {BF_response}')\n",
    "    \n",
    "    metrics.log_metric(\"elapsed_query_time\", elapsed_query_time)\n",
    "    metrics.log_metric(\"elapsed_ann_time\", elapsed_ann_time)\n",
    "    metrics.log_metric(\"elapsed_bf_time\", elapsed_bf_time)\n",
    "    metrics.log_metric(\"Recall\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8ec4ca-1fcc-4b7d-9dd0-ba5bb6094ce8",
   "metadata": {},
   "source": [
    "## Compute config for pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4bb82930-214e-4e1c-92b0-0256ce9ca0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/train_pipes/pipeline_config.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/pipeline_config.py\n",
    "CPU_LIMIT='96' # 24\n",
    "MEMORY_LIMIT='170G' # 170G 624G\n",
    "INSTANCE_TYPE=\"a2-highgpu-2g\"\n",
    "GPU_LIMIT=2\n",
    "GPU_TYPE=\"NVIDIA_TESLA_A100\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f626f-e4a9-4cec-87f2-977339b59147",
   "metadata": {},
   "source": [
    "# Prepare Job Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22501ce6-b1e6-4008-b3f2-a5d0483ba9a8",
   "metadata": {},
   "source": [
    "## Accelerators and Device Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a88e2b76-6074-4a71-87f2-721b1615ec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Single | Single machine, single GPU\n",
    "# ====================================================\n",
    "WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "REPLICA_COUNT = 1\n",
    "ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "REDUCTION_SERVER_COUNT = 0                                                      \n",
    "REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "DISTRIBUTE_STRATEGY = 'single'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c3c05-b486-44d9-956c-cb3b766de229",
   "metadata": {},
   "source": [
    "## Vertex AI Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e5039cb-e1f3-4f4a-bb69-dac8f21654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='v11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "861b8488-3ef1-42fa-9d83-611cebfcffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: test-e2e-pipe-v11\n",
      "RUN_NAME: run-20230321-100615\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_PREFIX = 'test-e2e-pipe'                     # custom identifier for organizing experiments\n",
    "EXPERIMENT_NAME=f'{EXPERIMENT_PREFIX}-{VERSION}'\n",
    "RUN_NAME = f'run-{time.strftime(\"%Y%m%d-%H%M%S\")}'\n",
    "# RUN_NAME = 'run-20230308-171530'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"RUN_NAME: {RUN_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39348ef0-e24e-4cf9-86f7-5eabcc2d79af",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6a4972-4761-47b4-ba33-ac59048f3003",
   "metadata": {},
   "source": [
    "### train image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db706d09-9f09-4c9c-a1dd-7e090486e556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================================================\n",
    "# train image\n",
    "# =================================================\n",
    "# Existing image URI or name for image to create\n",
    "\n",
    "TRAIN_IMAGE_URI = 'gcr.io/hybrid-vertex/train-2212v16-vertex-merlin-tf-2tower-jtv34'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0735c7d-2e19-4d93-a856-771d9c918a5a",
   "metadata": {},
   "source": [
    "### data source\n",
    "* TODO: update these variables to point to the GCS location where the processed training data is stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "025755b6-f918-4bcb-b7ef-e5d37812b09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed\n",
      "TRAIN_DIR: gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/train\n",
      "VALID_DIR: gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/valid\n",
      "WORKFLOW_DIR: gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow\n",
      "PIPELINE_ROOT_PATH: gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root\n"
     ]
    }
   ],
   "source": [
    "# gcs bucket\n",
    "OUTPUT_BUCKET = 'jt-merlin-scaling'\n",
    "\n",
    "# data and schema from nvtabular pipes\n",
    "DATA_DIR = 'gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed'\n",
    "\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "VALID_DIR = f'{DATA_DIR}/valid'\n",
    "\n",
    "WORKFLOW_DIR = 'gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow'\n",
    "\n",
    "# Stores pipeline executions for each run\n",
    "PIPELINE_ROOT_PATH = f'gs://{OUTPUT_BUCKET}/{EXPERIMENT_NAME}/{RUN_NAME}/pipeline_root' # TODO - parametrize\n",
    "\n",
    "print(f\"DATA_DIR: {DATA_DIR}\")\n",
    "print(f\"TRAIN_DIR: {TRAIN_DIR}\")\n",
    "print(f\"VALID_DIR: {VALID_DIR}\")\n",
    "print(f\"WORKFLOW_DIR: {WORKFLOW_DIR}\")\n",
    "print(f\"PIPELINE_ROOT_PATH: {PIPELINE_ROOT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f76216-b4ee-447c-b0c7-7f1a45297955",
   "metadata": {},
   "source": [
    "### train params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5914b10e-2c1d-484d-82c4-f85176cfb778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'container_spec': {'command': ['sh',\n",
      "                                 '-euc',\n",
      "                                 'pip freeze && python -m '\n",
      "                                 'trainer.train_task     '\n",
      "                                 '--per_gpu_batch_size=16384     '\n",
      "                                 '--train_output_bucket=jt-merlin-scaling     '\n",
      "                                 '--train_dir=gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/train     '\n",
      "                                 '--valid_dir=gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/valid     '\n",
      "                                 '--workflow_dir=gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow     '\n",
      "                                 '--num_epochs=60     '\n",
      "                                 '--learning_rate=0.001     '\n",
      "                                 '--distribute=single     '\n",
      "                                 '--experiment_name=test-e2e-pipe-v11     '\n",
      "                                 '--experiment_run=run-20230321-100615     '\n",
      "                                 '--project=hybrid-vertex     '\n",
      "                                 '--location=us-central1     '\n",
      "                                 \"--layer_sizes='[512, 256, 128]'     \"\n",
      "                                 '--valid_frequency=20     '\n",
      "                                 '--epoch_steps=500     --valid_steps=5     '\n",
      "                                 '--chkpt_freq=epoch     --write_embeddings'],\n",
      "                     'image_uri': 'gcr.io/hybrid-vertex/train-2212v16-vertex-merlin-tf-2tower-jtv34'},\n",
      "  'machine_spec': {'accelerator_count': 1,\n",
      "                   'accelerator_type': 'NVIDIA_TESLA_A100',\n",
      "                   'machine_type': 'a2-highgpu-1g'},\n",
      "  'replica_count': 1}]\n"
     ]
    }
   ],
   "source": [
    "from utils import train_utils\n",
    "\n",
    "# data size\n",
    "train_sample_cnt = 8_205_265 # 8_205_265\n",
    "valid_samples_cnt = 82_959\n",
    "\n",
    "# train config\n",
    "NUM_EPOCHS = 60\n",
    "BATCH_SIZE = 4096*4 \n",
    "LEARNING_RATE = 0.001\n",
    "VALID_FREQUENCY = 20\n",
    "VALID_STEPS = valid_samples_cnt // BATCH_SIZE\n",
    "EPOCH_STEPS = train_sample_cnt // BATCH_SIZE\n",
    "CHECKPOINT_FREQ='epoch'\n",
    "\n",
    "# model\n",
    "LAYERS = \"[512, 256, 128]\"\n",
    "\n",
    "    \n",
    "WORKER_CMD = [\n",
    "    'sh',\n",
    "    '-euc',\n",
    "    f'''pip freeze && python -m trainer.train_task \\\n",
    "    --per_gpu_batch_size={BATCH_SIZE} \\\n",
    "    --train_output_bucket={OUTPUT_BUCKET} \\\n",
    "    --train_dir={TRAIN_DIR} \\\n",
    "    --valid_dir={VALID_DIR} \\\n",
    "    --workflow_dir={WORKFLOW_DIR} \\\n",
    "    --num_epochs={NUM_EPOCHS} \\\n",
    "    --learning_rate={LEARNING_RATE} \\\n",
    "    --distribute={DISTRIBUTE_STRATEGY} \\\n",
    "    --experiment_name={EXPERIMENT_NAME} \\\n",
    "    --experiment_run={RUN_NAME} \\\n",
    "    --project={PROJECT_ID} \\\n",
    "    --location={LOCATION} \\\n",
    "    --layer_sizes=\\'{LAYERS}\\' \\\n",
    "    --valid_frequency={VALID_FREQUENCY} \\\n",
    "    --epoch_steps={EPOCH_STEPS} \\\n",
    "    --valid_steps={VALID_STEPS} \\\n",
    "    --chkpt_freq={CHECKPOINT_FREQ} \\\n",
    "    --write_embeddings'''\n",
    "    # --profiler \\\n",
    "    # --tb_name={TB_RESOURCE_NAME} \\\n",
    "]\n",
    "    \n",
    "WORKER_POOL_SPECS = train_utils.prepare_worker_pool_specs(\n",
    "    image_uri=TRAIN_IMAGE_URI,\n",
    "    # args=WORKER_ARGS,\n",
    "    cmd=WORKER_CMD,\n",
    "    replica_count=REPLICA_COUNT,\n",
    "    machine_type=WORKER_MACHINE_TYPE,\n",
    "    accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "    accelerator_type=ACCELERATOR_TYPE,\n",
    "    reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "    reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(WORKER_POOL_SPECS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f6ed0-5fbd-4168-bba8-45b4d5899340",
   "metadata": {},
   "source": [
    "# Build & Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb337-7015-419e-aa3b-40f8bcda6db7",
   "metadata": {},
   "source": [
    "### pipe configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc7d180f-1158-4769-a583-1b2ca6969b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: merlin-v11-e2e-pipe-jtv05\n",
      "PIPELINE_NAME: merlin-v11-e2e-pipe-jtv05\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_VERSION = 'jtv05' # pipeline code\n",
    "\n",
    "PIPELINE_TAG = f'merlin-{VERSION}-e2e-pipe-{PIPELINE_VERSION}'\n",
    "\n",
    "PIPELINE_NAME = f'{PIPELINE_TAG}'.replace('_', '-')\n",
    "\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)\n",
    "print(\"PIPELINE_NAME:\", PIPELINE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268a06a-1214-470b-ad73-3203c0010291",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cdc191f5-b605-4b53-9f8d-7cf5dc2a9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_pipes import (\n",
    "    train_merlin, build_custom_image, upload_custom_model,\n",
    "    create_ann_index, create_brute_force_index, create_ann_index_endpoint_vpc,\n",
    "    create_brute_index_endpoint_vpc, deploy_ann_index, deploy_brute_index, \n",
    "    create_tensorboard, pipeline_config, test_deployed_query_model_v7, test_model_index_endpoint_v5\n",
    ")\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "    name=f'{PIPELINE_NAME}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version:str,\n",
    "    vpc_network_name: str,\n",
    "    pipe_gcs_path: str,\n",
    "    train_output_gcs_bucket: str,\n",
    "    training_image_uri: str,\n",
    "    serving_image_uri: str,\n",
    "    train_docker_name: str,\n",
    "    serving_docker_name: str,\n",
    "    tb_resource: str,\n",
    "    batch_size: int,\n",
    "    train_epochs: int,\n",
    "    train_dir: str,\n",
    "    valid_dir: str,\n",
    "    workflow_dir: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    "    service_account: str,\n",
    "    embeddings_dim: int,\n",
    "    layer_sizes: str,\n",
    "    worker_pool_specs: dict,\n",
    "    test_instance_gcs_blob_name: str,\n",
    "):\n",
    "    \n",
    "    from kfp.v2.components import importer_node\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    # ========================================================================\n",
    "    # TODO: data processing steps\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build TRAIN Image\n",
    "    # ========================================================================\n",
    "    build_custom_train_image_op = (\n",
    "        build_custom_image.build_custom_image(\n",
    "            project=project,\n",
    "            artifact_gcs_path=f'{pipe_gcs_path}',\n",
    "            app_dir_name='trainer',\n",
    "            docker_name=train_docker_name,\n",
    "            custom_image_uri=training_image_uri,\n",
    "            use_existing='True',\n",
    "        )\n",
    "        .set_display_name(\"Build Train Image\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Managed TB\n",
    "    # ========================================================================\n",
    "    \n",
    "    create_managed_tensorboard_op = (\n",
    "        create_tensorboard.create_tensorboard(\n",
    "            # here\n",
    "            project=project,\n",
    "            location=location,\n",
    "            model_version=version,\n",
    "            pipeline_version=version,\n",
    "            # model_name=model_display_name, \n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run=experiment_run,\n",
    "        )\n",
    "        .set_display_name(\"Managed TB\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Train Merlin Towers\n",
    "    # ========================================================================\n",
    "    \n",
    "    train_merlin_op = (\n",
    "        train_merlin.train_merlin(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            train_image_uri=build_custom_train_image_op.outputs['custom_image_uri'],\n",
    "            train_output_gcs_bucket=train_output_gcs_bucket,\n",
    "            tb_resource=create_managed_tensorboard_op.outputs['tensorboard_resource_name'], #tb_resource,\n",
    "            batch_size=batch_size,\n",
    "            train_epochs=train_epochs,\n",
    "            train_dir=train_dir,\n",
    "            valid_dir=valid_dir,\n",
    "            workflow_dir=workflow_dir,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run=experiment_run,\n",
    "            service_account=service_account,\n",
    "            worker_pool_specs=worker_pool_specs,\n",
    "        )\n",
    "        .set_display_name(\"Train Merlin Towers\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build SERVING Image\n",
    "    # ========================================================================\n",
    "    build_custom_serving_image_op = (\n",
    "        build_custom_image.build_custom_image(\n",
    "            project=project,\n",
    "            artifact_gcs_path=f'{pipe_gcs_path}',\n",
    "            app_dir_name='serving',\n",
    "            docker_name=serving_docker_name,\n",
    "            custom_image_uri=serving_image_uri,\n",
    "            use_existing='True',\n",
    "        )\n",
    "        .set_display_name(\"Build Serving Image\")\n",
    "        # .after(build_custom_train_image_op)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "       \n",
    "    # ========================================================================\n",
    "    # Import Trained Towers to Pipeline DAG\n",
    "    # ========================================================================\n",
    "    import_query_model_task = (\n",
    "        importer_node.importer(\n",
    "            artifact_uri=train_merlin_op.outputs['query_tower_gcs_dir'],\n",
    "            artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        )\n",
    "        .set_display_name(\"Import Query Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    import_candidate_model_task = (\n",
    "        importer_node.importer(\n",
    "            artifact_uri=train_merlin_op.outputs['candidate_tower_gcs_uri'],\n",
    "            artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        )\n",
    "        .set_display_name(\"Import Candidate Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Upload Models to Vertex AI Model Registry\n",
    "    # ========================================================================\n",
    "    \n",
    "    query_model_upload_op = (\n",
    "        upload_custom_model.upload_custom_model(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            display_name=f'merlin-query-tower-{version}',\n",
    "            artifact_uri=train_merlin_op.outputs[\"query_tower_gcs_dir\"],\n",
    "            unmanaged_container_model=import_query_model_task.outputs[\"artifact\"],\n",
    "            serving_container_image_uri=build_custom_serving_image_op.outputs[\"custom_image_uri\"],\n",
    "        )\n",
    "        .set_display_name(\"Register Query Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    from google_cloud_pipeline_components.experimental.evaluation import \\\n",
    "        GetVertexModelOp\n",
    "    \n",
    "    model = (\n",
    "        GetVertexModelOp(\n",
    "            model_resource_name=query_model_upload_op.outputs['model_resource_name'],\n",
    "        )\n",
    "        .set_display_name(\"Get Vertex Model\")\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Deploy Model to Endpoint\n",
    "    # ========================================================================\n",
    "    endpoint_create_op = (\n",
    "        gcc_aip.EndpointCreateOp(\n",
    "            project=project,\n",
    "            display_name=f'query-tower-endpoint-{version}'\n",
    "        )\n",
    "        .after(query_model_upload_op)\n",
    "        .set_display_name(\"Create Query Endpoint\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    model_deploy_op = (\n",
    "        gcc_aip.ModelDeployOp(\n",
    "            endpoint=endpoint_create_op.outputs['endpoint'],\n",
    "            model=model.outputs['model'],\n",
    "            deployed_model_display_name=f'deployed-qtower-{version}',\n",
    "            dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "            dedicated_resources_accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "            dedicated_resources_accelerator_count=1,\n",
    "            dedicated_resources_max_replica_count=1,\n",
    "            dedicated_resources_min_replica_count=1,\n",
    "            service_account=service_account,\n",
    "        )\n",
    "        .set_display_name(\"Deploy Query Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    test_deployed_query_model_op = (\n",
    "        test_deployed_query_model_v7.test_deployed_query_model(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            deployed_endpoint=model_deploy_op.outputs[\"gcp_resources\"],\n",
    "            data_dir_bucket_name=train_output_gcs_bucket,\n",
    "            test_instance_gcs_blob_name=test_instance_gcs_blob_name\n",
    "        )\n",
    "        .set_display_name(\"test query model deploy\")\n",
    "        .set_caching_options(False)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Create ME indexes\n",
    "    # ========================================================================\n",
    "    \n",
    "    create_ann_index_op = (\n",
    "        create_ann_index.create_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=train_merlin_op.outputs['candidate_embeddings_gcs_uri'],\n",
    "            dimensions=embeddings_dim,\n",
    "            ann_index_display_name=f'v1_ann_index_{version}'.replace('-', '_'),\n",
    "            approximate_neighbors_count=50,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            leaf_node_embedding_count=500,\n",
    "            leaf_nodes_to_search_percent=7, \n",
    "            ann_index_description=\"testing ann index for Merlin deployment\",\n",
    "            # ann_index_labels=ann_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index\")\n",
    "        # .after(XXXX)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    create_brute_force_index_op = (\n",
    "        create_brute_force_index.create_brute_force_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=train_merlin_op.outputs['candidate_embeddings_gcs_uri'],\n",
    "            dimensions=embeddings_dim,\n",
    "            brute_force_index_display_name=f'v1_bf_index_{version}'.replace('-', '_'),\n",
    "            approximate_neighbors_count=50,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            brute_force_index_description=\"testing bf index for Merlin deployment\",\n",
    "            # brute_force_index_labels=brute_force_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index\")\n",
    "        # .after(XXX)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Create ME index endpoints\n",
    "    # ========================================================================\n",
    "    \n",
    "    create_ann_index_endpoint_vpc_op = (\n",
    "        create_ann_index_endpoint_vpc.create_ann_index_endpoint_vpc(\n",
    "            ann_index_artifact=create_ann_index_op.outputs['ann_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            ann_index_endpoint_display_name=f'ann-endpoint_{version}'.replace('-', '_'),\n",
    "            ann_index_endpoint_description='endpoint for ann index',\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index Endpoint\")\n",
    "        # .after(XXX)\n",
    "    )\n",
    "        \n",
    "    create_brute_index_endpoint_vpc_op = (\n",
    "        create_brute_index_endpoint_vpc.create_brute_index_endpoint_vpc(\n",
    "            bf_index_artifact=create_brute_force_index_op.outputs['brute_force_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            brute_index_endpoint_display_name=f'bf-endpoint_{version}'.replace('-', '_'),\n",
    "            brute_index_endpoint_description='endpoint for brute force index',\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index Endpoint\")\n",
    "        # .after(XXX)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Deploy Indexes\n",
    "    # ========================================================================\n",
    "\n",
    "    deploy_ann_index_op = (\n",
    "        deploy_ann_index.deploy_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            deployed_ann_index_name=f'deployed_ann_{version}'.replace('-', '_'),\n",
    "            ann_index_resource_uri=create_ann_index_op.outputs['ann_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_ann_index_endpoint_vpc_op.outputs['ann_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy ANN Index\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    deploy_brute_index_op = (\n",
    "        deploy_brute_index.deploy_brute_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            deployed_brute_force_index_name=f'deployed_bf_{version}'.replace('-', '_'),\n",
    "            brute_force_index_resource_uri=create_brute_force_index_op.outputs['brute_force_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_brute_index_endpoint_vpc_op.outputs['brute_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy BF Index\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Test deployed indexes\n",
    "    # ========================================================================\n",
    "    test_model_index_endpoint_op = (\n",
    "        test_model_index_endpoint_v5.test_model_index_endpoint(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            data_dir_bucket_name=train_output_gcs_bucket,\n",
    "            test_instance_gcs_blob_name=test_instance_gcs_blob_name,\n",
    "            ann_index_endpoint_resource_uri=deploy_ann_index_op.outputs['index_endpoint_resource_uri'],\n",
    "            brute_index_endpoint_resource_uri=deploy_brute_index_op.outputs['index_endpoint_resource_uri'],\n",
    "            endpoint=model_deploy_op.outputs['gcp_resources']\n",
    "        )\n",
    "        .set_display_name(\"Test deployed model & indexes\")\n",
    "        .set_caching_options(False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0277936-8f7e-44f7-bd31-33a6d40d5ff1",
   "metadata": {},
   "source": [
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f05b2a36-97f1-4a14-b0d9-67b15f9aac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON_SPEC_LOCAL = \"custom_pipeline_spec.json\"\n",
    "\n",
    "! rm -f $PIPELINE_JSON_SPEC_LOCAL\n",
    "\n",
    "kfp.v2.compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=PIPELINE_JSON_SPEC_LOCAL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e9c2f00e-779d-4ff3-b63d-2f23765f33a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINES_FILEPATH: gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/pipeline_spec.json\n",
      "Copying file://custom_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][106.1 KiB/106.1 KiB]                                                \n",
      "Operation completed over 1 objects/106.1 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "PIPELINES_FILEPATH = f'{PIPELINE_ROOT_PATH}/pipeline_spec.json'\n",
    "print(\"PIPELINES_FILEPATH:\", PIPELINES_FILEPATH)\n",
    "\n",
    "!gsutil cp $PIPELINE_JSON_SPEC_LOCAL $PIPELINES_FILEPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2466973-34a0-4bdf-96e6-0a72c9b08110",
   "metadata": {},
   "source": [
    "## Upload test instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf8cd175-254c-48fd-a292-ba5540660ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "# query features\n",
    "LOCAL_INSTANCE_FILE = f'merlin_last5_test_instance_{VERSION}.pkl'\n",
    "\n",
    "! rm -f $LOCAL_INSTANCE_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "79573d92-fa98-443e-a9f0-e69e8db23374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE_FILE_GCS_OBJ: test-e2e-pipe-v11/run-20230321-100615/merlin_last5_test_instance_v11.pkl\n",
      "INSTANCE_FILE GCS URI: gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/merlin_last5_test_instance_v11.pkl\n"
     ]
    }
   ],
   "source": [
    "TEST_INSTANCE = {\n",
    "    'collaborative': 'false',\n",
    "    'album_name_pl': [\n",
    "        \"There's Really A Wolf\", 'Late Nights: The Album','American Teen', 'Crazy In Love', 'Pony'\n",
    "    ], \n",
    "    'artist_genres_pl': [\n",
    "        \"'hawaiian hip hop', 'rap'\",\n",
    "       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"\n",
    "    ], \n",
    "    'artist_name_pl': [\n",
    "        'Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9','William Singe'\n",
    "    ], \n",
    "    'artist_pop_can': 82.0, \n",
    "    'description_pl': '', \n",
    "    'duration_ms_songs_pl': [\n",
    "        237506.0, 217200.0, 219080.0, 226400.0, 121739.0\n",
    "    ], \n",
    "    'n_songs_pl': 8.0, \n",
    "    'name': 'Lit Tunes ', \n",
    "    'num_albums_pl': 8.0, \n",
    "    'num_artists_pl': 8.0, \n",
    "    'track_name_pl': [\n",
    "        'Losin Control', 'Paradise', 'Location','Crazy In Love - Remix', 'Pony'\n",
    "    ], \n",
    "    'track_pop_pl': [\n",
    "        79.0, 58.0, 83.0, 71.0, 57.0\n",
    "    ],\n",
    "    'duration_ms_seed_pl': 51023.1,\n",
    "    'pid': 1,\n",
    "    'track_uri_pl': [\n",
    "        'spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "        'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "        'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "        'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "        'spotify:track:4Lj8paMFwyKTGfILLELVxt'\n",
    "    ]\n",
    "}\n",
    "\n",
    "INSTANCE_FILE_GCS_OBJ = f'{EXPERIMENT_NAME}/{RUN_NAME}/{LOCAL_INSTANCE_FILE}'\n",
    "\n",
    "# pickle\n",
    "filehandler = open(f'{LOCAL_INSTANCE_FILE}', 'wb')\n",
    "pkl.dump(TEST_INSTANCE, filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# upload to GCS\n",
    "bucket_client = storage_client.bucket(OUTPUT_BUCKET)\n",
    "blob = bucket_client.blob(INSTANCE_FILE_GCS_OBJ)\n",
    "blob.upload_from_filename(LOCAL_INSTANCE_FILE)\n",
    "\n",
    "print(\"INSTANCE_FILE_GCS_OBJ:\", INSTANCE_FILE_GCS_OBJ)\n",
    "print(f\"INSTANCE_FILE GCS URI: gs://{OUTPUT_BUCKET}/{INSTANCE_FILE_GCS_OBJ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b8c7e8-8f4c-414c-b6fd-b4eb4090681a",
   "metadata": {},
   "source": [
    "### copy artifacts & repo to GCS\n",
    "\n",
    "> helps with tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4ceb963-5fdc-4dc7-bbda-df85057753ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_DOCKERNAME='mm-query-serve'\n",
    "TRAIN_DOCKERNAME='train'\n",
    "SERVING_SUB_DIR='serving'\n",
    "TRAIN_SUB_DIR='trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3b1966bf-ec3b-4c14-aae2-8d7a580d9f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/Dockerfile.mm-query-serve [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  862.0 B/  862.0 B]                                                \n",
      "Operation completed over 1 objects/862.0 B.                                      \n",
      "Copying file://./src/Dockerfile.train [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  319.0 B/  319.0 B]                                                \n",
      "Operation completed over 1 objects/319.0 B.                                      \n",
      "Copying file://./src/serving/app/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://./src/serving/app/dataset_to_tensors.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/serving/app/__init__.py [Content-Type=text/x-python]...    \n",
      "Copying file://./src/serving/app/instances.json [Content-Type=application/json]...\n",
      "Copying file://./src/serving/app/predictor.py [Content-Type=text/x-python]...   \n",
      "Copying file://./src/serving/app/main.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/serving/app/prestart.sh [Content-Type=text/x-sh]...        \n",
      "Copying file://./src/serving/local_workflow/workflow/metadata.json [Content-Type=application/json]...\n",
      "Copying file://./src/serving/local_workflow/workflow/workflow.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.collaborative.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_uri_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_uri_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_genres_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.name.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.album_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.description_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.pid.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_genres_pl.parquet [Content-Type=application/octet-stream]...\n",
      "| [22/22 files][284.9 MiB/284.9 MiB] 100% Done                                  \n",
      "Operation completed over 22 objects/284.9 MiB.                                   \n",
      "Copying file://./src/trainer/train_task.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/trainer/interactive_train.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/trainer/requirements.txt [Content-Type=text/plain]...      \n",
      "Copying file://./src/trainer/two_tower_model.py [Content-Type=text/x-python]... \n",
      "Copying file://./src/trainer/__init__.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/trainer/train_utils.py [Content-Type=text/x-python]...     \n",
      "/ [6/6 files][ 25.5 KiB/ 25.5 KiB] 100% Done                                    \n",
      "Operation completed over 6 objects/25.5 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./$REPO_DOCKER_PATH_PREFIX/Dockerfile.$SERVING_DOCKERNAME $PIPELINE_ROOT_PATH/\n",
    "!gsutil cp ./$REPO_DOCKER_PATH_PREFIX/Dockerfile.$TRAIN_DOCKERNAME $PIPELINE_ROOT_PATH/\n",
    "\n",
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR $PIPELINE_ROOT_PATH/\n",
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$TRAIN_SUB_DIR $PIPELINE_ROOT_PATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a92a5c2-83d0-441e-9529-3523859d23d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/Dockerfile.mm-query-serve\n",
      "gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/Dockerfile.train\n",
      "gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/pipeline_spec.json\n",
      "gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/serving/\n",
      "gs://jt-merlin-scaling/test-e2e-pipe-v11/run-20230321-100615/pipeline_root/trainer/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $PIPELINE_ROOT_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17686d4c-cb8a-43ef-801f-60c842f494a7",
   "metadata": {},
   "source": [
    "## Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4b575-ed3b-4535-8fc4-4caae701ed22",
   "metadata": {},
   "source": [
    "## pipe args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8fae3384-9ec2-4f51-ab52-c4b6ee8bf73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DOCKERFILE_NAME: Dockerfile.train\n",
      "SERVE_DOCKERFILE_NAME: Dockerfile.mm-query-serve\n",
      "\n",
      "TRAIN_IMAGE_URI: gcr.io/hybrid-vertex/train-2212v16-vertex-merlin-tf-2tower-jtv34\n",
      "SERVING_IMAGE_URI: gcr.io/hybrid-vertex/mm2t-vertex-serv-v28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# IMAGES\n",
    "# TRAIN_IMAGE_URI = f'gcr.io/hybrid-vertex/train-2212v15-vertex-merlin-tf-2tower-jtv33'\n",
    "SERVING_IMAGE_URI='gcr.io/hybrid-vertex/mm2t-vertex-serv-v28'\n",
    "\n",
    "# DOCKERFILES\n",
    "TRAIN_DOCKERFILE_NAME = f'Dockerfile.{TRAIN_DOCKERNAME}'\n",
    "SERVE_DOCKERFILE_NAME = f'Dockerfile.{SERVING_DOCKERNAME}'\n",
    "\n",
    "print(f\"TRAIN_DOCKERFILE_NAME: {TRAIN_DOCKERFILE_NAME}\")\n",
    "print(f\"SERVE_DOCKERFILE_NAME: {SERVE_DOCKERFILE_NAME}\\n\")\n",
    "print(f\"TRAIN_IMAGE_URI: {TRAIN_IMAGE_URI}\")\n",
    "print(f\"SERVING_IMAGE_URI: {SERVING_IMAGE_URI}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ea0cd6a-6963-4743-ad57-245be87d2e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "vpc_network_name = 'ucaip-haystack-vpc-network'\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "job = vertex_ai.PipelineJob(\n",
    "    display_name=PIPELINE_NAME,\n",
    "    template_path=PIPELINES_FILEPATH,\n",
    "    pipeline_root=f'{PIPELINE_ROOT_PATH}',\n",
    "    failure_policy='fast', # slow | fast\n",
    "    # enable_caching=False,\n",
    "    parameter_values={\n",
    "        # here\n",
    "        'project': PROJECT_ID,\n",
    "        'project_number': PROJECT_NUM,\n",
    "        'location': LOCATION,\n",
    "        'vpc_network_name': vpc_network_name,\n",
    "        'version': VERSION,\n",
    "        'train_output_gcs_bucket':OUTPUT_BUCKET,\n",
    "        'pipe_gcs_path': PIPELINE_ROOT_PATH,\n",
    "        'training_image_uri': TRAIN_IMAGE_URI,\n",
    "        'serving_image_uri': SERVING_IMAGE_URI,\n",
    "        'train_docker_name': TRAIN_DOCKERFILE_NAME,\n",
    "        'serving_docker_name': SERVE_DOCKERFILE_NAME,\n",
    "        'tb_resource': '',\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'train_epochs': NUM_EPOCHS,\n",
    "        'train_dir': TRAIN_DIR,\n",
    "        'valid_dir': VALID_DIR,\n",
    "        'workflow_dir': WORKFLOW_DIR,\n",
    "        'experiment_name': EXPERIMENT_NAME,\n",
    "        'experiment_run': RUN_NAME,\n",
    "        'service_account': VERTEX_SA,\n",
    "        'embeddings_dim': 128,\n",
    "        'layer_sizes': LAYERS,\n",
    "        'worker_pool_specs': WORKER_POOL_SPECS,\n",
    "        'test_instance_gcs_blob_name':INSTANCE_FILE_GCS_OBJ,\n",
    "    },\n",
    ")\n",
    "\n",
    "job.run(\n",
    "    sync=False,\n",
    "    service_account=VERTEX_SA,\n",
    "    network=f'projects/{PROJECT_NUM}/global/networks/{vpc_network_name}'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d36c45d-3120-4cf2-afad-a221b9a509f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
