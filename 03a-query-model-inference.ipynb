{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc27ca62-e310-4139-b3bb-3a0cba5d58ef",
   "metadata": {},
   "source": [
    "# Deploying Merlin Query Tower with Vertex AI\n",
    "\n",
    "* Create custom prediction routine (CPR)\n",
    "* Upload query model to Vertex AI Model Registry\n",
    "* Test registered models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb40555-d090-45b8-a197-26252e430287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb336ccc-239a-4f43-8fc5-318a31dd0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "import os\n",
    "import time\n",
    "\n",
    "BUCKET = 'jt-merlin-scaling'\n",
    "BUCKET_URI = 'gs://jt-merlin-scaling'\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b8b6e4-0426-49f9-82ca-8e7cf5ea07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce275cb8-05ba-4daf-9cfc-2a2d8ab4f591",
   "metadata": {},
   "source": [
    "## Build serving app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a28ef83-b05b-4b4c-9694-59d5b64e2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "SERVING_SUB_DIR = 'serving'\n",
    "SERVING_APPLICATION_DIR = 'app'\n",
    "SERVING_DOCKERNAME = 'mm-query-serve'\n",
    "LOCAL_WORKFLOW_DIR = f'{REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/local_workflow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723aaec-495e-4a74-b895-ff87fdd9ba1d",
   "metadata": {},
   "source": [
    "### write pred files to local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734aea8d-6367-4bcd-9ce2-e8025ac17475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training subfolder\n",
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}\n",
    "! touch {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/__init__.py\n",
    "\n",
    "!rm -rf $LOCAL_WORKFLOW_DIR\n",
    "!mkdir $LOCAL_WORKFLOW_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c1711-1b15-4df1-8ec1-b919e25eddaa",
   "metadata": {},
   "source": [
    "#### requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308c947c-1bdf-42ea-96aa-0bb897bd9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "# uvloop==0.15.2\n",
    "# fastapi-utils\n",
    "google-cloud-aiplatform\n",
    "merlin-models\n",
    "nvtabular\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef49b8d-c2eb-4216-8468-1e94cb96dd5b",
   "metadata": {},
   "source": [
    "### dataset to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2b4ea03-b21e-4a58-a737-7622278dbafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/dataset_to_tensors.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/dataset_to_tensors.py\n",
    "\n",
    "try:\n",
    "    import cudf\n",
    "except ImportError:\n",
    "    cudf = None\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from typing import Dict\n",
    "from merlin.io import Dataset\n",
    "import itertools\n",
    "\n",
    "\n",
    "def cupy_array_to_tensor(array):\n",
    "    return tf.experimental.dlpack.from_dlpack(array.reshape(-1, 1).toDlpack())\n",
    "\n",
    "def numpy_array_to_tensor(array):\n",
    "    return tf.convert_to_tensor(array.reshape(-1, 1))\n",
    "\n",
    "def cudf_series_to_tensor(col) -> tf.Tensor:\n",
    "    \"Convert a cudf.Series to a TensorFlow Tensor with DLPack\"\n",
    "    if isinstance(col.dtype, cudf.ListDtype):\n",
    "        values = col.list.leaves.values\n",
    "        offsets = col.list._column.offsets.values\n",
    "        row_lengths = offsets[1:] - offsets[:-1]\n",
    "        return cupy_array_to_tensor(values), cupy_array_to_tensor(row_lengths)\n",
    "    else:\n",
    "        return cupy_array_to_tensor(col.values)\n",
    "\n",
    "def pandas_series_to_tensor(col) -> tf.Tensor:\n",
    "    if len(col) and pd.api.types.is_list_like(col.values[0]):\n",
    "        values = pd.Series(itertools.chain(*col)).values\n",
    "        row_lengths = col.map(len).values\n",
    "        return numpy_array_to_tensor(values), numpy_array_to_tensor(row_lengths)\n",
    "    else:\n",
    "        return numpy_array_to_tensor(col.values)\n",
    "        \n",
    "    \n",
    "def dataset_to_tensors(dataset: Dataset) -> Dict[str, tf.Tensor]:\n",
    "    \"\"\"Convert a DataFrame to Dict of Tensors\"\"\"\n",
    "    df = dataset.to_ddf().compute()\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        col_to_tensor = pandas_series_to_tensor\n",
    "    else:\n",
    "        col_to_tensor = cudf_series_to_tensor\n",
    "    return {\n",
    "        column: col_to_tensor(df[column])\n",
    "        for column in df.columns\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9432c-59f2-467e-8334-da6764e64326",
   "metadata": {},
   "source": [
    "#### predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "141ef566-1582-433b-a5c6-e6ad41c8e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/predictor.py\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "from dataset_to_tensors import *\n",
    "\n",
    "\n",
    "# These are helper functions that ensure the dictionary input is in a certain order and types are preserved\n",
    "# this is to get scalar values to appear first in the dict to not confuse pandas with lists https://github.com/pandas-dev/pandas/issues/46092\n",
    "reordered_keys = [\n",
    "    'collaborative', \n",
    "    'album_name_pl', \n",
    "    'artist_genres_pl', \n",
    "    'artist_name_pl', \n",
    "    'artist_pop_can', \n",
    "    'description_pl', \n",
    "    'duration_ms_songs_pl', \n",
    "    'n_songs_pl', \n",
    "    'name', \n",
    "    'num_albums_pl', \n",
    "    'num_artists_pl', \n",
    "    'track_name_pl', \n",
    "    'track_pop_pl', \n",
    "    'duration_ms_seed_pl', \n",
    "    'pid', \n",
    "    'track_uri_pl'\n",
    "]\n",
    "\n",
    "float_num_fix = ['n_songs_pl','num_albums_pl','num_artists_pl','duration_ms_seed_pl']\n",
    "float_list_fix = ['track_pop_pl', 'duration_ms_songs_pl']\n",
    "    \n",
    "def fix_list_num_dtypes(num_list):\n",
    "    \"this fixes lists of ints to list of floats converted in json input\"\n",
    "    return [float(x) for x in num_list]\n",
    "\n",
    "def fix_num_dtypes(num):\n",
    "    \"this fixes ints and casts to floats\"\n",
    "    return float(num)\n",
    "\n",
    "def fix_types(k, v):\n",
    "    if k in float_num_fix:\n",
    "        return fix_num_dtypes(v)\n",
    "    if k in float_list_fix:\n",
    "        return fix_list_num_dtypes(v)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def create_pandas_instance(inputs):\n",
    "    \"\"\"\n",
    "    Helper function to reorder the input to have a sclar first for pandas\n",
    "    And fix the types converted when data is imported by fastAPI\n",
    "    \"\"\"\n",
    "    if type(inputs) == list:\n",
    "        header = inputs[0]\n",
    "        reordered_header_dict = {k: fix_types(k,header[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_header_dict, orient='index').T\n",
    "        if len(inputs) > 1:\n",
    "            for ti in inputs[1:]:\n",
    "                reordered_dict = {k: fix_types(k,ti[k]) for k in reordered_keys}\n",
    "                pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(reordered_dict, orient='index').T)\n",
    "    else:\n",
    "        reordered_dict = {k: fix_types(k,inputs[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_dict, orient='index').T\n",
    "    return pandas_instance\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        logging.info(\"loading model and workflow\")\n",
    "        start_init = time.process_time()\n",
    "        \n",
    "        #test_bucket = 'gs://jt-merlin-scaling'\n",
    "        # self.model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query_model_merlin\" ))\n",
    "        # self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\")) # TODO: parameterize\n",
    "        self.model = tf.keras.models.load_model(artifacts_uri)\n",
    "        \n",
    "        # self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\"))\n",
    "        # self.workflow = nvt.Workflow.load('gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed') # TODO: parametrize\n",
    "        self.workflow = nvt.Workflow.load(\"/docker_workflow/workflow\")\n",
    "        \n",
    "        self.workflow = self.workflow.remove_inputs(\n",
    "            [\n",
    "                'track_pop_can', \n",
    "                'track_uri_can', \n",
    "                'duration_ms_can', \n",
    "                'track_name_can', \n",
    "                'artist_name_can',\n",
    "                'album_name_can',\n",
    "                'album_uri_can',\n",
    "                'artist_followers_can', \n",
    "                'artist_genres_can',\n",
    "                'artist_name_can', \n",
    "                'artist_pop_can',\n",
    "                'artist_pop_pl',\n",
    "                'artist_uri_can', \n",
    "                'artists_followers_pl'\n",
    "            ]\n",
    "        )\n",
    "        return self\n",
    "        \n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        # handle different input types, can take a dict or list of dicts\n",
    "        self.n_rows = len(prediction_input)\n",
    "        start = time.process_time()\n",
    "        pandas_instance = create_pandas_instance(prediction_input[0])\n",
    "        #logging.info(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        print(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        #logging.info(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        print(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        print(f\"Workflow transformation took {time.process_time() - start} seconds\")\n",
    "\n",
    "        # def predict(self, instances):\n",
    "        start = time.process_time()\n",
    "        \n",
    "        batch = dataset_to_tensors(transformed_instance)\n",
    "        print(f\"converting to dict_tensors took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        output = self.model(batch)\n",
    "        print(f\"Generating query embeddings took {time.process_time() - start} seconds\")\n",
    "        return transformed_instance, output, batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31d7cf-0a48-4190-8c48-9f6544d47124",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9af6931b-0fe1-43b1-a14e-85b8fa0ef862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "from predictor import Predictor\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    outputs = loaded_predictor.predict(instances)\n",
    "\n",
    "    return {\"predictions\": outputs[1].numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e5eb243-8407-4f90-a070-749038288fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f71121ab-b4d8-40de-8c72-022fd97878bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/instances.json\n",
    "{\n",
    "    \"instances\": {\n",
    "        \"collaborative\": \"false\", \n",
    "        \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \n",
    "        \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \n",
    "        \"artist_followers_can\": 4339757.0, \n",
    "        \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \n",
    "        \"artist_genres_pl\": [\n",
    "            \"'hawaiian hip hop', 'rap'\", \n",
    "            \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \n",
    "            \"'pop', 'pop r&b'\", \n",
    "            \"'dance pop', 'pop', 'r&b'\", \n",
    "            \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"\n",
    "        ], \n",
    "        \"artist_name_can\": \"Russ\", \n",
    "        \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \n",
    "        \"artist_pop_can\": 82.0, \n",
    "        \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \n",
    "        \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \n",
    "        \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \n",
    "        \"description_pl\": \"\", \n",
    "        \"duration_ms_can\": 237322.0, \n",
    "        \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \n",
    "        \"n_songs_pl\": 8.0, \n",
    "        \"name\": \"Lit Tunes \", \n",
    "        \"num_albums_pl\": 8.0, \n",
    "        \"num_artists_pl\": 8.0, \n",
    "        \"track_name_can\": \"We Just Havent Met Yet\", \n",
    "        \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \n",
    "        \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \n",
    "        \"duration_ms_seed_pl\": 51023.1, \n",
    "        \"pid\": 1, \n",
    "        \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \n",
    "        \"track_uri_pl\": [\n",
    "            \"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \n",
    "            \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \n",
    "            \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \n",
    "            \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \n",
    "            \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a4b76-f823-40a6-a23d-dc531fd64150",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"instances\": {\n",
    "        'collaborative': 'false',\n",
    "        'album_name_pl': [\n",
    "            \"There's Really A Wolf\",\n",
    "            'Late Nights: The Album',\n",
    "            'American Teen',\n",
    "            'Crazy In Love',\n",
    "            'Pony'\n",
    "        ],\n",
    "        'artist_genres_pl': [\n",
    "            \"'hawaiian hip hop', 'rap'\",\n",
    "            \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "            \"'pop', 'pop r&b'\",\n",
    "            \"'dance pop', 'pop', 'r&b'\",\n",
    "            \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"\n",
    "        ],\n",
    "        'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'BeyoncÃ©', 'William Singe'],\n",
    "        'artist_pop_can': 82.0,\n",
    "        'description_pl': '',\n",
    "        'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0],\n",
    "        'n_songs_pl': 8.0,\n",
    "        'name': 'Lit Tunes ',\n",
    "        'num_albums_pl': 8.0,\n",
    "        'num_artists_pl': 8.0,\n",
    "        'track_name_pl': ['Losin Control','Paradise','Location','Crazy In Love - Remix','Pony'],\n",
    "        'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
    "        'duration_ms_seed_pl': 51023.1,\n",
    "        'pid': 1,\n",
    "        'track_uri_pl': [\n",
    "            'spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "            'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "            'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "            'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "            'spotify:track:4Lj8paMFwyKTGfILLELVxt'\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1147891d-0d39-4ad6-8466-da0ad292d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# !tree /home/jupyter/merlin-on-vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d1058-73f1-48a7-bede-a1bca7d9f47c",
   "metadata": {},
   "source": [
    "### local nvtabular workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3b5714b-31dc-4e59-8b6e-cfa63e69e8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.album_name_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_genres_can.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_genres_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_name_can.parquet...\n",
      "- [4 files][ 23.6 MiB/ 23.6 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_name_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.collaborative.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.description_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.name.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.pid.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_name_can.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_name_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_uri_can.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_uri_pl.parquet...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/metadata.json...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/workflow.pkl...\n",
      "- [15 files][284.9 MiB/284.9 MiB]                                               \n",
      "Operation completed over 15 objects/284.9 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "WORKFLOW_DIR='gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow'\n",
    "\n",
    "!gsutil cp -r $WORKFLOW_DIR $LOCAL_WORKFLOW_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2390771-4c19-4c14-b8b3-940437deb824",
   "metadata": {},
   "source": [
    "### dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10de1285-535f-4952-9bb0-15e08ab36de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f9837b4-c739-4671-9ca6-df71fb590404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Dockerfile.mm-query-serve\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.12\n",
    "\n",
    "# WORKDIR /src\n",
    "WORKDIR /app\n",
    "\n",
    "# Copies the serving code to the docker image.\n",
    "COPY ./serving/app/requirements.txt /requirements.txt\n",
    "RUN pip install -r /requirements.txt\n",
    "\n",
    "RUN mkdir /docker_workflow\n",
    "\n",
    "COPY ./serving/local_workflow /docker_workflow\n",
    "\n",
    "COPY ./serving/app /app\n",
    "\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8bf668c-7fd8-4a71-aca8-6a6d18319402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "\n",
    "# !cp /src/serving/local_workflow /docker_workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bede56-9349-47b8-8149-ad4daf0487c0",
   "metadata": {},
   "source": [
    "## Copy serving assets to `MODEL_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28005617-3219-4810-9be6-2b2960365dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_RUN_DIR: gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554\n",
      "MODEL_DIR: gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT_RUN_DIR='gs://jt-merlin-scaling/new9-2tower-merlin-tf-jtv24/run-20230228-170848'\n",
    "EXPERIMENT_RUN_DIR='gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554'\n",
    "MODEL_DIR=f'{EXPERIMENT_RUN_DIR}/model_dir'\n",
    "\n",
    "print(f\"EXPERIMENT_RUN_DIR: {EXPERIMENT_RUN_DIR}\")\n",
    "print(f\"MODEL_DIR: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4253ac00-f75f-4cd5-aacb-c5c5b3c8959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/candidate_embeddings/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/candidate_tower/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/query_tower/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309d8c62-c6f0-4d24-a400-b993f2c2a8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp -r $MODEL_DIR_old/candidate-embeddings $MODEL_DIR/candidate-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae9f29a0-21e7-4fec-957e-33b6c27195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp -r $MODEL_DIR_old/query-tower $MODEL_DIR/query-tower\n",
    "# !gsutil cp -r $MODEL_DIR_old/candidate-tower $MODEL_DIR/candidate-tower\n",
    "# !gsutil cp -r $MODEL_DIR_old/workflow $MODEL_DIR/workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3d84d-bb16-4d55-a8d3-0e2f5af774c2",
   "metadata": {},
   "source": [
    "### copy Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8acb93a-6776-4027-891a-beccf422007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/Dockerfile.mm-query-serve [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  862.0 B/  862.0 B]                                                \n",
      "Operation completed over 1 objects/862.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./src/Dockerfile.$SERVING_DOCKERNAME $EXPERIMENT_RUN_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4d265-24ff-4f2d-bbd3-7f2fc65ec00f",
   "metadata": {},
   "source": [
    "### copy serving application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a56eaf0f-591a-4d25-9fe4-67119f10f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/serving/app/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://./src/serving/app/dataset_to_tensors.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/serving/app/__init__.py [Content-Type=text/x-python]...    \n",
      "Copying file://./src/serving/app/instances.json [Content-Type=application/json]...\n",
      "Copying file://./src/serving/app/predictor.py [Content-Type=text/x-python]...   \n",
      "Copying file://./src/serving/app/main.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/serving/local_workflow/workflow/workflow.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/metadata.json [Content-Type=application/json]...\n",
      "Copying file://./src/serving/app/prestart.sh [Content-Type=text/x-sh]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_uri_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.collaborative.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_genres_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.album_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.name.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.track_uri_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_genres_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.artist_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.description_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying file://./src/serving/local_workflow/workflow/categories/unique.pid.parquet [Content-Type=application/octet-stream]...\n",
      "| [22/22 files][284.9 MiB/284.9 MiB] 100% Done                                  \n",
      "Operation completed over 22 objects/284.9 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR $EXPERIMENT_RUN_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283c95e-a6b4-4901-9bee-1840fd46e9f2",
   "metadata": {},
   "source": [
    "### copy workflow\n",
    "\n",
    "* easier for prediction container if a model's related workflow artifacts are stored in the `model_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "984d0b76-1bd8-4b68-8e8a-8f77638c8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKFLOW_DIR = \"gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "020ef708-19e5-45b1-b364-e2839318b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.album_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_genres_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_genres_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.artist_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.collaborative.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.description_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.name.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.pid.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_uri_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/categories/unique.track_uri_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/metadata.json [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-latest-12/nvt-processed/workflow/workflow.pkl [Content-Type=application/octet-stream]...\n",
      "/ [15/15 files][284.9 MiB/284.9 MiB] 100% Done                                  \n",
      "Operation completed over 15 objects/284.9 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r $WORKFLOW_DIR $EXPERIMENT_RUN_DIR/workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42b497b8-5134-49f7-8ee2-29184a0da60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/Dockerfile.mm-query-serve\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/logs/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/serving/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/workflow/\n"
     ]
    }
   ],
   "source": [
    "# check experiment run dir\n",
    "!gsutil ls $EXPERIMENT_RUN_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1511e95-c5d3-4ceb-b9a7-acdac2e317db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/candidate_embeddings/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/candidate_tower/\n",
      "gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/query_tower/\n"
     ]
    }
   ],
   "source": [
    "# check model_dir\n",
    "!gsutil ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83083194-47bd-470c-9d20-4449d1b48535",
   "metadata": {},
   "source": [
    "## Build Serving Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7b07c-13d9-41e8-aabe-25e9e32497a2",
   "metadata": {},
   "source": [
    "### gcloud ignore (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf6e5ff-e6e5-4870-9bdb-496a9d3f9bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [gcloudignore/enabled].\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set gcloudignore/enabled true\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6cb80ffb-1a10-4316-ac1b-be7e3595615a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting .gcloudignore\n"
     ]
    }
   ],
   "source": [
    "%%writefile .gcloudignore\n",
    ".gcloudignore\n",
    "/archive/\n",
    "/imgs/\n",
    "/mm_src/\n",
    "src/process_pipes/*\n",
    "src/preprocessor/*\n",
    "src/train_pipes/*\n",
    "src/trainer/*\n",
    "/local_workflow/*\n",
    "# *.json\n",
    "*.ipynb\n",
    ".git\n",
    ".github\n",
    ".ipynb_checkpoints/*\n",
    "*__pycache__\n",
    "*cpython-37.pyc\n",
    "README.md\n",
    "src/Dockerfile.triton-cpr\n",
    "src/Dockerfile.merlintf-22_12_v4\n",
    "src/Dockerfile.nvt\n",
    "src/Dockerfile.train\n",
    "src/Dockerfile.nvt-133\n",
    "Dockerfile\n",
    "/app/*\n",
    "src/Dockerfile.merlin-retriever\n",
    "custom_container_pipeline_spec.json\n",
    "nvt-parquet-full-1a100.json\n",
    "nvt-parquet-latest-12.json\n",
    "nvt-parquet-full-4t4.json\n",
    "nvt-parquet-full-2a100.json\n",
    "custom_pipeline_spec.json\n",
    ".cache\n",
    "merlin_last5_test_instance_v09.pkl\n",
    "spotipy_secret_creds.py\n",
    "merlin_last5_test_instance_v10.pkl\n",
    ".gitignore\n",
    "sp_utils.py\n",
    "merlin_last5_test_instance.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f21ea3a-6d26-45dc-8440-5742bb3f3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils/train_utils.py\n",
      "src/cloudbuild.yaml\n",
      "src/Dockerfile.mm-query-serve\n",
      "src/serving/app/requirements.txt\n",
      "src/serving/app/dataset_to_tensors.py\n",
      "src/serving/app/__init__.py\n",
      "src/serving/app/instances.json\n",
      "src/serving/app/predictor.py\n",
      "src/serving/app/main.py\n",
      "src/serving/app/prestart.sh\n",
      "src/serving/local_workflow/workflow/metadata.json\n",
      "src/serving/local_workflow/workflow/workflow.pkl\n",
      "src/serving/local_workflow/workflow/categories/unique.track_uri_pl.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.collaborative.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.track_name_can.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.artist_name_can.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.track_name_pl.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.track_uri_can.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.artist_genres_can.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.album_name_pl.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.name.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.description_pl.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.pid.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.artist_name_pl.parquet\n",
      "src/serving/local_workflow/workflow/categories/unique.artist_genres_pl.parquet\n"
     ]
    }
   ],
   "source": [
    "!gcloud meta list-files-for-upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5094bb7-6a37-483e-9689-bd0d885dd651",
   "metadata": {},
   "source": [
    "### submit to Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "114833f2-f22a-4657-93ba-e8c5b6f5a913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "SERVING_VERSION = 'v28'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29dd9ca3-6fb2-4030-80c4-42ebb256140c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_NAME: mm2t-vertex-serv-v28\n",
      "IMAGE_URI: gcr.io/hybrid-vertex/mm2t-vertex-serv-v28\n",
      "DOCKERNAME: mm-query-serve\n",
      "FILE_LOCATION: ./src\n",
      "MACHINE_TYPE: e2-highcpu-32\n"
     ]
    }
   ],
   "source": [
    "# Docker definitions for training\n",
    "IMAGE_NAME = f'mm2t-vertex-serv-{SERVING_VERSION}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "\n",
    "DOCKERNAME = f'{SERVING_DOCKERNAME}'\n",
    "MACHINE_TYPE ='e2-highcpu-32'\n",
    "FILE_LOCATION = './src'\n",
    "\n",
    "print(f\"IMAGE_NAME: {IMAGE_NAME}\")\n",
    "print(f\"IMAGE_URI: {IMAGE_URI}\")\n",
    "print(f\"DOCKERNAME: {DOCKERNAME}\")\n",
    "print(f\"FILE_LOCATION: {FILE_LOCATION}\")\n",
    "print(f\"MACHINE_TYPE: {MACHINE_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0db70f2c-99e8-477a-b7f7-e42fc5749137",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gcloud builds submit --config src/cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1ef4abf-d7eb-49f9-b7e5-c3ece91d2afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/hybrid-vertex/mm2t-vertex-serv-v28'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94bf61-afbc-4187-9460-251a37e67171",
   "metadata": {},
   "source": [
    "# Deploy Query Model to Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a9295-e707-4127-aa76-42ed7fc756a5",
   "metadata": {},
   "source": [
    "## Upload to Model Regsitry\n",
    "\n",
    "* `parent_model` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/models.py#L2831) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6123427d-ee45-4c3f-9f6c-5f8bb5331fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEPLOY_VERSION = \"v28\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b7aa0466-d49c-44df-b636-dd3035824a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_ARTIFACT_URI: gs://jt-merlin-scaling/mm-vertex-tf-2tower-jtv34/run-20230321-041554/model_dir/query_tower\n"
     ]
    }
   ],
   "source": [
    "MODEL_DISPLAY_NAME=f\"mm-qtower-{MODEL_DEPLOY_VERSION}\"\n",
    "MODEL_ARTIFACT_URI = f'{MODEL_DIR}/query_tower'\n",
    "\n",
    "print(f\"MODEL_ARTIFACT_URI: {MODEL_ARTIFACT_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2f1afd52-8bd6-49ed-ad8b-14bb470b850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing model resource\n",
    "# MODEL_URI = 'projects/934903580331/locations/us-central1/models/2330386307768909824@1'\n",
    "# MODEL_URI = \"projects/934903580331/locations/us-central1/models/3574305593713754112\" # 50 epoch\n",
    "# model = vertex_ai.Model(MODEL_URI)\n",
    "\n",
    "# vertex_ai.Model.delete(model)\n",
    "\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6114bfba-7b2c-41ef-9828-1cfebb33cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/3723194861277413376/operations/4253361569846525952\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/3723194861277413376@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/3723194861277413376@1')\n",
      "Created model in 0.11 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=MODEL_ARTIFACT_URI,\n",
    "        serving_container_image_uri=IMAGE_URI,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        # parent_model=PARENT_MODEL,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Created model in {round((end - start),2)} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c799802-643a-4650-be6f-3d670479af0a",
   "metadata": {},
   "source": [
    "## Deploy to Vertex AI Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d65883-ba63-4b6c-b128-73f7b7122075",
   "metadata": {},
   "source": [
    "### deployment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6a03fd66-72ed-40de-8dcc-c4eca468b142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPLOYED_MODEL_DISPLAY_NAME: nb-deployed-mm-qtower-v28\n",
      "ENDPOINT_DISPLAY_NAME: mm-endpoint-v28\n"
     ]
    }
   ],
   "source": [
    "# service account for predictions\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "# model and endpoint display names\n",
    "DEPLOYED_MODEL_DISPLAY_NAME=f\"nb-deployed-{MODEL_DISPLAY_NAME}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"mm-endpoint-{MODEL_DEPLOY_VERSION}\"\n",
    "\n",
    "traffic_percentage = 100\n",
    "machine_type = \"n1-highmem-16\"\n",
    "accelerator_type = \"NVIDIA_TESLA_T4\"\n",
    "accelerator_count = 1\n",
    "min_replica_count = 1\n",
    "max_replica_count = 1\n",
    "\n",
    "print(f\"DEPLOYED_MODEL_DISPLAY_NAME: {DEPLOYED_MODEL_DISPLAY_NAME}\")\n",
    "print(f\"ENDPOINT_DISPLAY_NAME: {ENDPOINT_DISPLAY_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc4d5d-20e8-4d25-9afa-820be25fdcbc",
   "metadata": {},
   "source": [
    "### create model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f128bfd9-5568-4a13-a5a6-725f2ff0bb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT_URI = 'projects/934903580331/locations/us-central1/endpoints/2071809760218316800'\n",
    "# endpoint = vertex_ai.Endpoint(ENDPOINT_URI)\n",
    "# vertex_ai.Endpoint.delete(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea1247f8-fe16-4e46-98c5-4bb7a79a846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/714467053775355904/operations/4123883080559624192\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/714467053775355904\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/714467053775355904')\n",
      "Created endpoint in 0.03 seconds\n",
      "\n",
      "<google.cloud.aiplatform.models.Endpoint object at 0x7f07ef26a3d0> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/714467053775355904\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=ENDPOINT_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Created endpoint in {round((end - start),2)} seconds\\n\")\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a28159-10dd-4ee9-adf6-5336c0edb496",
   "metadata": {},
   "source": [
    "### deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a8cec7c-7cbf-4b70-b7b6-b56cdafa5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/714467053775355904\n",
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/714467053775355904/operations/7913662166991896576\n",
      "Endpoint model deployed. Resource name: projects/934903580331/locations/us-central1/endpoints/714467053775355904\n",
      "Deployed model to endpoint in 0.22 seconds\n",
      "\n",
      "<google.cloud.aiplatform.models.Model object at 0x7f07725a6790> \n",
      "resource name: projects/934903580331/locations/us-central1/models/3723194861277413376\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=DEPLOYED_MODEL_DISPLAY_NAME,\n",
    "    machine_type=machine_type,\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    traffic_percentage=traffic_percentage,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    service_account=VERTEX_SA,\n",
    "    sync=True,\n",
    "    # deploy_request_timeout=1800\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Deployed model to endpoint in {round((end - start),2)} seconds\\n\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d36c9e-1d90-4c5c-9220-7fc824e42f73",
   "metadata": {},
   "source": [
    "#### check endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c32166d9-0ba4-4932-aefa-83d31f9d7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"7334107595126341632\"\n",
      "model: \"projects/934903580331/locations/us-central1/models/3723194861277413376\"\n",
      "display_name: \"nb-deployed-mm-qtower-v28\"\n",
      "create_time {\n",
      "  seconds: 1679382212\n",
      "  nanos: 208683000\n",
      "}\n",
      "dedicated_resources {\n",
      "  machine_spec {\n",
      "    machine_type: \"n1-highmem-16\"\n",
      "    accelerator_type: NVIDIA_TESLA_T4\n",
      "    accelerator_count: 1\n",
      "  }\n",
      "  min_replica_count: 1\n",
      "  max_replica_count: 1\n",
      "}\n",
      "service_account: \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "model_version_id: \"1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(endpoint.gca_resource.deployed_models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171104a3-490f-49bf-9662-2012efb35595",
   "metadata": {},
   "source": [
    "## Test Deployed Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edef10e-e2de-4073-bc19-132d3409e139",
   "metadata": {},
   "source": [
    "### Define endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57040e34-b61a-4b15-9dbb-d7930977da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENDPOINT_URI = 'projects/934903580331/locations/us-central1/endpoints/714467053775355904'\n",
    "# endpoint = vertex_ai.Endpoint(ENDPOINT_URI)\n",
    "\n",
    "# vertex_ai.Endpoint.delete(endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2355b042-0aff-4eec-b433-e6231b114fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"7334107595126341632\"\n",
      "model: \"projects/934903580331/locations/us-central1/models/3723194861277413376\"\n",
      "display_name: \"nb-deployed-mm-qtower-v28\"\n",
      "create_time {\n",
      "  seconds: 1679382212\n",
      "  nanos: 208683000\n",
      "}\n",
      "dedicated_resources {\n",
      "  machine_spec {\n",
      "    machine_type: \"n1-highmem-16\"\n",
      "    accelerator_type: NVIDIA_TESLA_T4\n",
      "    accelerator_count: 1\n",
      "  }\n",
      "  min_replica_count: 1\n",
      "  max_replica_count: 1\n",
      "}\n",
      "service_account: \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "model_version_id: \"1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(endpoint.gca_resource.deployed_models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73deb8-8987-4a18-beb3-c92c1bbbe956",
   "metadata": {},
   "source": [
    "### create sample test instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c85dffd9-b7d6-4cf2-a7e6-fc43b00dec70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collaborative': 'false',\n",
       " 'album_name_pl': [\"There's Really A Wolf\",\n",
       "  'Late Nights: The Album',\n",
       "  'American Teen',\n",
       "  'Crazy In Love',\n",
       "  'Pony'],\n",
       " 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
       "  \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
       "  \"'pop', 'pop r&b'\",\n",
       "  \"'dance pop', 'pop', 'r&b'\",\n",
       "  \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"],\n",
       " 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'BeyoncÃ©', 'William Singe'],\n",
       " 'artist_pop_can': 82.0,\n",
       " 'description_pl': '',\n",
       " 'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0],\n",
       " 'n_songs_pl': 8.0,\n",
       " 'name': 'Lit Tunes ',\n",
       " 'num_albums_pl': 8.0,\n",
       " 'num_artists_pl': 8.0,\n",
       " 'track_name_pl': ['Losin Control',\n",
       "  'Paradise',\n",
       "  'Location',\n",
       "  'Crazy In Love - Remix',\n",
       "  'Pony'],\n",
       " 'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
       " 'duration_ms_seed_pl': 51023.1,\n",
       " 'pid': 1,\n",
       " 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
       "  'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
       "  'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
       "  'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
       "  'spotify:track:4Lj8paMFwyKTGfILLELVxt']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "filehandler = open('merlin_last5_test_instance.pkl', 'rb')\n",
    "TEST_INSTANCE = pkl.load(filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "TEST_INSTANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290522-d95f-4043-b18d-52d3266d3ee4",
   "metadata": {},
   "source": [
    "### make prediction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7561c1c0-2be9-4ef1-b460-a3067eec6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dd721e42-3d13-4046-99f9-966cb50b28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query conversion: 2.782 seconds\n",
      "Vector Dimensions: 128\n",
      "\n",
      "embeddings: [[0.04306147247552872, 0.0, 0.1541330963373184, 0.02622287534177303, 0.03811377659440041, 0.01116169989109039, 0.0, 0.0, 0.04474653676152229, 0.0, 0.0, 0.0, 0.02140465378761292, 0.0, 0.0, 0.0, 0.001586958067491651, 0.0, 0.0222462136298418, 0.0830300822854042, 0.01280351355671883, 0.02744066342711449, 0.03303935006260872, 0.0, 0.0, 0.05789442732930183, 0.0, 0.0, 0.0, 0.02518848516047001, 0.1041594371199608, 0.1695009768009186, 0.01560135744512081, 0.0, 0.0, 0.0, 0.08916763216257095, 0.0, 0.0, 0.02710841223597527, 0.0, 0.04701695591211319, 0.0, 0.02980164624750614, 0.117186039686203, 0.0, 0.0, 0.0, 0.0, 0.07672543078660965, 0.0794282853603363, 0.0142751494422555, 0.0, 0.01396751310676336, 0.0, 0.01476635225117207, 0.005098144058138132, 0.007774507626891136, 0.0, 0.0, 0.004853374324738979, 0.0, 0.0, 0.02901207469403744, 0.01740282960236073, 0.04868501424789429, 0.1304978728294373, 0.0, 0.0, 0.0, 0.03922000154852867, 0.0009094009874388576, 0.0, 0.0, 0.0, 0.0, 0.01155873388051987, 0.03167691826820374, 0.0, 0.02460280805826187, 0.01587847992777824, 0.03023398481309414, 0.0, 0.01998442783951759, 0.0, 0.01020767260342836, 0.0343865193426609, 0.002592647913843393, 0.03698309510946274, 0.0, 0.02937860041856766, 0.01548787765204906, 0.0, 0.0, 0.1032155752182007, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.005453874357044697, 0.0, 0.0, 0.0373181514441967, 0.04472017288208008, 0.1223760843276978, 0.0, 0.01411030814051628, 0.06310773640871048, 0.03020548261702061, 0.0, 0.02766656316816807, 0.05945475026965141, 0.0, 0.0, 0.0325125977396965, 0.0, 0.02347051538527012, 0.0, 0.1096861734986305, 0.00733253825455904, 0.06217588856816292, 0.0, 0.01536395028233528, 0.0245197769254446]]\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "playlist_emb = endpoint.predict(instances=[TEST_INSTANCE])\n",
    "\n",
    "print(f\"query conversion: {round((time.time() - start),4)} seconds\")\n",
    "print(f\"Vector Dimensions: {len(playlist_emb.predictions[0])}\\n\")\n",
    "\n",
    "print(f\"embeddings: {playlist_emb.predictions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77980d4f-ec22-47db-9af9-05d6fb97dad0",
   "metadata": {},
   "source": [
    "### prediction latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a079e19-fcb2-4653-97a9-acf1d307e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535 ms ± 10.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c908c7c-545f-4145-9029-a9549ee288e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526 ms ± 11.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da54182-ca61-484b-b456-0f3058394f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.predict(instances=[[TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2896aa54-7050-4a7e-974c-4716fe77d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playlist_emb.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abb563-76bd-42ee-a7a8-64d8f7a2a8f0",
   "metadata": {},
   "source": [
    "## write test instance to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c16ec8b-c1fb-438d-aa43-1fdfed2a6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST_INSTANCE = {\n",
    "#     'collaborative': 'false',\n",
    "#     'album_name_pl': [\n",
    "#         \"There's Really A Wolf\", 'Late Nights: The Album','American Teen', 'Crazy In Love', 'Pony'\n",
    "#     ], \n",
    "#     'artist_genres_pl': [\n",
    "#         \"'hawaiian hip hop', 'rap'\",\n",
    "#        \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "#        \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "#        \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"\n",
    "#     ], \n",
    "#     'artist_name_pl': [\n",
    "#         'Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9','William Singe'\n",
    "#     ], \n",
    "#     'artist_pop_can': 82.0, \n",
    "#     'description_pl': '', \n",
    "#     'duration_ms_songs_pl': [\n",
    "#         237506.0, 217200.0, 219080.0, 226400.0, 121739.0\n",
    "#     ], \n",
    "#     'n_songs_pl': 8.0, \n",
    "#     'name': 'Lit Tunes ', \n",
    "#     'num_albums_pl': 8.0, \n",
    "#     'num_artists_pl': 8.0, \n",
    "#     'track_name_pl': [\n",
    "#         'Losin Control', 'Paradise', 'Location','Crazy In Love - Remix', 'Pony'\n",
    "#     ], \n",
    "#     'track_pop_pl': [\n",
    "#         79.0, 58.0, 83.0, 71.0, 57.0\n",
    "#     ],\n",
    "#     'duration_ms_seed_pl': 51023.1,\n",
    "#     'pid': 1,\n",
    "#     'track_uri_pl': [\n",
    "#         'spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "#         'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "#         'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "#         'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "#         'spotify:track:4Lj8paMFwyKTGfILLELVxt'\n",
    "#     ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2bbaa69c-e7fd-4dac-994f-d6efb7da145e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle as pkl\n",
    "\n",
    "# LOCAL_INSTANCE_FILE = 'merlin_last5_test_instance.pkl'\n",
    "\n",
    "# filehandler = open(LOCAL_INSTANCE_FILE, 'wb')\n",
    "# pkl.dump(TEST_INSTANCE, filehandler)\n",
    "# filehandler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "690e14d1-4c37-40d4-ac8f-f653dc01d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp $LOCAL_INSTANCE_FILE gs://BUCKET/PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df2f8c-9ce9-49ca-abbc-b27ae6b5490a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
