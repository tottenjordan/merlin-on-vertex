{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc27ca62-e310-4139-b3bb-3a0cba5d58ef",
   "metadata": {},
   "source": [
    "# Deploying Merlin Query Tower with Vertex AI\n",
    "\n",
    "* Create custom prediction routine (CPR)\n",
    "* Upload query model to Vertex AI Model Registry\n",
    "* Test registered models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "bb336ccc-239a-4f43-8fc5-318a31dd0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "import os\n",
    "\n",
    "PROJECT_ID = 'hybrid-vertex'             \n",
    "LOCATION = 'us-central1' \n",
    "BUCKET = 'jt-merlin-scaling'\n",
    "BUCKET_URI = 'gs://jt-merlin-scaling'\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)\n",
    "# !gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "15b8b6e4-0426-49f9-82ca-8e7cf5ea07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce275cb8-05ba-4daf-9cfc-2a2d8ab4f591",
   "metadata": {},
   "source": [
    "## Build serving container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3a28ef83-b05b-4b4c-9694-59d5b64e2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "SERVING_SUB_DIR = 'serving'\n",
    "SERVING_APPLICATION_DIR = 'app'\n",
    "SERVING_DOCKERNAME = 'merlin-retriever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "734aea8d-6367-4bcd-9ce2-e8025ac17475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training subfolder\n",
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}\n",
    "! touch {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c1711-1b15-4df1-8ec1-b919e25eddaa",
   "metadata": {},
   "source": [
    "nvtabular==1.3.3 (for prediction only per ronnay AK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "308c947c-1bdf-42ea-96aa-0bb897bd9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "uvloop==0.15.2\n",
    "fastapi-utils\n",
    "google-cloud-aiplatform\n",
    "git+https://github.com/NVIDIA-Merlin/models.git\n",
    "nvtabular==1.3.3\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "141ef566-1582-433b-a5c6-e6ad41c8e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/predictor.py\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "\n",
    "\n",
    "# These are helper functions that ensure the dictionary input is in a certain order and types are preserved\n",
    "# this is to get scalar values to appear first in the dict to not confuse pandas with lists https://github.com/pandas-dev/pandas/issues/46092\n",
    "reordered_keys = [\n",
    "    'collaborative', \n",
    "    'album_name_pl', \n",
    "    'artist_genres_pl', \n",
    "    'artist_name_pl', \n",
    "    'artist_pop_can', \n",
    "    'description_pl', \n",
    "    'duration_ms_songs_pl', \n",
    "    'n_songs_pl', 'name', \n",
    "    'num_albums_pl', \n",
    "    'num_artists_pl', \n",
    "    'track_name_pl', \n",
    "    'track_pop_pl', \n",
    "    'duration_ms_seed_pl', \n",
    "    'pid', \n",
    "    'track_uri_pl'\n",
    "]\n",
    "\n",
    "float_num_fix = ['n_songs_pl','num_albums_pl','num_artists_pl','duration_ms_seed_pl']\n",
    "float_list_fix = ['track_pop_pl', 'duration_ms_songs_pl']\n",
    "    \n",
    "def fix_list_num_dtypes(num_list):\n",
    "    \"this fixes lists of ints to list of floats converted in json input\"\n",
    "    return [float(x) for x in num_list]\n",
    "\n",
    "def fix_num_dtypes(num):\n",
    "    \"this fixes ints and casts to floats\"\n",
    "    return float(num)\n",
    "\n",
    "def fix_types(k, v):\n",
    "    if k in float_num_fix:\n",
    "        return fix_num_dtypes(v)\n",
    "    if k in float_list_fix:\n",
    "        return fix_list_num_dtypes(v)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def create_pandas_instance(inputs):\n",
    "    \"\"\"\n",
    "    Helper function to reorder the input to have a sclar first for pandas\n",
    "    And fix the types converted when data is imported by fastAPI\n",
    "    \"\"\"\n",
    "    if type(inputs) == list:\n",
    "        header = inputs[0]\n",
    "        reordered_header_dict = {k: fix_types(k,header[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_header_dict, orient='index').T\n",
    "        if len(inputs) > 1:\n",
    "            for ti in inputs[1:]:\n",
    "                reordered_dict = {k: fix_types(k,ti[k]) for k in reordered_keys}\n",
    "                pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(reordered_dict, orient='index').T)\n",
    "    else:\n",
    "        reordered_dict = {k: fix_types(k,inputs[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_dict, orient='index').T\n",
    "    return pandas_instance\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        logging.info(\"loading model and workflow\")\n",
    "        start = time.process_time()\n",
    "        \n",
    "        test_bucket = 'gs://jt-merlin-scaling'\n",
    "        self.model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query-tower\"))\n",
    "        # self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\")) # TODO: parameterize\n",
    "        self.workflow = nvt.Workflow.load(os.path.join(test_bucket, \"nvt-last5-v1full/nvt-analyzed\"))\n",
    "        # self.workflow = nvt.Workflow.load('gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed') # TODO: parametrize\n",
    "        self.workflow = self.workflow.remove_inputs(\n",
    "            [\n",
    "                'track_pop_can', \n",
    "                'track_uri_can', \n",
    "                'duration_ms_can', \n",
    "                'track_name_can', \n",
    "                'artist_name_can',\n",
    "                'album_name_can',\n",
    "                'album_uri_can',\n",
    "                'artist_followers_can', \n",
    "                'artist_genres_can',\n",
    "                'artist_name_can', \n",
    "                'artist_pop_can',\n",
    "                'artist_pop_pl',\n",
    "                'artist_uri_can', \n",
    "                'artists_followers_pl'\n",
    "            ]\n",
    "        )\n",
    "        # self.model = tf.keras.models.load_model(os.path.join(artifacts_uri, \"query_model_merlin\" ))\n",
    "        # self.workflow = nvt.Workflow.load(os.path.join(artifacts_uri, \"workflow/2t-spotify-workflow\"))\n",
    "        # self.workflow = self.workflow.remove_inputs(['track_pop_can', 'track_uri_can', 'duration_ms_can', \n",
    "        #                               'track_name_can', 'artist_name_can','album_name_can',\n",
    "        #                               'album_uri_can','artist_followers_can', 'artist_genres_can',\n",
    "        #                               'artist_name_can', 'artist_pop_can','artist_pop_pl','artist_uri_can', \n",
    "        #                               'artists_followers_pl']) \n",
    "        self.loader = None # will load this after first load\n",
    "        self.n_rows = 0\n",
    "        logging.info(f\"loading took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        # handle different input types, can take a dict or list of dicts\n",
    "        self.n_rows = len(prediction_input)\n",
    "        start = time.process_time()\n",
    "        pandas_instance = create_pandas_instance(prediction_input[0])\n",
    "        logging.info(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        logging.info(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        logging.info(f\"Workflow transformation took {time.process_time() - start} seconds\")\n",
    "        # return transformed_instance\n",
    "\n",
    "    # def predict(self, instances):\n",
    "        \"\"\"Performs prediction.\n",
    "        Args:\n",
    "            instances (Any):\n",
    "                Required. The instance(s) used for performing prediction.\n",
    "        Returns:\n",
    "            Prediction results.\n",
    "        \"\"\"  \n",
    "        # if self.loader is None:\n",
    "        start = time.process_time()\n",
    "        # if self.loader is None:\n",
    "        #     self.loader = mm.Loader(transformed_instance, batch_size=1, shuffle=False)\n",
    "        #     logging.info(f\"Dataloader creation took {time.process_time() - start} seconds\")\n",
    "        # else:\n",
    "        #     self.loader.data = transformed_instance #this is faster we don't want tokeep loading dataloder\n",
    "        #     logging.info(f\"Dataloader creation took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        batch = mm.sample_batch(transformed_instance, batch_size=1, include_targets=False, shuffle=False)\n",
    "        logging.info(f\"TF Dataloader took {time.process_time() - start} seconds\")\n",
    "        start = time.process_time()\n",
    "        output = self.model(batch)\n",
    "        logging.info(f\"Prediction took {time.process_time() - start} seconds\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9af6931b-0fe1-43b1-a14e-85b8fa0ef862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from fastapi_utils.timing import add_timing_middleware, record_timing\n",
    "\n",
    "from google.cloud import storage\n",
    "from .predictor import Predictor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "app = FastAPI()\n",
    "add_timing_middleware(app, record=logger.info, prefix=\"app\", exclude=\"untimed\")\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    outputs = loaded_predictor.predict(instances)\n",
    "    # outputs = loaded_predictor.predict(preprocessed_inputs)\n",
    "\n",
    "    return {\"predictions\": outputs.numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6e5eb243-8407-4f90-a070-749038288fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f71121ab-b4d8-40de-8c72-022fd97878bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \"artist_followers_can\": 4339757.0, \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_can\": \"Russ\", \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \"description_pl\": \"\", \"duration_ms_can\": 237322.0, \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_can\": \"We Just Havent Met Yet\", \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1147891d-0d39-4ad6-8466-da0ad292d511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/merlin-on-vertex\n",
      "\u001b[01;34m/home/jupyter/merlin-on-vertex\u001b[00m\n",
      "├── 01-data-preprocess-pipeline.ipynb\n",
      "├── 02-merlin-vertex-training.ipynb\n",
      "├── 03-query-model-inference.ipynb\n",
      "├── 04-train-deploy-pipeline.ipynb\n",
      "├── README.md\n",
      "├── \u001b[01;34marchive\u001b[00m\n",
      "│   └── archived-merlin-start.ipynb\n",
      "├── custom_container_pipeline_spec.json\n",
      "└── \u001b[01;34msrc\u001b[00m\n",
      "    ├── Dockerfile.merlin-retriever\n",
      "    ├── Dockerfile.merlintf-22_09\n",
      "    ├── Dockerfile.merlintf-22_09_v2\n",
      "    ├── Dockerfile.triton-cpr\n",
      "    ├── cloudbuild.yaml\n",
      "    ├── \u001b[01;34mpipes\u001b[00m\n",
      "    │   ├── config.py\n",
      "    │   ├── pipe_components.py\n",
      "    │   └── preproc_pipelines.py\n",
      "    ├── \u001b[01;34mpreprocessor\u001b[00m\n",
      "    │   ├── __init__,py\n",
      "    │   └── preprocess_task.py\n",
      "    ├── \u001b[01;34mserving\u001b[00m\n",
      "    │   ├── \u001b[01;34mapp\u001b[00m\n",
      "    │   │   ├── __init__.py\n",
      "    │   │   ├── main.py\n",
      "    │   │   ├── predictor.py\n",
      "    │   │   └── prestart.sh\n",
      "    │   ├── instances.json\n",
      "    │   └── requirements.txt\n",
      "    ├── \u001b[01;34mtrain_pipes\u001b[00m\n",
      "    │   ├── build_custom_image.py\n",
      "    │   ├── create_ann_index.py\n",
      "    │   ├── create_ann_index_endpoint_vpc.py\n",
      "    │   ├── create_brute_force_index.py\n",
      "    │   ├── create_brute_index_endpoint_vpc.py\n",
      "    │   ├── deploy_ann_index.py\n",
      "    │   ├── deploy_brute_index.py\n",
      "    │   ├── train_merlin.py\n",
      "    │   └── upload_custom_model.py\n",
      "    └── \u001b[01;34mtrainer\u001b[00m\n",
      "        ├── __init__.py\n",
      "        ├── interactive_train.py\n",
      "        ├── train_task.py\n",
      "        └── two_tower_model.py\n",
      "\n",
      "8 directories, 36 files\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "!tree /home/jupyter/merlin-on-vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f9837b4-c739-4671-9ca6-df71fb590404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/Dockerfile.merlin-retriever\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
    "\n",
    "WORKDIR / \n",
    "\n",
    "# COPY /src/serving/requirements.txt /requirements.txt\n",
    "# COPY ./src/serving/requirements.txt /requirements.txt\n",
    "COPY /serving/requirements.txt /requirements.txt\n",
    "\n",
    "RUN pip install -r /requirements.txt\n",
    "\n",
    "# COPY /src/serving/app /app\n",
    "# COPY ./src/serving/app /app\n",
    "COPY /serving/app /app\n",
    "\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bede56-9349-47b8-8149-ad4daf0487c0",
   "metadata": {},
   "source": [
    "## Copy serving app to GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3bf920-f453-4538-b401-6b6ea9069a74",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "> currently getting gsutil auth issues.. refactor this section with `gsutil -cp ...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "28005617-3219-4810-9be6-2b2960365dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = 'gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4253ac00-f75f-4cd5-aacb-c5c5b3c8959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/\n",
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/Dockerfile.merlin-retriever\n",
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/candidate-embeddings/\n",
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/candidate-tower/\n",
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/query-tower/\n",
      "gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v6-20221108-210323/model-dir/serving/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c8acb93a-6776-4027-891a-beccf422007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/Dockerfile.merlin-retriever [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  440.0 B/  440.0 B]                                                \n",
      "Operation completed over 1 objects/440.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./src/Dockerfile.$SERVING_DOCKERNAME $MODEL_DIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a56eaf0f-591a-4d25-9fe4-67119f10f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/serving/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://./src/serving/app/__init__.py [Content-Type=text/x-python]...    \n",
      "Copying file://./src/serving/instances.json [Content-Type=application/json]...\n",
      "Copying file://./src/serving/app/predictor.py [Content-Type=text/x-python]...   \n",
      "Copying file://./src/serving/app/main.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/serving/app/prestart.sh [Content-Type=text/x-sh]...        \n",
      "/ [6/6 files][  9.9 KiB/  9.9 KiB] 100% Done                                    \n",
      "Operation completed over 6 objects/9.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR $MODEL_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d3cda0-7796-4d01-a4f9-3aeb3db4c035",
   "metadata": {
    "tags": []
   },
   "source": [
    "### delete these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "01cca067-f87e-4255-bb65-24036da1ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !gcloud auth login\n",
    "\n",
    "# from google.cloud import storage\n",
    "# from google.cloud.storage.bucket import Bucket\n",
    "# from google.cloud.storage.blob import Blob\n",
    "\n",
    "# def _upload_blob_gcs(gcs_uri, source_file_name, destination_blob_name, project):\n",
    "#     \"\"\"Uploads a file to GCS bucket\"\"\"\n",
    "#     client = storage.Client(project=project)\n",
    "#     blob = Blob.from_string(os.path.join(gcs_uri, destination_blob_name))\n",
    "#     blob.bucket._client = client\n",
    "#     blob.upload_from_filename(source_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "43338dbe-28e8-4a2a-925a-efcbafb35375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL_FILENAME_docker = f'{REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}'\n",
    "# LOCAL_FILENAME_main = f'{REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/main.py'\n",
    "# LOCAL_FILENAME_predictor = f'{REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/predictor.py'\n",
    "# LOCAL_FILENAME_prestart = f'{REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/prestart.sh'\n",
    "# LOCAL_FILENAME_reqs = f'{REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/requirements.txt'\n",
    "\n",
    "# GCS_MODEL_DIR_PATH = 'test-2tower-merlin-tf-jtv1/run-v5-20221108-163948/model-dir'\n",
    "# GCS_SERVING_DIR_PATH = f'{GCS_MODEL_DIR_PATH}/serving'\n",
    "\n",
    "# DESTINATION_FILENAME_docker = f'{GCS_SERVING_DIR_PATH}/Dockerfile.{SERVING_DOCKERNAME}'\n",
    "# DESTINATION_FILENAME_main = f'{GCS_SERVING_DIR_PATH}/app/main.py'\n",
    "# DESTINATION_FILENAME_predictor = f'{GCS_SERVING_DIR_PATH}/app/predictor.py'\n",
    "# DESTINATION_FILENAME_prestart = f'{GCS_SERVING_DIR_PATH}/app/prestart.sh'\n",
    "# DESTINATION_FILENAME_reqs = f'{GCS_SERVING_DIR_PATH}/app/requirements.txt'\n",
    "\n",
    "# # print(f\"LOCAL_FILENAME_docker : {LOCAL_FILENAME_docker}\")\n",
    "# # print(f\"LOCAL_FILENAME_main : {LOCAL_FILENAME_main}\")\n",
    "# # print(f\"LOCAL_FILENAME_predictor : {LOCAL_FILENAME_predictor}\")\n",
    "# # print(f\"LOCAL_FILENAME_prestart : {LOCAL_FILENAME_prestart}\")\n",
    "# # print(f\"LOCAL_FILENAME_reqs : {LOCAL_FILENAME_reqs}\\n\")\n",
    "# print(f\"GCS_MODEL_DIR_PATH : {GCS_MODEL_DIR_PATH}\\n\")\n",
    "# print(f\"DESTINATION_FILENAME_docker : {DESTINATION_FILENAME_docker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7096c584-c535-4e01-896f-e54d64a0fc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _upload_blob_gcs(BUCKET_URI, LOCAL_FILENAME_docker,DESTINATION_FILENAME_docker, PROJECT_ID)\n",
    "# _upload_blob_gcs(BUCKET_URI, LOCAL_FILENAME_main,DESTINATION_FILENAME_main, PROJECT_ID)\n",
    "# _upload_blob_gcs(BUCKET_URI, LOCAL_FILENAME_predictor,DESTINATION_FILENAME_predictor, PROJECT_ID)\n",
    "# _upload_blob_gcs(BUCKET_URI, LOCAL_FILENAME_prestart,DESTINATION_FILENAME_prestart, PROJECT_ID)\n",
    "# _upload_blob_gcs(BUCKET_URI, LOCAL_FILENAME_reqs,DESTINATION_FILENAME_reqs, PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c5570653-f80f-4e88-a0cb-9574d84e65c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil ls gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v5-20221108-163948/model-dir/serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83083194-47bd-470c-9d20-4449d1b48535",
   "metadata": {},
   "source": [
    "### Build Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "eb87a7c4-be26-4004-902e-3732fc684bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker definitions for training\n",
    "SERVING_VERSION = 'v6'\n",
    "IMAGE_NAME = f'merlin-triton-serving-{SERVING_VERSION}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "\n",
    "DOCKERNAME = f'{SERVING_DOCKERNAME}'\n",
    "MACHINE_TYPE ='e2-highcpu-32'\n",
    "FILE_LOCATION = './src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "367f6be9-c179-4d74-84d6-6ce1d8af0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE_LOCATION = './src'\n",
    "# ! gcloud builds submit --config src/cloudbuild.yaml --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION --timeout=2h --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0db70f2c-99e8-477a-b7f7-e42fc5749137",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 40 file(s) totalling 1.1 MiB before compression.\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1668026173.08763-f1cbda98a6584b2d9b65b0886c42caab.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/2681eb09-22d5-4727-8e70-503dcc2365e6].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/2681eb09-22d5-4727-8e70-503dcc2365e6?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"2681eb09-22d5-4727-8e70-503dcc2365e6\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1668026173.08763-f1cbda98a6584b2d9b65b0886c42caab.tgz#1668026173582399\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1668026173.08763-f1cbda98a6584b2d9b65b0886c42caab.tgz#1668026173582399...\n",
      "/ [1 files][198.7 KiB/198.7 KiB]                                                \n",
      "Operation completed over 1 objects/198.7 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  118.8kB\n",
      "Step 1/7 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      "22.09: Pulling from nvidia/merlin/merlin-tensorflow\n",
      "3b65ec22a9e9: Pulling fs layer\n",
      "fd80d866e8b2: Pulling fs layer\n",
      "a364ca75fd6d: Pulling fs layer\n",
      "3d4731d03623: Pulling fs layer\n",
      "53a5c2e0251f: Pulling fs layer\n",
      "b00ff40d02d9: Pulling fs layer\n",
      "3036e9b94123: Pulling fs layer\n",
      "453fdcdda788: Pulling fs layer\n",
      "35e12ec5e515: Pulling fs layer\n",
      "11f61a475a23: Pulling fs layer\n",
      "24280cf31c9a: Pulling fs layer\n",
      "79007799e2ed: Pulling fs layer\n",
      "03eb76abf1e5: Pulling fs layer\n",
      "53a5c2e0251f: Waiting\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "b00ff40d02d9: Waiting\n",
      "5e9434e8ae41: Pulling fs layer\n",
      "3036e9b94123: Waiting\n",
      "88a3e778b5bf: Pulling fs layer\n",
      "729af2b35d14: Pulling fs layer\n",
      "453fdcdda788: Waiting\n",
      "30e0a3a7e9e5: Pulling fs layer\n",
      "11f61a475a23: Waiting\n",
      "0852b4bd65a1: Pulling fs layer\n",
      "35e12ec5e515: Waiting\n",
      "81cb421c2c25: Pulling fs layer\n",
      "79007799e2ed: Waiting\n",
      "24280cf31c9a: Waiting\n",
      "3d4731d03623: Waiting\n",
      "30e0a3a7e9e5: Waiting\n",
      "3d6b664afa23: Pulling fs layer\n",
      "3e8f37aba8a2: Pulling fs layer\n",
      "0852b4bd65a1: Waiting\n",
      "91bba9bd0f1f: Pulling fs layer\n",
      "a422be4dcb08: Pulling fs layer\n",
      "03eb76abf1e5: Waiting\n",
      "81cb421c2c25: Waiting\n",
      "88a3e778b5bf: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "ca10bb6dc143: Pulling fs layer\n",
      "3d6b664afa23: Waiting\n",
      "e48bbfc7d00e: Pulling fs layer\n",
      "3e8f37aba8a2: Waiting\n",
      "860a23551ac0: Pulling fs layer\n",
      "5e9434e8ae41: Waiting\n",
      "cc78be876588: Pulling fs layer\n",
      "ad6568ad37e5: Pulling fs layer\n",
      "91bba9bd0f1f: Waiting\n",
      "258a31babfce: Pulling fs layer\n",
      "116ca0069c88: Pulling fs layer\n",
      "ede4a5022f61: Pulling fs layer\n",
      "ca10bb6dc143: Waiting\n",
      "154d6414dd17: Pulling fs layer\n",
      "e1f68d1c5137: Pulling fs layer\n",
      "0d4b5cd36c43: Pulling fs layer\n",
      "fc9b6547dc7c: Pulling fs layer\n",
      "de51b5b1b318: Pulling fs layer\n",
      "e48bbfc7d00e: Waiting\n",
      "d684c579871f: Pulling fs layer\n",
      "4a39f6623824: Pulling fs layer\n",
      "30bba30584e3: Pulling fs layer\n",
      "860a23551ac0: Waiting\n",
      "a422be4dcb08: Waiting\n",
      "c104fa3a7626: Pulling fs layer\n",
      "22f09e497c63: Pulling fs layer\n",
      "0d4b5cd36c43: Waiting\n",
      "5f66cd739f31: Pulling fs layer\n",
      "c9c9a9e1cad6: Pulling fs layer\n",
      "630fcaa7a158: Pulling fs layer\n",
      "1b8090778700: Pulling fs layer\n",
      "ad6568ad37e5: Waiting\n",
      "fc9b6547dc7c: Waiting\n",
      "4ca3cacea924: Pulling fs layer\n",
      "154d6414dd17: Waiting\n",
      "de51b5b1b318: Waiting\n",
      "258a31babfce: Waiting\n",
      "4aa043daa566: Pulling fs layer\n",
      "c1d86dc35ba1: Pulling fs layer\n",
      "55f4be7d7adc: Pulling fs layer\n",
      "116ca0069c88: Waiting\n",
      "f8e1ddeececb: Pulling fs layer\n",
      "c104fa3a7626: Waiting\n",
      "4a39f6623824: Waiting\n",
      "30bba30584e3: Waiting\n",
      "bf1f5a5d15b8: Pulling fs layer\n",
      "ede4a5022f61: Waiting\n",
      "68d63385def6: Pulling fs layer\n",
      "865f53eecc40: Pulling fs layer\n",
      "4aa043daa566: Waiting\n",
      "70ac11bbf381: Pulling fs layer\n",
      "f8e1ddeececb: Waiting\n",
      "55f4be7d7adc: Waiting\n",
      "91a761249212: Pulling fs layer\n",
      "2cb953eac694: Pulling fs layer\n",
      "c1d86dc35ba1: Waiting\n",
      "5f66cd739f31: Waiting\n",
      "2e6386dccac0: Pulling fs layer\n",
      "67793606273a: Pulling fs layer\n",
      "bfdaa5a6754f: Pulling fs layer\n",
      "1b8090778700: Waiting\n",
      "3e0d0b3b5c1c: Pulling fs layer\n",
      "bf1f5a5d15b8: Waiting\n",
      "8d6d2c98840c: Pulling fs layer\n",
      "68d63385def6: Waiting\n",
      "2559630e37d2: Pulling fs layer\n",
      "d0f13d58f7fa: Pulling fs layer\n",
      "929ce3ad5dc9: Pulling fs layer\n",
      "4ca3cacea924: Waiting\n",
      "7a42c1978b2e: Pulling fs layer\n",
      "c9c9a9e1cad6: Waiting\n",
      "630fcaa7a158: Waiting\n",
      "91a761249212: Waiting\n",
      "bfdaa5a6754f: Waiting\n",
      "3e0d0b3b5c1c: Waiting\n",
      "2e6386dccac0: Waiting\n",
      "67793606273a: Waiting\n",
      "865f53eecc40: Waiting\n",
      "7a42c1978b2e: Waiting\n",
      "8d6d2c98840c: Waiting\n",
      "929ce3ad5dc9: Waiting\n",
      "2559630e37d2: Waiting\n",
      "d0f13d58f7fa: Waiting\n",
      "cc78be876588: Waiting\n",
      "2cb953eac694: Waiting\n",
      "3b65ec22a9e9: Verifying Checksum\n",
      "3b65ec22a9e9: Download complete\n",
      "3d4731d03623: Verifying Checksum\n",
      "3d4731d03623: Download complete\n",
      "fd80d866e8b2: Verifying Checksum\n",
      "fd80d866e8b2: Download complete\n",
      "a364ca75fd6d: Verifying Checksum\n",
      "a364ca75fd6d: Download complete\n",
      "b00ff40d02d9: Verifying Checksum\n",
      "b00ff40d02d9: Download complete\n",
      "3036e9b94123: Download complete\n",
      "453fdcdda788: Verifying Checksum\n",
      "453fdcdda788: Download complete\n",
      "35e12ec5e515: Verifying Checksum\n",
      "35e12ec5e515: Download complete\n",
      "3b65ec22a9e9: Pull complete\n",
      "11f61a475a23: Verifying Checksum\n",
      "11f61a475a23: Download complete\n",
      "79007799e2ed: Download complete\n",
      "24280cf31c9a: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "5e9434e8ae41: Verifying Checksum\n",
      "5e9434e8ae41: Download complete\n",
      "88a3e778b5bf: Verifying Checksum\n",
      "88a3e778b5bf: Download complete\n",
      "729af2b35d14: Verifying Checksum\n",
      "729af2b35d14: Download complete\n",
      "03eb76abf1e5: Verifying Checksum\n",
      "03eb76abf1e5: Download complete\n",
      "fd80d866e8b2: Pull complete\n",
      "0852b4bd65a1: Verifying Checksum\n",
      "0852b4bd65a1: Download complete\n",
      "81cb421c2c25: Verifying Checksum\n",
      "81cb421c2c25: Download complete\n",
      "3d6b664afa23: Verifying Checksum\n",
      "3d6b664afa23: Download complete\n",
      "30e0a3a7e9e5: Verifying Checksum\n",
      "30e0a3a7e9e5: Download complete\n",
      "a364ca75fd6d: Pull complete\n",
      "3d4731d03623: Pull complete\n",
      "91bba9bd0f1f: Verifying Checksum\n",
      "91bba9bd0f1f: Download complete\n",
      "a422be4dcb08: Verifying Checksum\n",
      "a422be4dcb08: Download complete\n",
      "ca10bb6dc143: Verifying Checksum\n",
      "ca10bb6dc143: Download complete\n",
      "e48bbfc7d00e: Verifying Checksum\n",
      "e48bbfc7d00e: Download complete\n",
      "860a23551ac0: Verifying Checksum\n",
      "860a23551ac0: Download complete\n",
      "cc78be876588: Verifying Checksum\n",
      "cc78be876588: Download complete\n",
      "ad6568ad37e5: Verifying Checksum\n",
      "ad6568ad37e5: Download complete\n",
      "258a31babfce: Verifying Checksum\n",
      "258a31babfce: Download complete\n",
      "116ca0069c88: Verifying Checksum\n",
      "116ca0069c88: Download complete\n",
      "ede4a5022f61: Verifying Checksum\n",
      "ede4a5022f61: Download complete\n",
      "154d6414dd17: Verifying Checksum\n",
      "154d6414dd17: Download complete\n",
      "e1f68d1c5137: Verifying Checksum\n",
      "e1f68d1c5137: Download complete\n",
      "0d4b5cd36c43: Verifying Checksum\n",
      "0d4b5cd36c43: Download complete\n",
      "fc9b6547dc7c: Verifying Checksum\n",
      "fc9b6547dc7c: Download complete\n",
      "53a5c2e0251f: Verifying Checksum\n",
      "53a5c2e0251f: Download complete\n",
      "3e8f37aba8a2: Verifying Checksum\n",
      "3e8f37aba8a2: Download complete\n",
      "4a39f6623824: Verifying Checksum\n",
      "4a39f6623824: Download complete\n",
      "30bba30584e3: Verifying Checksum\n",
      "30bba30584e3: Download complete\n",
      "c104fa3a7626: Verifying Checksum\n",
      "c104fa3a7626: Download complete\n",
      "22f09e497c63: Download complete\n",
      "5f66cd739f31: Verifying Checksum\n",
      "5f66cd739f31: Download complete\n",
      "c9c9a9e1cad6: Download complete\n",
      "630fcaa7a158: Verifying Checksum\n",
      "630fcaa7a158: Download complete\n",
      "d684c579871f: Verifying Checksum\n",
      "d684c579871f: Download complete\n",
      "1b8090778700: Verifying Checksum\n",
      "1b8090778700: Download complete\n",
      "4ca3cacea924: Download complete\n",
      "de51b5b1b318: Verifying Checksum\n",
      "de51b5b1b318: Download complete\n",
      "c1d86dc35ba1: Verifying Checksum\n",
      "c1d86dc35ba1: Download complete\n",
      "4aa043daa566: Verifying Checksum\n",
      "4aa043daa566: Download complete\n",
      "55f4be7d7adc: Verifying Checksum\n",
      "55f4be7d7adc: Download complete\n",
      "bf1f5a5d15b8: Verifying Checksum\n",
      "bf1f5a5d15b8: Download complete\n",
      "f8e1ddeececb: Verifying Checksum\n",
      "f8e1ddeececb: Download complete\n",
      "68d63385def6: Verifying Checksum\n",
      "68d63385def6: Download complete\n",
      "865f53eecc40: Verifying Checksum\n",
      "865f53eecc40: Download complete\n",
      "70ac11bbf381: Verifying Checksum\n",
      "70ac11bbf381: Download complete\n",
      "2e6386dccac0: Verifying Checksum\n",
      "2e6386dccac0: Download complete\n",
      "67793606273a: Download complete\n",
      "bfdaa5a6754f: Verifying Checksum\n",
      "bfdaa5a6754f: Download complete\n",
      "3e0d0b3b5c1c: Verifying Checksum\n",
      "3e0d0b3b5c1c: Download complete\n",
      "8d6d2c98840c: Verifying Checksum\n",
      "8d6d2c98840c: Download complete\n",
      "2559630e37d2: Verifying Checksum\n",
      "2559630e37d2: Download complete\n",
      "91a761249212: Verifying Checksum\n",
      "91a761249212: Download complete\n",
      "d0f13d58f7fa: Verifying Checksum\n",
      "d0f13d58f7fa: Download complete\n",
      "7a42c1978b2e: Verifying Checksum\n",
      "7a42c1978b2e: Download complete\n",
      "2cb953eac694: Verifying Checksum\n",
      "2cb953eac694: Download complete\n",
      "929ce3ad5dc9: Verifying Checksum\n",
      "929ce3ad5dc9: Download complete\n",
      "53a5c2e0251f: Pull complete\n",
      "b00ff40d02d9: Pull complete\n",
      "3036e9b94123: Pull complete\n",
      "453fdcdda788: Pull complete\n",
      "35e12ec5e515: Pull complete\n",
      "11f61a475a23: Pull complete\n",
      "24280cf31c9a: Pull complete\n",
      "79007799e2ed: Pull complete\n",
      "03eb76abf1e5: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "5e9434e8ae41: Pull complete\n",
      "88a3e778b5bf: Pull complete\n",
      "729af2b35d14: Pull complete\n",
      "30e0a3a7e9e5: Pull complete\n",
      "0852b4bd65a1: Pull complete\n",
      "81cb421c2c25: Pull complete\n",
      "3d6b664afa23: Pull complete\n",
      "3e8f37aba8a2: Pull complete\n",
      "91bba9bd0f1f: Pull complete\n",
      "a422be4dcb08: Pull complete\n",
      "ca10bb6dc143: Pull complete\n",
      "e48bbfc7d00e: Pull complete\n",
      "860a23551ac0: Pull complete\n",
      "cc78be876588: Pull complete\n",
      "ad6568ad37e5: Pull complete\n",
      "258a31babfce: Pull complete\n",
      "116ca0069c88: Pull complete\n",
      "ede4a5022f61: Pull complete\n",
      "154d6414dd17: Pull complete\n",
      "e1f68d1c5137: Pull complete\n",
      "0d4b5cd36c43: Pull complete\n",
      "fc9b6547dc7c: Pull complete\n",
      "de51b5b1b318: Pull complete\n",
      "d684c579871f: Pull complete\n",
      "4a39f6623824: Pull complete\n",
      "30bba30584e3: Pull complete\n",
      "c104fa3a7626: Pull complete\n",
      "22f09e497c63: Pull complete\n",
      "5f66cd739f31: Pull complete\n",
      "c9c9a9e1cad6: Pull complete\n",
      "630fcaa7a158: Pull complete\n",
      "1b8090778700: Pull complete\n",
      "4ca3cacea924: Pull complete\n",
      "4aa043daa566: Pull complete\n",
      "c1d86dc35ba1: Pull complete\n",
      "55f4be7d7adc: Pull complete\n",
      "f8e1ddeececb: Pull complete\n",
      "bf1f5a5d15b8: Pull complete\n",
      "68d63385def6: Pull complete\n",
      "865f53eecc40: Pull complete\n",
      "70ac11bbf381: Pull complete\n",
      "91a761249212: Pull complete\n",
      "2cb953eac694: Pull complete\n",
      "2e6386dccac0: Pull complete\n",
      "67793606273a: Pull complete\n",
      "bfdaa5a6754f: Pull complete\n",
      "3e0d0b3b5c1c: Pull complete\n",
      "8d6d2c98840c: Pull complete\n",
      "2559630e37d2: Pull complete\n",
      "d0f13d58f7fa: Pull complete\n",
      "929ce3ad5dc9: Pull complete\n",
      "7a42c1978b2e: Pull complete\n",
      "Digest: sha256:2475b7062a16cd7ba0e5eda0ff58f206400714aafd061d4d8a1a1e8aacd59668\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      " ---> ec90adb8185e\n",
      "Step 2/7 : WORKDIR /\n",
      " ---> Running in e2434dc0f33d\n",
      "Removing intermediate container e2434dc0f33d\n",
      " ---> d2047e64033f\n",
      "Step 3/7 : COPY /serving/requirements.txt /requirements.txt\n",
      " ---> 400dd75b1234\n",
      "Step 4/7 : RUN pip install -r /requirements.txt\n",
      " ---> Running in 477745a534fd\n",
      "Collecting git+https://github.com/NVIDIA-Merlin/models.git (from -r /requirements.txt (line 7))\n",
      "  Cloning https://github.com/NVIDIA-Merlin/models.git to /tmp/pip-req-build-iwgatqum\n",
      "\u001b[91m  Running command git clone -q https://github.com/NVIDIA-Merlin/models.git /tmp/pip-req-build-iwgatqum\n",
      "\u001b[0m  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting uvicorn[standard]==0.15.0\n",
      "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting fastapi==0.68.1\n",
      "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\n",
      "Collecting uvloop==0.15.2\n",
      "  Downloading uvloop-0.15.2-cp38-cp38-manylinux2010_x86_64.whl (4.7 MB)\n",
      "Collecting fastapi-utils\n",
      "  Downloading fastapi_utils-0.2.1-py3-none-any.whl (16 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.18.3-py2.py3-none-any.whl (2.3 MB)\n",
      "Collecting nvtabular==1.3.3\n",
      "  Downloading nvtabular-1.3.3.tar.gz (132 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.10.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.6.0-py2.py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (0.7.0)\n",
      "Collecting asgiref>=3.4.0\n",
      "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (8.1.3)\n",
      "Requirement already satisfied: PyYAML>=5.1; extra == \"standard\" in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (6.0)\n",
      "Collecting python-dotenv>=0.13; extra == \"standard\"\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Collecting watchgod>=0.6; extra == \"standard\"\n",
      "  Downloading watchgod-0.8.2-py3-none-any.whl (12 kB)\n",
      "Collecting websockets>=9.1; extra == \"standard\"\n",
      "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "Collecting httptools==0.2.*; extra == \"standard\"\n",
      "  Downloading httptools-0.2.0-cp38-cp38-manylinux1_x86_64.whl (354 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn==20.1.0->-r /requirements.txt (line 2)) (45.2.0)\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "Collecting starlette==0.14.2\n",
      "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.12\n",
      "  Downloading SQLAlchemy-1.4.43-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.6.3-py2.py3-none-any.whl (233 kB)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform->-r /requirements.txt (line 6)) (21.3)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0\n",
      "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform->-r /requirements.txt (line 6)) (3.19.5)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (2.22.0)\n",
      "Collecting fsspec==2022.10.0\n",
      "  Downloading fsspec-2022.10.0-py3-none-any.whl (138 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (2.12.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (0.4.6)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (7.0.0)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (0.56.2)\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.3.5)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2022.5.1)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (4.64.1)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2022.5.1)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.2.5)\n",
      "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1->-r /requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2.0.0,>=1.3.12->fastapi-utils->-r /requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (1.41.0)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform->-r /requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (1.56.4)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2; extra == \"grpc\"\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (22.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib->gcsfs->-r /requirements.txt (line 9)) (1.3.1)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.8/dist-packages (from pyarrow>=5.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.22.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (4.12.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (0.39.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2022.2.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.26.12)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (5.9.2)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.7.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (6.2)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (0.4.3)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<4,>=3.0.0->watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.0.0->watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->-r /requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (3.8.1)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+37.gb46ddddd9->-r /requirements.txt (line 7)) (6.0.1)\n",
      "Building wheels for collected packages: nvtabular, merlin-models\n",
      "  Building wheel for nvtabular (PEP 517): started\n",
      "  Building wheel for nvtabular (PEP 517): finished with status 'done'\n",
      "  Created wheel for nvtabular: filename=nvtabular-1.3.3-cp38-cp38-linux_x86_64.whl size=267323 sha256=b1815fc2d5e6f5e60c1e325839cdb78487f412fd2db66f5d5cfff9cc0f79769c\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/77/fd/af573fde58e010040b863b7e552d4877f0b2c221bfcadb3cc6\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-0.9.0+37.gb46ddddd9-py3-none-any.whl size=364688 sha256=43e042221134b0a530f5a5534ec3af299db264aa130b61782e5deec85067268e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8cy9qb3a/wheels/5a/43/99/d50fe2c33b4f4686db73207ce3865e0d6be6609ffb03abade5\n",
      "Successfully built nvtabular merlin-models\n",
      "\u001b[91mERROR: merlin-core 0.7.0 has requirement fsspec==2022.5.0, but you'll have fsspec 2022.10.0 which is incompatible.\n",
      "ERROR: grpcio-status 1.50.0 has requirement grpcio>=1.50.0, but you'll have grpcio 1.41.0 which is incompatible.\n",
      "ERROR: grpcio-status 1.50.0 has requirement protobuf>=4.21.6, but you'll have protobuf 3.19.5 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: asgiref, h11, python-dotenv, uvloop, watchgod, websockets, httptools, uvicorn, gunicorn, pydantic, starlette, fastapi, sqlalchemy, fastapi-utils, google-crc32c, google-resumable-media, grpcio-status, google-api-core, google-cloud-core, proto-plus, google-cloud-bigquery, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-storage, google-cloud-aiplatform, nvtabular, fsspec, gcsfs, merlin-models\n",
      "  Attempting uninstall: nvtabular\n",
      "    Found existing installation: nvtabular 1.5.0\n",
      "    Uninstalling nvtabular-1.5.0:\n",
      "      Successfully uninstalled nvtabular-1.5.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 0.8.0\n",
      "    Uninstalling merlin-models-0.8.0:\n",
      "      Successfully uninstalled merlin-models-0.8.0\n",
      "Successfully installed asgiref-3.5.2 fastapi-0.68.1 fastapi-utils-0.2.1 fsspec-2022.10.0 gcsfs-2022.10.0 google-api-core-2.10.2 google-cloud-aiplatform-1.18.3 google-cloud-bigquery-2.34.4 google-cloud-core-2.3.2 google-cloud-resource-manager-1.6.3 google-cloud-storage-2.6.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 grpc-google-iam-v1-0.12.4 grpcio-status-1.50.0 gunicorn-20.1.0 h11-0.14.0 httptools-0.2.0 merlin-models-0.9.0+37.gb46ddddd9 nvtabular-1.3.3 proto-plus-1.22.1 pydantic-1.10.2 python-dotenv-0.21.0 sqlalchemy-1.4.43 starlette-0.14.2 uvicorn-0.15.0 uvloop-0.15.2 watchgod-0.8.2 websockets-10.4\n",
      "Removing intermediate container 477745a534fd\n",
      " ---> 0857404ceed9\n",
      "Step 5/7 : COPY /serving/app /app\n",
      " ---> 054cef6615c0\n",
      "Step 6/7 : EXPOSE 80\n",
      " ---> Running in deb4adfe2934\n",
      "Removing intermediate container deb4adfe2934\n",
      " ---> 156cafddf4a6\n",
      "Step 7/7 : CMD [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]\n",
      " ---> Running in a41e9f696f1a\n",
      "Removing intermediate container a41e9f696f1a\n",
      " ---> fecb1994bdc5\n",
      "Successfully built fecb1994bdc5\n",
      "Successfully tagged gcr.io/hybrid-vertex/merlin-triton-serving-v6:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/merlin-triton-serving-v6\n",
      "The push refers to repository [gcr.io/hybrid-vertex/merlin-triton-serving-v6]\n",
      "853591be7455: Preparing\n",
      "1de7fc1bb630: Preparing\n",
      "7c6a04c6be4c: Preparing\n",
      "bd113aa55fbd: Preparing\n",
      "e58f9c500afd: Preparing\n",
      "c3c9ca29c9f2: Preparing\n",
      "e844c8057c95: Preparing\n",
      "0b07555d3a5b: Preparing\n",
      "a1537cf26842: Preparing\n",
      "00679b7c9426: Preparing\n",
      "add0b850bdf8: Preparing\n",
      "c2e412b87e2d: Preparing\n",
      "7730d4c011cd: Preparing\n",
      "f83c32bae622: Preparing\n",
      "86147dce553c: Preparing\n",
      "a86afd489635: Preparing\n",
      "725647e88671: Preparing\n",
      "78e008bc66d2: Preparing\n",
      "e7d002ddb49b: Preparing\n",
      "f2b540bc31be: Preparing\n",
      "442b3d22fc2d: Preparing\n",
      "72f4d03b40d8: Preparing\n",
      "54244453f24a: Preparing\n",
      "c9dfb1d8d420: Preparing\n",
      "c1af80eb8994: Preparing\n",
      "5c0e49e0fefd: Preparing\n",
      "64579a0c8694: Preparing\n",
      "82432f6543d2: Preparing\n",
      "efbb58199899: Preparing\n",
      "f390faf5524c: Preparing\n",
      "daee9dea71d9: Preparing\n",
      "dc74b4fa6312: Preparing\n",
      "cf7ec5236059: Preparing\n",
      "2784fc353e53: Preparing\n",
      "4748e1954466: Preparing\n",
      "17dd0d3a32ca: Preparing\n",
      "1a4d9b216faa: Preparing\n",
      "29ec3f10d323: Preparing\n",
      "b103452845b7: Preparing\n",
      "5de10b8eda77: Preparing\n",
      "93a1a17119ba: Preparing\n",
      "0b949eaca829: Preparing\n",
      "76dffad7db12: Preparing\n",
      "103f14ded07d: Preparing\n",
      "05a0d2d578a6: Preparing\n",
      "1f7bd087086a: Preparing\n",
      "a03ce844e2ad: Preparing\n",
      "b5583e44add1: Preparing\n",
      "3ff439c0455c: Preparing\n",
      "c3c9ca29c9f2: Waiting\n",
      "2ee8c052052a: Preparing\n",
      "f3154f787b0f: Preparing\n",
      "e844c8057c95: Waiting\n",
      "944a1106424f: Preparing\n",
      "01386fafb257: Preparing\n",
      "0b07555d3a5b: Waiting\n",
      "8a9d499564b0: Preparing\n",
      "a1537cf26842: Waiting\n",
      "d882bfae03e4: Preparing\n",
      "00679b7c9426: Waiting\n",
      "5f70bf18a086: Preparing\n",
      "add0b850bdf8: Waiting\n",
      "913f47d5362d: Preparing\n",
      "06f02804b89d: Preparing\n",
      "54beb86c2dbe: Preparing\n",
      "aa57b43dc9e0: Preparing\n",
      "ae5c80704277: Preparing\n",
      "d1cc4baf7a93: Preparing\n",
      "8fd21a588646: Preparing\n",
      "b470f3b3096a: Preparing\n",
      "9af2b05f2c3b: Preparing\n",
      "4cf9aed48cda: Preparing\n",
      "57f574ab1503: Preparing\n",
      "c5b9544e7743: Preparing\n",
      "c3f11d77a5de: Preparing\n",
      "e7d002ddb49b: Waiting\n",
      "f2b540bc31be: Waiting\n",
      "442b3d22fc2d: Waiting\n",
      "72f4d03b40d8: Waiting\n",
      "54244453f24a: Waiting\n",
      "b5583e44add1: Waiting\n",
      "c9dfb1d8d420: Waiting\n",
      "aa57b43dc9e0: Waiting\n",
      "3ff439c0455c: Waiting\n",
      "ae5c80704277: Waiting\n",
      "2ee8c052052a: Waiting\n",
      "d1cc4baf7a93: Waiting\n",
      "8fd21a588646: Waiting\n",
      "c3f11d77a5de: Waiting\n",
      "5c0e49e0fefd: Waiting\n",
      "64579a0c8694: Waiting\n",
      "dc74b4fa6312: Waiting\n",
      "cf7ec5236059: Waiting\n",
      "f390faf5524c: Waiting\n",
      "2784fc353e53: Waiting\n",
      "c5b9544e7743: Waiting\n",
      "f3154f787b0f: Waiting\n",
      "944a1106424f: Waiting\n",
      "4cf9aed48cda: Waiting\n",
      "b470f3b3096a: Waiting\n",
      "01386fafb257: Waiting\n",
      "57f574ab1503: Waiting\n",
      "9af2b05f2c3b: Waiting\n",
      "8a9d499564b0: Waiting\n",
      "d882bfae03e4: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "913f47d5362d: Waiting\n",
      "c2e412b87e2d: Waiting\n",
      "7730d4c011cd: Waiting\n",
      "17dd0d3a32ca: Waiting\n",
      "f83c32bae622: Waiting\n",
      "86147dce553c: Waiting\n",
      "1a4d9b216faa: Waiting\n",
      "a86afd489635: Waiting\n",
      "5de10b8eda77: Waiting\n",
      "78e008bc66d2: Waiting\n",
      "725647e88671: Waiting\n",
      "93a1a17119ba: Waiting\n",
      "82432f6543d2: Waiting\n",
      "0b949eaca829: Waiting\n",
      "efbb58199899: Waiting\n",
      "103f14ded07d: Waiting\n",
      "76dffad7db12: Waiting\n",
      "05a0d2d578a6: Waiting\n",
      "b103452845b7: Waiting\n",
      "1f7bd087086a: Waiting\n",
      "a03ce844e2ad: Waiting\n",
      "daee9dea71d9: Waiting\n",
      "4748e1954466: Waiting\n",
      "29ec3f10d323: Waiting\n",
      "c1af80eb8994: Waiting\n",
      "bd113aa55fbd: Layer already exists\n",
      "e58f9c500afd: Layer already exists\n",
      "c3c9ca29c9f2: Layer already exists\n",
      "e844c8057c95: Layer already exists\n",
      "0b07555d3a5b: Layer already exists\n",
      "a1537cf26842: Layer already exists\n",
      "00679b7c9426: Layer already exists\n",
      "add0b850bdf8: Layer already exists\n",
      "c2e412b87e2d: Layer already exists\n",
      "7730d4c011cd: Layer already exists\n",
      "f83c32bae622: Layer already exists\n",
      "86147dce553c: Layer already exists\n",
      "a86afd489635: Layer already exists\n",
      "853591be7455: Pushed\n",
      "725647e88671: Layer already exists\n",
      "78e008bc66d2: Layer already exists\n",
      "e7d002ddb49b: Layer already exists\n",
      "f2b540bc31be: Layer already exists\n",
      "442b3d22fc2d: Layer already exists\n",
      "72f4d03b40d8: Layer already exists\n",
      "54244453f24a: Layer already exists\n",
      "c9dfb1d8d420: Layer already exists\n",
      "c1af80eb8994: Layer already exists\n",
      "5c0e49e0fefd: Layer already exists\n",
      "64579a0c8694: Layer already exists\n",
      "82432f6543d2: Layer already exists\n",
      "efbb58199899: Layer already exists\n",
      "f390faf5524c: Layer already exists\n",
      "dc74b4fa6312: Layer already exists\n",
      "daee9dea71d9: Layer already exists\n",
      "cf7ec5236059: Layer already exists\n",
      "17dd0d3a32ca: Layer already exists\n",
      "4748e1954466: Layer already exists\n",
      "2784fc353e53: Layer already exists\n",
      "1a4d9b216faa: Layer already exists\n",
      "29ec3f10d323: Layer already exists\n",
      "b103452845b7: Layer already exists\n",
      "5de10b8eda77: Layer already exists\n",
      "93a1a17119ba: Layer already exists\n",
      "0b949eaca829: Layer already exists\n",
      "76dffad7db12: Layer already exists\n",
      "103f14ded07d: Layer already exists\n",
      "7c6a04c6be4c: Pushed\n",
      "05a0d2d578a6: Layer already exists\n",
      "1f7bd087086a: Layer already exists\n",
      "a03ce844e2ad: Layer already exists\n",
      "b5583e44add1: Layer already exists\n",
      "2ee8c052052a: Layer already exists\n",
      "3ff439c0455c: Layer already exists\n",
      "f3154f787b0f: Layer already exists\n",
      "944a1106424f: Layer already exists\n",
      "8a9d499564b0: Layer already exists\n",
      "01386fafb257: Layer already exists\n",
      "d882bfae03e4: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "913f47d5362d: Layer already exists\n",
      "06f02804b89d: Layer already exists\n",
      "54beb86c2dbe: Layer already exists\n",
      "aa57b43dc9e0: Layer already exists\n",
      "ae5c80704277: Layer already exists\n",
      "8fd21a588646: Layer already exists\n",
      "b470f3b3096a: Layer already exists\n",
      "9af2b05f2c3b: Layer already exists\n",
      "d1cc4baf7a93: Layer already exists\n",
      "4cf9aed48cda: Layer already exists\n",
      "c3f11d77a5de: Layer already exists\n",
      "c5b9544e7743: Layer already exists\n",
      "57f574ab1503: Layer already exists\n",
      "1de7fc1bb630: Pushed\n",
      "latest: digest: sha256:f3ea2ae3c2796214203c328a618fd75f23c57b49a3d74e168a173f0b2a315ea2 size: 14847\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                      IMAGES                                                   STATUS\n",
      "2681eb09-22d5-4727-8e70-503dcc2365e6  2022-11-09T20:36:13+00:00  6M21S     gs://hybrid-vertex_cloudbuild/source/1668026173.08763-f1cbda98a6584b2d9b65b0886c42caab.tgz  gcr.io/hybrid-vertex/merlin-triton-serving-v6 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit --config src/cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94bf61-afbc-4187-9460-251a37e67171",
   "metadata": {},
   "source": [
    "# Deploy Query Model with Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a9295-e707-4127-aa76-42ed7fc756a5",
   "metadata": {},
   "source": [
    "## Upload to Model Regsitry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b7aa0466-d49c-44df-b636-dd3035824a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME = \"mm_qtower_test_v7\"\n",
    "MODEL_ARTIFACT_URI = 'gs://jt-merlin-scaling/test-2tower-merlin-tf-jtv1/run-v5-20221108-163948/model-dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6114bfba-7b2c-41ef-9828-1cfebb33cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/4060694353469767680/operations/3121281857899986944\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/4060694353469767680@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/4060694353469767680@1')\n"
     ]
    }
   ],
   "source": [
    "model = vertex_ai.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=MODEL_ARTIFACT_URI,\n",
    "        serving_container_image_uri=IMAGE_URI,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        sync=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c799802-643a-4650-be6f-3d670479af0a",
   "metadata": {},
   "source": [
    "## Deploy to Vertex AI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c851ac78-8322-4e57-b8aa-2e7c571ae73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/6328054455711301632/operations/6622830568180547584\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/6328054455711301632\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/6328054455711301632')\n",
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/6328054455711301632\n",
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/6328054455711301632/operations/4678682904040046592\n"
     ]
    },
    {
     "ename": "FailedPrecondition",
     "evalue": "400 Model server terminated: model server container terminated: exit_code: \t 1\nreason: \"Error\"\nstarted_at {\n  seconds: 1668029551\n}\nfinished_at {\n  seconds: 1668029695\n}\n. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=934903580331&resource=aiplatform.googleapis.com%252FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%226328054455711301632%22%0Aresource.labels.location%3D%22us-central1%22.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21686/806198762.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmax_replica_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccelerator_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NVIDIA_TESLA_T4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maccelerator_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m   3314\u001b[0m             \u001b[0mdeploy_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3315\u001b[0m             \u001b[0mautoscaling_target_cpu_utilization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoscaling_target_cpu_utilization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3316\u001b[0;31m             \u001b[0mautoscaling_target_accelerator_duty_cycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoscaling_target_accelerator_duty_cycle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3317\u001b[0m         )\n\u001b[1;32m   3318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m_deploy\u001b[0;34m(self, endpoint, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, encryption_spec_key_name, network, sync, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m   3489\u001b[0m             \u001b[0mdeploy_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeploy_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3490\u001b[0m             \u001b[0mautoscaling_target_cpu_utilization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoscaling_target_cpu_utilization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3491\u001b[0;31m             \u001b[0mautoscaling_target_accelerator_duty_cycle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoscaling_target_accelerator_duty_cycle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3492\u001b[0m         )\n\u001b[1;32m   3493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36m_deploy_call\u001b[0;34m(cls, api_client, endpoint_resource_name, model, endpoint_resource_traffic_split, network, deployed_model_display_name, traffic_percentage, traffic_split, machine_type, min_replica_count, max_replica_count, accelerator_type, accelerator_count, service_account, explanation_metadata, explanation_parameters, metadata, deploy_request_timeout, autoscaling_target_cpu_utilization, autoscaling_target_accelerator_duty_cycle)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         )\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0moperation_future\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def undeploy(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout, retry)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 Model server terminated: model server container terminated: exit_code: \t 1\nreason: \"Error\"\nstarted_at {\n  seconds: 1668029551\n}\nfinished_at {\n  seconds: 1668029695\n}\n. Model server logs can be found at https://console.cloud.google.com/logs/viewer?project=934903580331&resource=aiplatform.googleapis.com%252FEndpoint&advancedFilter=resource.type%3D%22aiplatform.googleapis.com%2FEndpoint%22%0Aresource.labels.endpoint_id%3D%226328054455711301632%22%0Aresource.labels.location%3D%22us-central1%22."
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(\n",
    "    deployed_model_display_name=\"mm_query_tower_deploy\",\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=1,\n",
    "    accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "    accelerator_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171104a3-490f-49bf-9662-2012efb35595",
   "metadata": {},
   "source": [
    "## Test Deployed Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ce601-e960-43a7-ace8-3fd2fa93313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ground truth candidate:\n",
    "    # 'album_uri_can': 'spotify:album:5l83t3mbVgCrIe1VU9uJZR', \n",
    "    # 'artist_name_can': 'Russ', \n",
    "    # 'track_name_can': 'We Just Havent Met Yet', \n",
    "## TODO - we have to overload with candidate data because of the workflow transform, add overloaded values in the predictor\n",
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834243af-4a5f-451f-83f8-4cecff11dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a prediction\n",
    "\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
