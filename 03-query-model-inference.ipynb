{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc27ca62-e310-4139-b3bb-3a0cba5d58ef",
   "metadata": {},
   "source": [
    "# Deploying Merlin Query Tower with Vertex AI\n",
    "\n",
    "* Create custom prediction routine (CPR)\n",
    "* Upload query model to Vertex AI Model Registry\n",
    "* Test registered models predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb40555-d090-45b8-a197-26252e430287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb336ccc-239a-4f43-8fc5-318a31dd0876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as vertex_ai\n",
    "import os\n",
    "import time\n",
    "\n",
    "BUCKET = 'jt-merlin-scaling'\n",
    "BUCKET_URI = 'gs://jt-merlin-scaling'\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b8b6e4-0426-49f9-82ca-8e7cf5ea07b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce275cb8-05ba-4daf-9cfc-2a2d8ab4f591",
   "metadata": {},
   "source": [
    "## Build serving app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a28ef83-b05b-4b4c-9694-59d5b64e2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "SERVING_SUB_DIR = 'serving'\n",
    "SERVING_APPLICATION_DIR = 'app'\n",
    "SERVING_DOCKERNAME = 'merlin-retriever'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2723aaec-495e-4a74-b895-ff87fdd9ba1d",
   "metadata": {},
   "source": [
    "### write pred files to local dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "734aea8d-6367-4bcd-9ce2-e8025ac17475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the training subfolder\n",
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}\n",
    "! touch {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/__init__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4c1711-1b15-4df1-8ec1-b919e25eddaa",
   "metadata": {},
   "source": [
    "#### requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308c947c-1bdf-42ea-96aa-0bb897bd9217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/requirements.txt\n",
    "uvicorn[standard]==0.15.0\n",
    "gunicorn==20.1.0\n",
    "fastapi==0.68.1\n",
    "uvloop==0.15.2\n",
    "fastapi-utils\n",
    "google-cloud-aiplatform\n",
    "git+https://github.com/NVIDIA-Merlin/models.git\n",
    "nvtabular==1.3.3\n",
    "gcsfs\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d9432c-59f2-467e-8334-da6764e64326",
   "metadata": {},
   "source": [
    "#### predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "141ef566-1582-433b-a5c6-e6ad41c8e3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/predictor.py\n",
    "import nvtabular as nvt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import merlin.models.tf as mm\n",
    "from nvtabular.loader.tf_utils import configure_tensorflow\n",
    "configure_tensorflow()\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import logging\n",
    "\n",
    "\n",
    "# These are helper functions that ensure the dictionary input is in a certain order and types are preserved\n",
    "# this is to get scalar values to appear first in the dict to not confuse pandas with lists https://github.com/pandas-dev/pandas/issues/46092\n",
    "reordered_keys = [\n",
    "    'collaborative', \n",
    "    'album_name_pl', \n",
    "    'artist_genres_pl', \n",
    "    'artist_name_pl', \n",
    "    'artist_pop_can', \n",
    "    'description_pl', \n",
    "    'duration_ms_songs_pl', \n",
    "    'n_songs_pl', \n",
    "    'name', \n",
    "    'num_albums_pl', \n",
    "    'num_artists_pl', \n",
    "    'track_name_pl', \n",
    "    'track_pop_pl', \n",
    "    'duration_ms_seed_pl', \n",
    "    'pid', \n",
    "    'track_uri_pl'\n",
    "]\n",
    "\n",
    "float_num_fix = ['n_songs_pl','num_albums_pl','num_artists_pl','duration_ms_seed_pl']\n",
    "float_list_fix = ['track_pop_pl', 'duration_ms_songs_pl']\n",
    "    \n",
    "def fix_list_num_dtypes(num_list):\n",
    "    \"this fixes lists of ints to list of floats converted in json input\"\n",
    "    return [float(x) for x in num_list]\n",
    "\n",
    "def fix_num_dtypes(num):\n",
    "    \"this fixes ints and casts to floats\"\n",
    "    return float(num)\n",
    "\n",
    "def fix_types(k, v):\n",
    "    if k in float_num_fix:\n",
    "        return fix_num_dtypes(v)\n",
    "    if k in float_list_fix:\n",
    "        return fix_list_num_dtypes(v)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def create_pandas_instance(inputs):\n",
    "    \"\"\"\n",
    "    Helper function to reorder the input to have a sclar first for pandas\n",
    "    And fix the types converted when data is imported by fastAPI\n",
    "    \"\"\"\n",
    "    if type(inputs) == list:\n",
    "        header = inputs[0]\n",
    "        reordered_header_dict = {k: fix_types(k,header[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_header_dict, orient='index').T\n",
    "        if len(inputs) > 1:\n",
    "            for ti in inputs[1:]:\n",
    "                reordered_dict = {k: fix_types(k,ti[k]) for k in reordered_keys}\n",
    "                pandas_instance = pandas_instance.append(pd.DataFrame.from_dict(reordered_dict, orient='index').T)\n",
    "    else:\n",
    "        reordered_dict = {k: fix_types(k,inputs[k]) for k in reordered_keys}\n",
    "        pandas_instance = pd.DataFrame.from_dict(reordered_dict, orient='index').T\n",
    "    return pandas_instance\n",
    "\n",
    "class Predictor():\n",
    "    \"\"\"Interface of the Predictor class for Custom Prediction Routines.\n",
    "    The Predictor is responsible for the ML logic for processing a prediction request.\n",
    "    Specifically, the Predictor must define:\n",
    "    (1) How to load all model artifacts used during prediction into memory.\n",
    "    (2) The logic that should be executed at predict time.\n",
    "    When using the default PredictionHandler, the Predictor will be invoked as follows:\n",
    "      predictor.postprocess(predictor.predict(predictor.preprocess(prediction_input)))\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, artifacts_uri):\n",
    "        \"\"\"Loads the model artifact.\n",
    "        Args:\n",
    "            artifacts_uri (str):\n",
    "                Required. The value of the environment variable AIP_STORAGE_URI.\n",
    "        \"\"\"\n",
    "        logging.info(\"loading model and workflow\")\n",
    "        logging.info(f\"artifacts_uri: {artifacts_uri}\")\n",
    "        start = time.process_time()\n",
    "        \n",
    "        self.model = tf.keras.models.load_model(f\"{artifacts_uri}/query-tower\")\n",
    "        self.workflow = nvt.Workflow.load(f\"{artifacts_uri}/workflow\")\n",
    "        self.workflow = self.workflow.remove_inputs(\n",
    "            [\n",
    "                'track_pop_can', \n",
    "                'track_uri_can', \n",
    "                'duration_ms_can', \n",
    "                'track_name_can', \n",
    "                'artist_name_can',\n",
    "                'album_name_can',\n",
    "                'album_uri_can',\n",
    "                'artist_followers_can', \n",
    "                'artist_genres_can',\n",
    "                'artist_name_can', \n",
    "                'artist_pop_can',\n",
    "                'artist_pop_pl',\n",
    "                'artist_uri_can', \n",
    "                'artists_followers_pl'\n",
    "            ]\n",
    "        )\n",
    "        self.loader = None # will load this after first load\n",
    "        self.n_rows = 0\n",
    "        logging.info(f\"loading took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    \n",
    "    def predict(self, prediction_input):\n",
    "        \"\"\"Preprocesses the prediction input before doing the prediction.\n",
    "        Args:\n",
    "            prediction_input (Any):\n",
    "                Required. The prediction input that needs to be preprocessed.\n",
    "        Returns:\n",
    "            The preprocessed prediction input.\n",
    "        \"\"\"\n",
    "        # handle different input types, can take a dict or list of dicts\n",
    "        self.n_rows = len(prediction_input)\n",
    "        \n",
    "        # pandas convert\n",
    "        start = time.process_time()\n",
    "        pandas_instance = create_pandas_instance(prediction_input[0])\n",
    "        logging.info(f\"Pandas conversion took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        # nvtabular data loading\n",
    "        start = time.process_time()\n",
    "        transformed_inputs = nvt.Dataset(pandas_instance)\n",
    "        logging.info(f\"NVT data loading took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        # workflow transformation\n",
    "        start = time.process_time()\n",
    "        transformed_instance = self.workflow.transform(transformed_inputs)\n",
    "        logging.info(f\"Workflow transformation took {time.process_time() - start} seconds\")\n",
    "\n",
    "        # tensorflow data loader\n",
    "        start = time.process_time()\n",
    "        batch = mm.sample_batch(transformed_instance, batch_size=1, include_targets=False, shuffle=False)\n",
    "        logging.info(f\"TF Dataloader took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        # model predict\n",
    "        start = time.process_time()\n",
    "        output = self.model(batch)\n",
    "        logging.info(f\"Prediction took {time.process_time() - start} seconds\")\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f31d7cf-0a48-4190-8c48-9f6544d47124",
   "metadata": {},
   "source": [
    "#### main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af6931b-0fe1-43b1-a14e-85b8fa0ef862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/main.py\n",
    "from fastapi import FastAPI, Request\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import logging\n",
    "from fastapi_utils.timing import add_timing_middleware, record_timing\n",
    "\n",
    "from google.cloud import storage\n",
    "from .predictor import Predictor\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "predictor_instance = Predictor()\n",
    "ARTIFACT_DIR = \"gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir\"\n",
    "loaded_predictor = predictor_instance.load(artifacts_uri = ARTIFACT_DIR)  # os.environ['AIP_STORAGE_URI'])\n",
    "\n",
    "app = FastAPI()\n",
    "add_timing_middleware(app, record=logger.info, prefix=\"app\", exclude=\"untimed\")\n",
    "\n",
    "@app.get(os.environ['AIP_HEALTH_ROUTE'], status_code=200)\n",
    "def health():\n",
    "    return {}\n",
    "\n",
    "\n",
    "@app.post(os.environ['AIP_PREDICT_ROUTE'])\n",
    "async def predict(request: Request):\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    outputs = loaded_predictor.predict(instances)\n",
    "    # outputs = loaded_predictor.predict(preprocessed_inputs)\n",
    "\n",
    "    return {\"predictions\": outputs.numpy().tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5eb243-8407-4f90-a070-749038288fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/app/prestart.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/{SERVING_APPLICATION_DIR}/prestart.sh\n",
    "#!/bin/bash\n",
    "export PORT=$AIP_HTTP_PORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71121ab-b4d8-40de-8c72-022fd97878bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/serving/instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{SERVING_SUB_DIR}/instances.json\n",
    "{\"instances\": {\"collaborative\": \"false\", \"album_name_pl\": [\"There's Really A Wolf\", \"Late Nights: The Album\", \"American Teen\", \"Crazy In Love\", \"Pony\"], \"album_uri_can\": \"spotify:album:5l83t3mbVgCrIe1VU9uJZR\", \"artist_followers_can\": 4339757.0, \"artist_genres_can\": \"'hawaiian hip hop', 'rap'\", \"artist_genres_pl\": [\"'hawaiian hip hop', 'rap'\", \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\", \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\", \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \"artist_name_can\": \"Russ\", \"artist_name_pl\": [\"Russ\", \"Jeremih\", \"Khalid\", \"Beyonc\\u00c3\\u00a9\", \"William Singe\"], \"artist_pop_can\": 82.0, \"artist_pop_pl\": [82.0, 80.0, 90.0, 87.0, 65.0], \"artist_uri_can\": \"spotify:artist:1z7b1Pr1rSlvWRzsW3HOrS\", \"artists_followers_pl\": [4339757.0, 5611842.0, 15046756.0, 30713126.0, 603837.0], \"description_pl\": \"\", \"duration_ms_can\": 237322.0, \"duration_ms_songs_pl\": [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \"n_songs_pl\": 8.0, \"name\": \"Lit Tunes \", \"num_albums_pl\": 8.0, \"num_artists_pl\": 8.0, \"track_name_can\": \"We Just Havent Met Yet\", \"track_name_pl\": [\"Losin Control\", \"Paradise\", \"Location\", \"Crazy In Love - Remix\", \"Pony\"], \"track_pop_can\": 57.0, \"track_pop_pl\": [79.0, 58.0, 83.0, 71.0, 57.0], \"duration_ms_seed_pl\": 51023.1, \"pid\": 1, \"track_uri_can\": \"spotify:track:0VzDv4wiuZsLsNOmfaUy2W\", \"track_uri_pl\": [\"spotify:track:4cxMGhkinTocPSVVKWIw0d\", \"spotify:track:1wNEBPo3nsbGCZRryI832I\", \"spotify:track:152lZdxL1OR0ZMW6KquMif\", \"spotify:track:2f4IuijXLxYOeBncS60GUD\", \"spotify:track:4Lj8paMFwyKTGfILLELVxt\"]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1147891d-0d39-4ad6-8466-da0ad292d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pwd\n",
    "# !tree /home/jupyter/merlin-on-vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2390771-4c19-4c14-b8b3-940437deb824",
   "metadata": {},
   "source": [
    "### dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10de1285-535f-4952-9bb0-15e08ab36de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f9837b4-c739-4671-9ca6-df71fb590404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/Dockerfile.merlin-retriever\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/Dockerfile.{SERVING_DOCKERNAME}\n",
    "\n",
    "FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
    "\n",
    "WORKDIR / \n",
    "\n",
    "COPY /serving/requirements.txt /requirements.txt\n",
    "\n",
    "RUN pip install -r /requirements.txt\n",
    "\n",
    "COPY /serving/app /app\n",
    "\n",
    "EXPOSE 80\n",
    "    \n",
    "CMD [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bede56-9349-47b8-8149-ad4daf0487c0",
   "metadata": {},
   "source": [
    "## Copy serving assets to `MODEL_DIR`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28005617-3219-4810-9be6-2b2960365dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR_old = 'gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir'\n",
    "MODEL_DIR = 'gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4253ac00-f75f-4cd5-aacb-c5c5b3c8959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "309d8c62-c6f0-4d24-a400-b993f2c2a8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir/candidate-embeddings/candidate_embeddings.json [Content-Type=application/json]...\n",
      "/ [1 files][  4.1 GiB/  4.1 GiB]                                                \n",
      "Operation completed over 1 objects/4.1 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r $MODEL_DIR_old/candidate-embeddings $MODEL_DIR/candidate-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9f29a0-21e7-4fec-957e-33b6c27195ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil cp -r $MODEL_DIR_old/query-tower $MODEL_DIR/query-tower\n",
    "# !gsutil cp -r $MODEL_DIR_old/candidate-tower $MODEL_DIR/candidate-tower\n",
    "# !gsutil cp -r $MODEL_DIR_old/workflow $MODEL_DIR/workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3d84d-bb16-4d55-a8d3-0e2f5af774c2",
   "metadata": {},
   "source": [
    "### copy Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8acb93a-6776-4027-891a-beccf422007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/Dockerfile.merlin-retriever [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  270.0 B/  270.0 B]                                                \n",
      "Operation completed over 1 objects/270.0 B.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./src/Dockerfile.$SERVING_DOCKERNAME $MODEL_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b4d265-24ff-4f2d-bbd3-7f2fc65ec00f",
   "metadata": {},
   "source": [
    "### copy serving application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56eaf0f-591a-4d25-9fe4-67119f10f43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/serving/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://./src/serving/instances.json [Content-Type=application/json]...  \n",
      "Copying file://./src/serving/app/__init__.py [Content-Type=text/x-python]...    \n",
      "Copying file://./src/serving/app/predictor.py [Content-Type=text/x-python]...   \n",
      "Copying file://./src/serving/app/main.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/serving/app/prestart.sh [Content-Type=text/x-sh]...        \n",
      "Copying file://./src/serving/app/.ipynb_checkpoints/__init__-checkpoint.py [Content-Type=text/x-python]...\n",
      "/ [7/7 files][  8.5 KiB/  8.5 KiB] 100% Done                                    \n",
      "Operation completed over 7 objects/8.5 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR $MODEL_DIR/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a283c95e-a6b4-4901-9bee-1840fd46e9f2",
   "metadata": {},
   "source": [
    "### copy workflow\n",
    "\n",
    "* easier for prediction container if a model's related workflow artifacts are stored in the `model_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984d0b76-1bd8-4b68-8e8a-8f77638c8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKFLOW_DIR = \"gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "020ef708-19e5-45b1-b364-e2839318b3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.album_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.artist_genres_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.artist_genres_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.artist_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.artist_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.collaborative.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.description_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.name.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.pid.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.track_name_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.track_name_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.track_uri_can.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/categories/unique.track_uri_pl.parquet [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/metadata.json [Content-Type=application/octet-stream]...\n",
      "Copying gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed/workflow.pkl [Content-Type=application/octet-stream]...\n",
      "/ [15/15 files][284.9 MiB/284.9 MiB] 100% Done                                  \n",
      "Operation completed over 15 objects/284.9 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r $WORKFLOW_DIR $MODEL_DIR/workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1511e95-c5d3-4ceb-b9a7-acdac2e317db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/Dockerfile.merlin-retriever\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/candidate-embeddings/\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/candidate-tower/\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/query-tower/\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/serving/\n",
      "gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2/workflow/\n"
     ]
    }
   ],
   "source": [
    "# check model_dir\n",
    "!gsutil ls $MODEL_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83083194-47bd-470c-9d20-4449d1b48535",
   "metadata": {},
   "source": [
    "## Build Serving Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e33fed8d-10c9-46b6-8d0c-fd6be21d6114",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_VERSION = 'v11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb87a7c4-be26-4004-902e-3732fc684bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_NAME: merlin-vertex-serv-v11\n",
      "IMAGE_URI: gcr.io/hybrid-vertex/merlin-vertex-serv-v11\n",
      "DOCKERNAME: merlin-retriever\n"
     ]
    }
   ],
   "source": [
    "# Docker definitions for training\n",
    "IMAGE_NAME = f'merlin-vertex-serv-{SERVING_VERSION}'\n",
    "IMAGE_URI = f'gcr.io/{PROJECT_ID}/{IMAGE_NAME}'\n",
    "\n",
    "DOCKERNAME = f'{SERVING_DOCKERNAME}'\n",
    "MACHINE_TYPE ='e2-highcpu-32'\n",
    "FILE_LOCATION = './src'\n",
    "\n",
    "print(f\"IMAGE_NAME: {IMAGE_NAME}\")\n",
    "print(f\"IMAGE_URI: {IMAGE_URI}\")\n",
    "print(f\"DOCKERNAME: {DOCKERNAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5094bb7-6a37-483e-9689-bd0d885dd651",
   "metadata": {},
   "source": [
    "### submit to Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0db70f2c-99e8-477a-b7f7-e42fc5749137",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 62 file(s) totalling 1.6 MiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/home/jupyter/.config/gcloud/logs/2022.11.11/18.33.54.534693.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://hybrid-vertex_cloudbuild/source/1668191634.654956-7861da43623d4552a36a65c4c1cf6618.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/hybrid-vertex/locations/global/builds/aa73ebb1-a7cd-412e-8f84-a81f15abe095].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/aa73ebb1-a7cd-412e-8f84-a81f15abe095?project=934903580331 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"aa73ebb1-a7cd-412e-8f84-a81f15abe095\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://hybrid-vertex_cloudbuild/source/1668191634.654956-7861da43623d4552a36a65c4c1cf6618.tgz#1668191635178276\n",
      "Copying gs://hybrid-vertex_cloudbuild/source/1668191634.654956-7861da43623d4552a36a65c4c1cf6618.tgz#1668191635178276...\n",
      "/ [1 files][587.9 KiB/587.9 KiB]                                                \n",
      "Operation completed over 1 objects/587.9 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  138.2kB\n",
      "Step 1/7 : FROM nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      "22.09: Pulling from nvidia/merlin/merlin-tensorflow\n",
      "3b65ec22a9e9: Pulling fs layer\n",
      "fd80d866e8b2: Pulling fs layer\n",
      "a364ca75fd6d: Pulling fs layer\n",
      "3d4731d03623: Pulling fs layer\n",
      "53a5c2e0251f: Pulling fs layer\n",
      "b00ff40d02d9: Pulling fs layer\n",
      "3036e9b94123: Pulling fs layer\n",
      "453fdcdda788: Pulling fs layer\n",
      "35e12ec5e515: Pulling fs layer\n",
      "11f61a475a23: Pulling fs layer\n",
      "24280cf31c9a: Pulling fs layer\n",
      "79007799e2ed: Pulling fs layer\n",
      "03eb76abf1e5: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "5e9434e8ae41: Pulling fs layer\n",
      "88a3e778b5bf: Pulling fs layer\n",
      "729af2b35d14: Pulling fs layer\n",
      "30e0a3a7e9e5: Pulling fs layer\n",
      "0852b4bd65a1: Pulling fs layer\n",
      "81cb421c2c25: Pulling fs layer\n",
      "3d6b664afa23: Pulling fs layer\n",
      "3e8f37aba8a2: Pulling fs layer\n",
      "91bba9bd0f1f: Pulling fs layer\n",
      "a422be4dcb08: Pulling fs layer\n",
      "ca10bb6dc143: Pulling fs layer\n",
      "e48bbfc7d00e: Pulling fs layer\n",
      "860a23551ac0: Pulling fs layer\n",
      "cc78be876588: Pulling fs layer\n",
      "ad6568ad37e5: Pulling fs layer\n",
      "258a31babfce: Pulling fs layer\n",
      "116ca0069c88: Pulling fs layer\n",
      "ede4a5022f61: Pulling fs layer\n",
      "154d6414dd17: Pulling fs layer\n",
      "e1f68d1c5137: Pulling fs layer\n",
      "0d4b5cd36c43: Pulling fs layer\n",
      "fc9b6547dc7c: Pulling fs layer\n",
      "de51b5b1b318: Pulling fs layer\n",
      "d684c579871f: Pulling fs layer\n",
      "4a39f6623824: Pulling fs layer\n",
      "30bba30584e3: Pulling fs layer\n",
      "c104fa3a7626: Pulling fs layer\n",
      "22f09e497c63: Pulling fs layer\n",
      "5f66cd739f31: Pulling fs layer\n",
      "c9c9a9e1cad6: Pulling fs layer\n",
      "630fcaa7a158: Pulling fs layer\n",
      "1b8090778700: Pulling fs layer\n",
      "4ca3cacea924: Pulling fs layer\n",
      "4aa043daa566: Pulling fs layer\n",
      "c1d86dc35ba1: Pulling fs layer\n",
      "55f4be7d7adc: Pulling fs layer\n",
      "f8e1ddeececb: Pulling fs layer\n",
      "bf1f5a5d15b8: Pulling fs layer\n",
      "68d63385def6: Pulling fs layer\n",
      "3d4731d03623: Waiting\n",
      "865f53eecc40: Pulling fs layer\n",
      "53a5c2e0251f: Waiting\n",
      "70ac11bbf381: Pulling fs layer\n",
      "91a761249212: Pulling fs layer\n",
      "b00ff40d02d9: Waiting\n",
      "3036e9b94123: Waiting\n",
      "453fdcdda788: Waiting\n",
      "35e12ec5e515: Waiting\n",
      "11f61a475a23: Waiting\n",
      "2cb953eac694: Pulling fs layer\n",
      "24280cf31c9a: Waiting\n",
      "2e6386dccac0: Pulling fs layer\n",
      "79007799e2ed: Waiting\n",
      "67793606273a: Pulling fs layer\n",
      "bfdaa5a6754f: Pulling fs layer\n",
      "03eb76abf1e5: Waiting\n",
      "3e0d0b3b5c1c: Pulling fs layer\n",
      "4f4fb700ef54: Waiting\n",
      "8d6d2c98840c: Pulling fs layer\n",
      "5e9434e8ae41: Waiting\n",
      "2559630e37d2: Pulling fs layer\n",
      "88a3e778b5bf: Waiting\n",
      "d0f13d58f7fa: Pulling fs layer\n",
      "929ce3ad5dc9: Pulling fs layer\n",
      "729af2b35d14: Waiting\n",
      "7a42c1978b2e: Pulling fs layer\n",
      "30e0a3a7e9e5: Waiting\n",
      "0852b4bd65a1: Waiting\n",
      "81cb421c2c25: Waiting\n",
      "ad6568ad37e5: Waiting\n",
      "3d6b664afa23: Waiting\n",
      "258a31babfce: Waiting\n",
      "116ca0069c88: Waiting\n",
      "cc78be876588: Waiting\n",
      "ede4a5022f61: Waiting\n",
      "154d6414dd17: Waiting\n",
      "e1f68d1c5137: Waiting\n",
      "ca10bb6dc143: Waiting\n",
      "3e8f37aba8a2: Waiting\n",
      "0d4b5cd36c43: Waiting\n",
      "91bba9bd0f1f: Waiting\n",
      "e48bbfc7d00e: Waiting\n",
      "fc9b6547dc7c: Waiting\n",
      "a422be4dcb08: Waiting\n",
      "860a23551ac0: Waiting\n",
      "68d63385def6: Waiting\n",
      "865f53eecc40: Waiting\n",
      "70ac11bbf381: Waiting\n",
      "7a42c1978b2e: Waiting\n",
      "8d6d2c98840c: Waiting\n",
      "de51b5b1b318: Waiting\n",
      "3e0d0b3b5c1c: Waiting\n",
      "91a761249212: Waiting\n",
      "d0f13d58f7fa: Waiting\n",
      "2559630e37d2: Waiting\n",
      "1b8090778700: Waiting\n",
      "67793606273a: Waiting\n",
      "4ca3cacea924: Waiting\n",
      "bfdaa5a6754f: Waiting\n",
      "4aa043daa566: Waiting\n",
      "d684c579871f: Waiting\n",
      "c1d86dc35ba1: Waiting\n",
      "f8e1ddeececb: Waiting\n",
      "55f4be7d7adc: Waiting\n",
      "c104fa3a7626: Waiting\n",
      "630fcaa7a158: Waiting\n",
      "4a39f6623824: Waiting\n",
      "bf1f5a5d15b8: Waiting\n",
      "c9c9a9e1cad6: Waiting\n",
      "30bba30584e3: Waiting\n",
      "3b65ec22a9e9: Verifying Checksum\n",
      "3b65ec22a9e9: Download complete\n",
      "3d4731d03623: Verifying Checksum\n",
      "3d4731d03623: Download complete\n",
      "3b65ec22a9e9: Pull complete\n",
      "a364ca75fd6d: Verifying Checksum\n",
      "a364ca75fd6d: Download complete\n",
      "fd80d866e8b2: Verifying Checksum\n",
      "fd80d866e8b2: Download complete\n",
      "b00ff40d02d9: Verifying Checksum\n",
      "b00ff40d02d9: Download complete\n",
      "3036e9b94123: Verifying Checksum\n",
      "3036e9b94123: Download complete\n",
      "453fdcdda788: Verifying Checksum\n",
      "453fdcdda788: Download complete\n",
      "35e12ec5e515: Download complete\n",
      "11f61a475a23: Verifying Checksum\n",
      "11f61a475a23: Download complete\n",
      "79007799e2ed: Verifying Checksum\n",
      "79007799e2ed: Download complete\n",
      "24280cf31c9a: Verifying Checksum\n",
      "24280cf31c9a: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "5e9434e8ae41: Download complete\n",
      "88a3e778b5bf: Verifying Checksum\n",
      "88a3e778b5bf: Download complete\n",
      "fd80d866e8b2: Pull complete\n",
      "729af2b35d14: Verifying Checksum\n",
      "729af2b35d14: Download complete\n",
      "a364ca75fd6d: Pull complete\n",
      "3d4731d03623: Pull complete\n",
      "03eb76abf1e5: Verifying Checksum\n",
      "03eb76abf1e5: Download complete\n",
      "0852b4bd65a1: Download complete\n",
      "81cb421c2c25: Download complete\n",
      "3d6b664afa23: Verifying Checksum\n",
      "3d6b664afa23: Download complete\n",
      "30e0a3a7e9e5: Verifying Checksum\n",
      "30e0a3a7e9e5: Download complete\n",
      "91bba9bd0f1f: Verifying Checksum\n",
      "91bba9bd0f1f: Download complete\n",
      "a422be4dcb08: Download complete\n",
      "ca10bb6dc143: Verifying Checksum\n",
      "ca10bb6dc143: Download complete\n",
      "e48bbfc7d00e: Verifying Checksum\n",
      "e48bbfc7d00e: Download complete\n",
      "860a23551ac0: Download complete\n",
      "cc78be876588: Verifying Checksum\n",
      "cc78be876588: Download complete\n",
      "ad6568ad37e5: Verifying Checksum\n",
      "ad6568ad37e5: Download complete\n",
      "258a31babfce: Verifying Checksum\n",
      "258a31babfce: Download complete\n",
      "116ca0069c88: Verifying Checksum\n",
      "116ca0069c88: Download complete\n",
      "ede4a5022f61: Download complete\n",
      "154d6414dd17: Verifying Checksum\n",
      "154d6414dd17: Download complete\n",
      "e1f68d1c5137: Download complete\n",
      "0d4b5cd36c43: Download complete\n",
      "fc9b6547dc7c: Verifying Checksum\n",
      "fc9b6547dc7c: Download complete\n",
      "53a5c2e0251f: Download complete\n",
      "3e8f37aba8a2: Verifying Checksum\n",
      "3e8f37aba8a2: Download complete\n",
      "4a39f6623824: Verifying Checksum\n",
      "4a39f6623824: Download complete\n",
      "d684c579871f: Verifying Checksum\n",
      "d684c579871f: Download complete\n",
      "c104fa3a7626: Verifying Checksum\n",
      "c104fa3a7626: Download complete\n",
      "30bba30584e3: Verifying Checksum\n",
      "30bba30584e3: Download complete\n",
      "22f09e497c63: Download complete\n",
      "5f66cd739f31: Verifying Checksum\n",
      "5f66cd739f31: Download complete\n",
      "c9c9a9e1cad6: Verifying Checksum\n",
      "c9c9a9e1cad6: Download complete\n",
      "1b8090778700: Verifying Checksum\n",
      "1b8090778700: Download complete\n",
      "630fcaa7a158: Verifying Checksum\n",
      "630fcaa7a158: Download complete\n",
      "4ca3cacea924: Verifying Checksum\n",
      "4ca3cacea924: Download complete\n",
      "c1d86dc35ba1: Verifying Checksum\n",
      "c1d86dc35ba1: Download complete\n",
      "4aa043daa566: Verifying Checksum\n",
      "4aa043daa566: Download complete\n",
      "de51b5b1b318: Download complete\n",
      "55f4be7d7adc: Verifying Checksum\n",
      "55f4be7d7adc: Download complete\n",
      "bf1f5a5d15b8: Verifying Checksum\n",
      "bf1f5a5d15b8: Download complete\n",
      "f8e1ddeececb: Verifying Checksum\n",
      "f8e1ddeececb: Download complete\n",
      "68d63385def6: Verifying Checksum\n",
      "68d63385def6: Download complete\n",
      "70ac11bbf381: Verifying Checksum\n",
      "70ac11bbf381: Download complete\n",
      "865f53eecc40: Verifying Checksum\n",
      "865f53eecc40: Download complete\n",
      "2e6386dccac0: Verifying Checksum\n",
      "2e6386dccac0: Download complete\n",
      "67793606273a: Verifying Checksum\n",
      "67793606273a: Download complete\n",
      "bfdaa5a6754f: Verifying Checksum\n",
      "bfdaa5a6754f: Download complete\n",
      "3e0d0b3b5c1c: Verifying Checksum\n",
      "3e0d0b3b5c1c: Download complete\n",
      "8d6d2c98840c: Verifying Checksum\n",
      "8d6d2c98840c: Download complete\n",
      "2559630e37d2: Verifying Checksum\n",
      "2559630e37d2: Download complete\n",
      "d0f13d58f7fa: Verifying Checksum\n",
      "d0f13d58f7fa: Download complete\n",
      "91a761249212: Verifying Checksum\n",
      "91a761249212: Download complete\n",
      "7a42c1978b2e: Verifying Checksum\n",
      "7a42c1978b2e: Download complete\n",
      "2cb953eac694: Verifying Checksum\n",
      "2cb953eac694: Download complete\n",
      "53a5c2e0251f: Pull complete\n",
      "b00ff40d02d9: Pull complete\n",
      "3036e9b94123: Pull complete\n",
      "453fdcdda788: Pull complete\n",
      "35e12ec5e515: Pull complete\n",
      "11f61a475a23: Pull complete\n",
      "24280cf31c9a: Pull complete\n",
      "79007799e2ed: Pull complete\n",
      "03eb76abf1e5: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "5e9434e8ae41: Pull complete\n",
      "88a3e778b5bf: Pull complete\n",
      "929ce3ad5dc9: Download complete\n",
      "729af2b35d14: Pull complete\n",
      "30e0a3a7e9e5: Pull complete\n",
      "0852b4bd65a1: Pull complete\n",
      "81cb421c2c25: Pull complete\n",
      "3d6b664afa23: Pull complete\n",
      "3e8f37aba8a2: Pull complete\n",
      "91bba9bd0f1f: Pull complete\n",
      "a422be4dcb08: Pull complete\n",
      "ca10bb6dc143: Pull complete\n",
      "e48bbfc7d00e: Pull complete\n",
      "860a23551ac0: Pull complete\n",
      "cc78be876588: Pull complete\n",
      "ad6568ad37e5: Pull complete\n",
      "258a31babfce: Pull complete\n",
      "116ca0069c88: Pull complete\n",
      "ede4a5022f61: Pull complete\n",
      "154d6414dd17: Pull complete\n",
      "e1f68d1c5137: Pull complete\n",
      "0d4b5cd36c43: Pull complete\n",
      "fc9b6547dc7c: Pull complete\n",
      "de51b5b1b318: Pull complete\n",
      "d684c579871f: Pull complete\n",
      "4a39f6623824: Pull complete\n",
      "30bba30584e3: Pull complete\n",
      "c104fa3a7626: Pull complete\n",
      "22f09e497c63: Pull complete\n",
      "5f66cd739f31: Pull complete\n",
      "c9c9a9e1cad6: Pull complete\n",
      "630fcaa7a158: Pull complete\n",
      "1b8090778700: Pull complete\n",
      "4ca3cacea924: Pull complete\n",
      "4aa043daa566: Pull complete\n",
      "c1d86dc35ba1: Pull complete\n",
      "55f4be7d7adc: Pull complete\n",
      "f8e1ddeececb: Pull complete\n",
      "bf1f5a5d15b8: Pull complete\n",
      "68d63385def6: Pull complete\n",
      "865f53eecc40: Pull complete\n",
      "70ac11bbf381: Pull complete\n",
      "91a761249212: Pull complete\n",
      "2cb953eac694: Pull complete\n",
      "2e6386dccac0: Pull complete\n",
      "67793606273a: Pull complete\n",
      "bfdaa5a6754f: Pull complete\n",
      "3e0d0b3b5c1c: Pull complete\n",
      "8d6d2c98840c: Pull complete\n",
      "2559630e37d2: Pull complete\n",
      "d0f13d58f7fa: Pull complete\n",
      "929ce3ad5dc9: Pull complete\n",
      "7a42c1978b2e: Pull complete\n",
      "Digest: sha256:2475b7062a16cd7ba0e5eda0ff58f206400714aafd061d4d8a1a1e8aacd59668\n",
      "Status: Downloaded newer image for nvcr.io/nvidia/merlin/merlin-tensorflow:22.09\n",
      " ---> ec90adb8185e\n",
      "Step 2/7 : WORKDIR /\n",
      " ---> Running in 1b0533943d68\n",
      "Removing intermediate container 1b0533943d68\n",
      " ---> 42ce43daeda3\n",
      "Step 3/7 : COPY /serving/requirements.txt /requirements.txt\n",
      " ---> 826c24189aa8\n",
      "Step 4/7 : RUN pip install -r /requirements.txt\n",
      " ---> Running in b174e3436cef\n",
      "Collecting git+https://github.com/NVIDIA-Merlin/models.git (from -r /requirements.txt (line 7))\n",
      "  Cloning https://github.com/NVIDIA-Merlin/models.git to /tmp/pip-req-build-y9e1u5pc\n",
      "\u001b[91m  Running command git clone -q https://github.com/NVIDIA-Merlin/models.git /tmp/pip-req-build-y9e1u5pc\n",
      "\u001b[0m  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting uvicorn[standard]==0.15.0\n",
      "  Downloading uvicorn-0.15.0-py3-none-any.whl (54 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting fastapi==0.68.1\n",
      "  Downloading fastapi-0.68.1-py3-none-any.whl (52 kB)\n",
      "Collecting uvloop==0.15.2\n",
      "  Downloading uvloop-0.15.2-cp38-cp38-manylinux2010_x86_64.whl (4.7 MB)\n",
      "Collecting fastapi-utils\n",
      "  Downloading fastapi_utils-0.2.1-py3-none-any.whl (16 kB)\n",
      "Collecting google-cloud-aiplatform\n",
      "  Downloading google_cloud_aiplatform-1.18.3-py2.py3-none-any.whl (2.3 MB)\n",
      "Collecting nvtabular==1.3.3\n",
      "  Downloading nvtabular-1.3.3.tar.gz (132 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.11.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.6.0-py2.py3-none-any.whl (105 kB)\n",
      "Requirement already satisfied: merlin-core>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (8.1.3)\n",
      "Collecting asgiref>=3.4.0\n",
      "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
      "Collecting h11>=0.8\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: PyYAML>=5.1; extra == \"standard\" in /usr/local/lib/python3.8/dist-packages (from uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (6.0)\n",
      "Collecting watchgod>=0.6; extra == \"standard\"\n",
      "  Downloading watchgod-0.8.2-py3-none-any.whl (12 kB)\n",
      "Collecting python-dotenv>=0.13; extra == \"standard\"\n",
      "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
      "Collecting websockets>=9.1; extra == \"standard\"\n",
      "  Downloading websockets-10.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
      "Collecting httptools==0.2.*; extra == \"standard\"\n",
      "  Downloading httptools-0.2.0-cp38-cp38-manylinux1_x86_64.whl (354 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /usr/lib/python3/dist-packages (from gunicorn==20.1.0->-r /requirements.txt (line 2)) (45.2.0)\n",
      "Collecting starlette==0.14.2\n",
      "  Downloading starlette-0.14.2-py3-none-any.whl (60 kB)\n",
      "Collecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
      "  Downloading pydantic-1.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
      "Collecting sqlalchemy<2.0.0,>=1.3.12\n",
      "  Downloading SQLAlchemy-1.4.43-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform->-r /requirements.txt (line 6)) (3.19.5)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.0\n",
      "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-aiplatform->-r /requirements.txt (line 6)) (21.3)\n",
      "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
      "  Downloading google_cloud_bigquery-2.34.4-py2.py3-none-any.whl (206 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3\n",
      "  Downloading google_cloud_resource_manager-1.6.3-py2.py3-none-any.whl (233 kB)\n",
      "Collecting google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0\n",
      "  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n",
      "Collecting fsspec==2022.11.0\n",
      "  Downloading fsspec-2022.11.0-py3-none-any.whl (139 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (3.8.3)\n",
      "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (2.12.0)\n",
      "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (5.1.1)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.8/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (0.4.6)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from gcsfs->-r /requirements.txt (line 9)) (2.22.0)\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.4.0-py2.py3-none-any.whl (77 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: tensorflow-metadata>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.10.0)\n",
      "Requirement already satisfied: pandas<1.4.0dev0,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.3.5)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (7.0.0)\n",
      "Requirement already satisfied: betterproto<2.0.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.2.5)\n",
      "Requirement already satisfied: distributed>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2022.5.1)\n",
      "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (0.56.2)\n",
      "Requirement already satisfied: tqdm>=4.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (4.64.1)\n",
      "Requirement already satisfied: dask>=2022.3.0 in /usr/local/lib/python3.8/dist-packages (from merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2022.5.1)\n",
      "Requirement already satisfied: anyio<4,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (3.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.68.1->-r /requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" and (platform_machine == \"aarch64\" or (platform_machine == \"ppc64le\" or (platform_machine == \"x86_64\" or (platform_machine == \"amd64\" or (platform_machine == \"AMD64\" or (platform_machine == \"win32\" or platform_machine == \"WIN32\")))))) in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2.0.0,>=1.3.12->fastapi-utils->-r /requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging<22.0.0dev,>=14.3->google-cloud-aiplatform->-r /requirements.txt (line 6)) (3.0.9)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.38.1 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (1.41.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (2.8.2)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4\n",
      "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform->-r /requirements.txt (line 6)) (1.56.4)\n",
      "Collecting grpcio-status<2.0dev,>=1.33.2; extra == \"grpc\"\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (22.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs->-r /requirements.txt (line 9)) (4.0.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib->gcsfs->-r /requirements.txt (line 9)) (1.3.1)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Requirement already satisfied: absl-py<2.0.0,>=0.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.22.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<1.4.0dev0,>=1.2.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2022.2.1)\n",
      "Requirement already satisfied: stringcase in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: grpclib in /usr/local/lib/python3.8/dist-packages (from betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (0.4.3)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.26.12)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (6.2)\n",
      "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (3.1.2)\n",
      "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.0.4)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.7.0)\n",
      "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2.4.0)\n",
      "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (0.12.0)\n",
      "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (5.9.2)\n",
      "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.9\" in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (4.12.0)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (0.39.1)\n",
      "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<4,>=3.0.0->watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<4,>=3.0.0->watchgod>=0.6; extra == \"standard\"->uvicorn[standard]==0.15.0->-r /requirements.txt (line 1)) (2.8)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.2->gcsfs->-r /requirements.txt (line 9)) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->-r /requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: h2<5,>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (2.1.1)\n",
      "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2022.3.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata; python_version < \"3.9\"->numba>=0.54->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (3.8.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (4.0.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.8/dist-packages (from h2<5,>=3.1.0->grpclib->betterproto<2.0.0->merlin-core>=0.2.0->merlin-models==0.9.0+40.gd88c54027->-r /requirements.txt (line 7)) (6.0.1)\n",
      "Building wheels for collected packages: nvtabular, merlin-models\n",
      "  Building wheel for nvtabular (PEP 517): started\n",
      "  Building wheel for nvtabular (PEP 517): finished with status 'done'\n",
      "  Created wheel for nvtabular: filename=nvtabular-1.3.3-cp38-cp38-linux_x86_64.whl size=267325 sha256=5f2e7e6ae06b4f27de0f9f31a256e08969117569e7ccebfa0025c94b5acf8fec\n",
      "  Stored in directory: /root/.cache/pip/wheels/4a/77/fd/af573fde58e010040b863b7e552d4877f0b2c221bfcadb3cc6\n",
      "  Building wheel for merlin-models (PEP 517): started\n",
      "  Building wheel for merlin-models (PEP 517): finished with status 'done'\n",
      "  Created wheel for merlin-models: filename=merlin_models-0.9.0+40.gd88c54027-py3-none-any.whl size=364700 sha256=f6bec80d213336fb22cf1603ab2cf66252df157535cc4703b40979c53ca0c8ab\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-kbz83vy3/wheels/5a/43/99/d50fe2c33b4f4686db73207ce3865e0d6be6609ffb03abade5\n",
      "Successfully built nvtabular merlin-models\n",
      "\u001b[91mERROR: merlin-core 0.7.0 has requirement fsspec==2022.5.0, but you'll have fsspec 2022.11.0 which is incompatible.\n",
      "ERROR: grpcio-status 1.50.0 has requirement grpcio>=1.50.0, but you'll have grpcio 1.41.0 which is incompatible.\n",
      "ERROR: grpcio-status 1.50.0 has requirement protobuf>=4.21.6, but you'll have protobuf 3.19.5 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: asgiref, h11, watchgod, python-dotenv, websockets, httptools, uvloop, uvicorn, gunicorn, starlette, pydantic, fastapi, sqlalchemy, fastapi-utils, proto-plus, grpcio-status, google-api-core, google-crc32c, google-resumable-media, google-cloud-core, google-cloud-storage, google-cloud-bigquery, grpc-google-iam-v1, google-cloud-resource-manager, google-cloud-aiplatform, nvtabular, fsspec, gcsfs, merlin-models\n",
      "  Attempting uninstall: nvtabular\n",
      "    Found existing installation: nvtabular 1.5.0\n",
      "    Uninstalling nvtabular-1.5.0:\n",
      "      Successfully uninstalled nvtabular-1.5.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.5.0\n",
      "    Uninstalling fsspec-2022.5.0:\n",
      "      Successfully uninstalled fsspec-2022.5.0\n",
      "  Attempting uninstall: merlin-models\n",
      "    Found existing installation: merlin-models 0.8.0\n",
      "    Uninstalling merlin-models-0.8.0:\n",
      "      Successfully uninstalled merlin-models-0.8.0\n",
      "Successfully installed asgiref-3.5.2 fastapi-0.68.1 fastapi-utils-0.2.1 fsspec-2022.11.0 gcsfs-2022.11.0 google-api-core-2.10.2 google-cloud-aiplatform-1.18.3 google-cloud-bigquery-2.34.4 google-cloud-core-2.3.2 google-cloud-resource-manager-1.6.3 google-cloud-storage-2.6.0 google-crc32c-1.5.0 google-resumable-media-2.4.0 grpc-google-iam-v1-0.12.4 grpcio-status-1.50.0 gunicorn-20.1.0 h11-0.14.0 httptools-0.2.0 merlin-models-0.9.0+40.gd88c54027 nvtabular-1.3.3 proto-plus-1.22.1 pydantic-1.10.2 python-dotenv-0.21.0 sqlalchemy-1.4.43 starlette-0.14.2 uvicorn-0.15.0 uvloop-0.15.2 watchgod-0.8.2 websockets-10.4\n",
      "Removing intermediate container b174e3436cef\n",
      " ---> 61a64a562a45\n",
      "Step 5/7 : COPY /serving/app /app\n",
      " ---> f7e991680160\n",
      "Step 6/7 : EXPOSE 80\n",
      " ---> Running in 957bb6eb2d79\n",
      "Removing intermediate container 957bb6eb2d79\n",
      " ---> 69a8d4f60067\n",
      "Step 7/7 : CMD [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]\n",
      " ---> Running in e0751b8fc509\n",
      "Removing intermediate container e0751b8fc509\n",
      " ---> 223d33b956d9\n",
      "Successfully built 223d33b956d9\n",
      "Successfully tagged gcr.io/hybrid-vertex/merlin-vertex-serv-v11:latest\n",
      "PUSH\n",
      "Pushing gcr.io/hybrid-vertex/merlin-vertex-serv-v11\n",
      "The push refers to repository [gcr.io/hybrid-vertex/merlin-vertex-serv-v11]\n",
      "69d5ba4d0447: Preparing\n",
      "0c4154eaa602: Preparing\n",
      "397baf150f85: Preparing\n",
      "bd113aa55fbd: Preparing\n",
      "e58f9c500afd: Preparing\n",
      "c3c9ca29c9f2: Preparing\n",
      "e844c8057c95: Preparing\n",
      "0b07555d3a5b: Preparing\n",
      "a1537cf26842: Preparing\n",
      "00679b7c9426: Preparing\n",
      "add0b850bdf8: Preparing\n",
      "c2e412b87e2d: Preparing\n",
      "7730d4c011cd: Preparing\n",
      "f83c32bae622: Preparing\n",
      "86147dce553c: Preparing\n",
      "a86afd489635: Preparing\n",
      "725647e88671: Preparing\n",
      "78e008bc66d2: Preparing\n",
      "e7d002ddb49b: Preparing\n",
      "f2b540bc31be: Preparing\n",
      "442b3d22fc2d: Preparing\n",
      "72f4d03b40d8: Preparing\n",
      "54244453f24a: Preparing\n",
      "c9dfb1d8d420: Preparing\n",
      "c1af80eb8994: Preparing\n",
      "5c0e49e0fefd: Preparing\n",
      "64579a0c8694: Preparing\n",
      "82432f6543d2: Preparing\n",
      "efbb58199899: Preparing\n",
      "f390faf5524c: Preparing\n",
      "daee9dea71d9: Preparing\n",
      "dc74b4fa6312: Preparing\n",
      "cf7ec5236059: Preparing\n",
      "2784fc353e53: Preparing\n",
      "7730d4c011cd: Waiting\n",
      "4748e1954466: Preparing\n",
      "f83c32bae622: Waiting\n",
      "17dd0d3a32ca: Preparing\n",
      "86147dce553c: Waiting\n",
      "1a4d9b216faa: Preparing\n",
      "f2b540bc31be: Waiting\n",
      "29ec3f10d323: Preparing\n",
      "442b3d22fc2d: Waiting\n",
      "a86afd489635: Waiting\n",
      "72f4d03b40d8: Waiting\n",
      "725647e88671: Waiting\n",
      "b103452845b7: Preparing\n",
      "54244453f24a: Waiting\n",
      "5de10b8eda77: Preparing\n",
      "93a1a17119ba: Preparing\n",
      "78e008bc66d2: Waiting\n",
      "0b949eaca829: Preparing\n",
      "0b07555d3a5b: Waiting\n",
      "e7d002ddb49b: Waiting\n",
      "a1537cf26842: Waiting\n",
      "00679b7c9426: Waiting\n",
      "add0b850bdf8: Waiting\n",
      "c2e412b87e2d: Waiting\n",
      "82432f6543d2: Waiting\n",
      "76dffad7db12: Preparing\n",
      "c3c9ca29c9f2: Waiting\n",
      "e844c8057c95: Waiting\n",
      "efbb58199899: Waiting\n",
      "103f14ded07d: Preparing\n",
      "daee9dea71d9: Waiting\n",
      "f390faf5524c: Waiting\n",
      "05a0d2d578a6: Preparing\n",
      "1f7bd087086a: Preparing\n",
      "cf7ec5236059: Waiting\n",
      "5c0e49e0fefd: Waiting\n",
      "a03ce844e2ad: Preparing\n",
      "dc74b4fa6312: Waiting\n",
      "b5583e44add1: Preparing\n",
      "c1af80eb8994: Waiting\n",
      "4748e1954466: Waiting\n",
      "3ff439c0455c: Preparing\n",
      "2ee8c052052a: Preparing\n",
      "2784fc353e53: Waiting\n",
      "17dd0d3a32ca: Waiting\n",
      "1a4d9b216faa: Waiting\n",
      "f3154f787b0f: Preparing\n",
      "944a1106424f: Preparing\n",
      "93a1a17119ba: Waiting\n",
      "01386fafb257: Preparing\n",
      "8a9d499564b0: Preparing\n",
      "d882bfae03e4: Preparing\n",
      "5de10b8eda77: Waiting\n",
      "76dffad7db12: Waiting\n",
      "29ec3f10d323: Waiting\n",
      "5f70bf18a086: Preparing\n",
      "f3154f787b0f: Waiting\n",
      "1f7bd087086a: Waiting\n",
      "913f47d5362d: Preparing\n",
      "06f02804b89d: Preparing\n",
      "54beb86c2dbe: Preparing\n",
      "b5583e44add1: Waiting\n",
      "aa57b43dc9e0: Preparing\n",
      "ae5c80704277: Preparing\n",
      "3ff439c0455c: Waiting\n",
      "d1cc4baf7a93: Preparing\n",
      "8fd21a588646: Preparing\n",
      "b470f3b3096a: Preparing\n",
      "9af2b05f2c3b: Preparing\n",
      "4cf9aed48cda: Preparing\n",
      "01386fafb257: Waiting\n",
      "57f574ab1503: Preparing\n",
      "c5b9544e7743: Preparing\n",
      "c3f11d77a5de: Preparing\n",
      "54beb86c2dbe: Waiting\n",
      "05a0d2d578a6: Waiting\n",
      "d882bfae03e4: Waiting\n",
      "8fd21a588646: Waiting\n",
      "06f02804b89d: Waiting\n",
      "b470f3b3096a: Waiting\n",
      "57f574ab1503: Waiting\n",
      "0b949eaca829: Waiting\n",
      "c3f11d77a5de: Waiting\n",
      "a03ce844e2ad: Waiting\n",
      "ae5c80704277: Waiting\n",
      "2ee8c052052a: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "913f47d5362d: Waiting\n",
      "4cf9aed48cda: Waiting\n",
      "9af2b05f2c3b: Waiting\n",
      "944a1106424f: Waiting\n",
      "d1cc4baf7a93: Waiting\n",
      "e58f9c500afd: Layer already exists\n",
      "bd113aa55fbd: Layer already exists\n",
      "c3c9ca29c9f2: Layer already exists\n",
      "e844c8057c95: Layer already exists\n",
      "0b07555d3a5b: Layer already exists\n",
      "a1537cf26842: Layer already exists\n",
      "add0b850bdf8: Layer already exists\n",
      "00679b7c9426: Layer already exists\n",
      "7730d4c011cd: Layer already exists\n",
      "c2e412b87e2d: Layer already exists\n",
      "86147dce553c: Layer already exists\n",
      "f83c32bae622: Layer already exists\n",
      "a86afd489635: Layer already exists\n",
      "725647e88671: Layer already exists\n",
      "78e008bc66d2: Layer already exists\n",
      "e7d002ddb49b: Layer already exists\n",
      "f2b540bc31be: Layer already exists\n",
      "442b3d22fc2d: Layer already exists\n",
      "72f4d03b40d8: Layer already exists\n",
      "54244453f24a: Layer already exists\n",
      "c9dfb1d8d420: Layer already exists\n",
      "c1af80eb8994: Layer already exists\n",
      "69d5ba4d0447: Pushed\n",
      "397baf150f85: Pushed\n",
      "5c0e49e0fefd: Layer already exists\n",
      "64579a0c8694: Layer already exists\n",
      "82432f6543d2: Layer already exists\n",
      "efbb58199899: Layer already exists\n",
      "f390faf5524c: Layer already exists\n",
      "daee9dea71d9: Layer already exists\n",
      "dc74b4fa6312: Layer already exists\n",
      "cf7ec5236059: Layer already exists\n",
      "4748e1954466: Layer already exists\n",
      "2784fc353e53: Layer already exists\n",
      "17dd0d3a32ca: Layer already exists\n",
      "1a4d9b216faa: Layer already exists\n",
      "5de10b8eda77: Layer already exists\n",
      "b103452845b7: Layer already exists\n",
      "29ec3f10d323: Layer already exists\n",
      "93a1a17119ba: Layer already exists\n",
      "76dffad7db12: Layer already exists\n",
      "0b949eaca829: Layer already exists\n",
      "05a0d2d578a6: Layer already exists\n",
      "103f14ded07d: Layer already exists\n",
      "1f7bd087086a: Layer already exists\n",
      "a03ce844e2ad: Layer already exists\n",
      "b5583e44add1: Layer already exists\n",
      "3ff439c0455c: Layer already exists\n",
      "2ee8c052052a: Layer already exists\n",
      "f3154f787b0f: Layer already exists\n",
      "01386fafb257: Layer already exists\n",
      "944a1106424f: Layer already exists\n",
      "8a9d499564b0: Layer already exists\n",
      "d882bfae03e4: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "913f47d5362d: Layer already exists\n",
      "06f02804b89d: Layer already exists\n",
      "54beb86c2dbe: Layer already exists\n",
      "aa57b43dc9e0: Layer already exists\n",
      "ae5c80704277: Layer already exists\n",
      "d1cc4baf7a93: Layer already exists\n",
      "b470f3b3096a: Layer already exists\n",
      "8fd21a588646: Layer already exists\n",
      "9af2b05f2c3b: Layer already exists\n",
      "4cf9aed48cda: Layer already exists\n",
      "57f574ab1503: Layer already exists\n",
      "c5b9544e7743: Layer already exists\n",
      "c3f11d77a5de: Layer already exists\n",
      "0c4154eaa602: Pushed\n",
      "latest: digest: sha256:b51bf4d848bb7a433e74b86ca7891351ba26acb10bcd267a8a26975e176b45d5 size: 14847\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                       IMAGES                                                 STATUS\n",
      "aa73ebb1-a7cd-412e-8f84-a81f15abe095  2022-11-11T18:33:55+00:00  5M46S     gs://hybrid-vertex_cloudbuild/source/1668191634.654956-7861da43623d4552a36a65c4c1cf6618.tgz  gcr.io/hybrid-vertex/merlin-vertex-serv-v11 (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "! gcloud builds submit --config src/cloudbuild.yaml \\\n",
    "    --substitutions _DOCKERNAME=$DOCKERNAME,_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "    --timeout=2h \\\n",
    "    --machine-type=$MACHINE_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94bf61-afbc-4187-9460-251a37e67171",
   "metadata": {},
   "source": [
    "# Deploy Query Model to Vertex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a9295-e707-4127-aa76-42ed7fc756a5",
   "metadata": {},
   "source": [
    "## Upload to Model Regsitry\n",
    "\n",
    "* `parent_model` [src](https://github.com/googleapis/python-aiplatform/blob/main/google/cloud/aiplatform/models.py#L2831) code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6123427d-ee45-4c3f-9f6c-5f8bb5331fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DEPLOY_VERSION = \"v11\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7aa0466-d49c-44df-b636-dd3035824a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DISPLAY_NAME=f\"mm-qtower-{MODEL_DEPLOY_VERSION}\"\n",
    "MODEL_ARTIFACT_URI = 'gs://jt-merlin-scaling/pipes-2tower-merlin-tf-v5/run-v1-20221110-024710/model-dir2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6114bfba-7b2c-41ef-9828-1cfebb33cb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/934903580331/locations/us-central1/models/4560312437131182080/operations/458563762589270016\n",
      "Model created. Resource name: projects/934903580331/locations/us-central1/models/4560312437131182080@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/934903580331/locations/us-central1/models/4560312437131182080@1')\n",
      "Created model in 0.34 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "        display_name=MODEL_DISPLAY_NAME,\n",
    "        artifact_uri=MODEL_ARTIFACT_URI,\n",
    "        serving_container_image_uri=IMAGE_URI,\n",
    "        serving_container_predict_route='/predict',\n",
    "        serving_container_health_route='/health',\n",
    "        serving_container_command=[\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"],\n",
    "        serving_container_args='--gpus all',\n",
    "        # parent_model=PARENT_MODEL,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "print(f\"Created model in {round((time.process_time() - start),2)} seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1afd52-8bd6-49ed-ad8b-14bb470b850f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Model object at 0x7fb26cb6e490> \n",
       "resource name: projects/934903580331/locations/us-central1/models/4560312437131182080"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# existing model resource\n",
    "# MODEL_URI = 'projects/934903580331/locations/us-central1/models/4060694353469767680@1'\n",
    "# MODEL_URI = \"projects/934903580331/locations/us-central1/models/3574305593713754112\" # 50 epoch\n",
    "# model = vertex_ai.Model(MODEL_URI)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c799802-643a-4650-be6f-3d670479af0a",
   "metadata": {},
   "source": [
    "## Deploy to Vertex AI Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d65883-ba63-4b6c-b128-73f7b7122075",
   "metadata": {},
   "source": [
    "### deployment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a03fd66-72ed-40de-8dcc-c4eca468b142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# service account for predictions\n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "# model and endpoint display names\n",
    "# MODEL_DISPLAY_NAME=f\"mm-retrieval-{VERSION_serving}\"\n",
    "DEPLOYED_MODEL_DISPLAY_NAME=f\"nb-deployed-{MODEL_DISPLAY_NAME}\"\n",
    "ENDPOINT_DISPLAY_NAME = f\"mm-endpoint-{MODEL_DEPLOY_VERSION}\"\n",
    "\n",
    "# Endpoint resource config\n",
    "DEPLOY_COMPUTE=\"n1-standard-4\"\n",
    "DEPLOY_GPU=\"NVIDIA_TESLA_T4\"\n",
    "DEPLOY_NGPU=1\n",
    "MIN_NODES=1\n",
    "MAX_NODES=1\n",
    "TRAFFIC=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bc4d5d-20e8-4d25-9afa-820be25fdcbc",
   "metadata": {},
   "source": [
    "### create model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea1247f8-fe16-4e46-98c5-4bb7a79a846d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/934903580331/locations/us-central1/endpoints/6231227063722835968/operations/926375173882380288\n",
      "Endpoint created. Resource name: projects/934903580331/locations/us-central1/endpoints/6231227063722835968\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/934903580331/locations/us-central1/endpoints/6231227063722835968')\n",
      "Created endpoint in 0.14 seconds\n",
      "\n",
      "<google.cloud.aiplatform.models.Endpoint object at 0x7fb26cbea550> \n",
      "resource name: projects/934903580331/locations/us-central1/endpoints/6231227063722835968\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.create(\n",
    "    display_name=ENDPOINT_DISPLAY_NAME,\n",
    "    project=PROJECT_ID,\n",
    "    location=LOCATION,\n",
    ")\n",
    "\n",
    "print(f\"Created endpoint in {round((time.process_time() - start),2)} seconds\\n\")\n",
    "\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a28159-10dd-4ee9-adf6-5336c0edb496",
   "metadata": {},
   "source": [
    "### deploy model to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a8cec7c-7cbf-4b70-b7b6-b56cdafa5e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model to Endpoint : projects/934903580331/locations/us-central1/endpoints/6231227063722835968\n",
      "Deploy Endpoint model backing LRO: projects/934903580331/locations/us-central1/endpoints/6231227063722835968/operations/7595080322111242240\n",
      "Endpoint model deployed. Resource name: projects/934903580331/locations/us-central1/endpoints/6231227063722835968\n",
      "Deployed model to endpoint in 0.99 seconds\n",
      "\n",
      "<google.cloud.aiplatform.models.Model object at 0x7fb26cb6e490> \n",
      "resource name: projects/934903580331/locations/us-central1/models/4560312437131182080\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "model.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "    machine_type=DEPLOY_COMPUTE,\n",
    "    min_replica_count=MIN_NODES,\n",
    "    max_replica_count=MAX_NODES,\n",
    "    traffic_percentage=TRAFFIC,\n",
    "    accelerator_type=DEPLOY_GPU,\n",
    "    accelerator_count=DEPLOY_NGPU,\n",
    "    service_account=VERTEX_SA,\n",
    "    sync=True\n",
    ")\n",
    "\n",
    "print(f\"Deployed model to endpoint in {round((time.process_time() - start),2)} seconds\\n\")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d36c9e-1d90-4c5c-9220-7fc824e42f73",
   "metadata": {},
   "source": [
    "#### check endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c32166d9-0ba4-4932-aefa-83d31f9d7098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: \"5064566061815300096\"\n",
      "model: \"projects/934903580331/locations/us-central1/models/4060694353469767680\"\n",
      "display_name: \"mm_qtower_test_v7\"\n",
      "create_time {\n",
      "  seconds: 1668150467\n",
      "  nanos: 265666000\n",
      "}\n",
      "dedicated_resources {\n",
      "  machine_spec {\n",
      "    machine_type: \"n1-standard-4\"\n",
      "    accelerator_type: NVIDIA_TESLA_T4\n",
      "    accelerator_count: 1\n",
      "  }\n",
      "  min_replica_count: 1\n",
      "  max_replica_count: 1\n",
      "}\n",
      "service_account: \"934903580331-compute@developer.gserviceaccount.com\"\n",
      "model_version_id: \"1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(endpoint.gca_resource.deployed_models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171104a3-490f-49bf-9662-2012efb35595",
   "metadata": {},
   "source": [
    "## Test Deployed Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73deb8-8987-4a18-beb3-c92c1bbbe956",
   "metadata": {},
   "source": [
    "### create sample test instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0d4ce601-e960-43a7-ace8-3fd2fa93313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {\n",
    "    'collaborative': 'false',\n",
    "    'album_name_pl': [\n",
    "        \"There's Really A Wolf\", 'Late Nights: The Album','American Teen', 'Crazy In Love', 'Pony'\n",
    "    ], \n",
    "    'artist_genres_pl': [\n",
    "        \"'hawaiian hip hop', 'rap'\",\n",
    "       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"\n",
    "    ], \n",
    "    'artist_name_pl': [\n",
    "        'Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9','William Singe'\n",
    "    ], \n",
    "    'artist_pop_can': 82.0, \n",
    "    'description_pl': '', \n",
    "    'duration_ms_songs_pl': [\n",
    "        237506.0, 217200.0, 219080.0, 226400.0, 121739.0\n",
    "    ], \n",
    "    'n_songs_pl': 8.0, \n",
    "    'name': 'Lit Tunes ', \n",
    "    'num_albums_pl': 8.0, \n",
    "    'num_artists_pl': 8.0, \n",
    "    'track_name_pl': [\n",
    "        'Losin Control', 'Paradise', 'Location','Crazy In Love - Remix', 'Pony'\n",
    "    ], \n",
    "    'track_pop_pl': [\n",
    "        79.0, 58.0, 83.0, 71.0, 57.0\n",
    "    ],\n",
    "    'duration_ms_seed_pl': 51023.1,\n",
    "    'pid': 1,\n",
    "    'track_uri_pl': [\n",
    "        'spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "        'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "        'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "        'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "        'spotify:track:4Lj8paMFwyKTGfILLELVxt'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4290522-d95f-4043-b18d-52d3266d3ee4",
   "metadata": {},
   "source": [
    "### make prediction request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7561c1c0-2be9-4ef1-b460-a3067eec6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "dd721e42-3d13-4046-99f9-966cb50b28db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors retrieved in 0.12 seconds\n",
      "Vector Dimensions: 128\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.4964520633220673,\n",
       "  0.5604552030563354,\n",
       "  0.0,\n",
       "  0.5495439171791077,\n",
       "  0.0,\n",
       "  0.1598391383886337,\n",
       "  0.0,\n",
       "  0.8183088898658752,\n",
       "  2.817295074462891,\n",
       "  0.2966776490211487,\n",
       "  0.165576845407486,\n",
       "  0.5191221833229065,\n",
       "  1.430994272232056,\n",
       "  0.0,\n",
       "  0.3241373300552368,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5781844258308411,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.366185665130615,\n",
       "  0.0,\n",
       "  0.1283302456140518,\n",
       "  0.165629118680954,\n",
       "  0.0,\n",
       "  1.512356758117676,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.8049782514572144,\n",
       "  4.366167068481445,\n",
       "  0.0,\n",
       "  0.9294438362121582,\n",
       "  0.1463523507118225,\n",
       "  0.0,\n",
       "  2.721257209777832,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.3107767999172211,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.08193261176347733,\n",
       "  0.1614352613687515,\n",
       "  0.0,\n",
       "  1.387633681297302,\n",
       "  1.532091498374939,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.248701333999634,\n",
       "  0.0,\n",
       "  0.09303939342498779,\n",
       "  1.476220369338989,\n",
       "  0.5754297971725464,\n",
       "  2.056629180908203,\n",
       "  0.0,\n",
       "  0.7716501355171204,\n",
       "  0.0,\n",
       "  0.0826091468334198,\n",
       "  1.439555644989014,\n",
       "  0.0,\n",
       "  1.09518039226532,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.9007233381271362,\n",
       "  1.540234684944153,\n",
       "  0.9302117824554443,\n",
       "  0.0,\n",
       "  0.06900937855243683,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.6677276492118835,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.573910236358643,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.5983467102050781,\n",
       "  0.9941506385803223,\n",
       "  1.198778867721558,\n",
       "  0.5120538473129272,\n",
       "  0.3574476540088654,\n",
       "  0.0,\n",
       "  0.8511934876441956,\n",
       "  0.5943729877471924,\n",
       "  0.0,\n",
       "  0.1548095643520355,\n",
       "  0.0,\n",
       "  0.374154269695282,\n",
       "  0.2666419744491577,\n",
       "  2.787921190261841,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.912954330444336,\n",
       "  0.02420709654688835,\n",
       "  0.0,\n",
       "  0.7003491520881653,\n",
       "  0.0,\n",
       "  0.09257082641124725,\n",
       "  0.04434563219547272,\n",
       "  0.0,\n",
       "  0.0699232965707779,\n",
       "  0.2487395107746124,\n",
       "  0.5050799250602722,\n",
       "  0.2842888534069061,\n",
       "  0.0,\n",
       "  0.2341521829366684,\n",
       "  4.195619106292725,\n",
       "  0.2216274440288544,\n",
       "  1.078157901763916,\n",
       "  0.1358898431062698,\n",
       "  0.0,\n",
       "  1.519026756286621,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.095138192176819,\n",
       "  0.1179374232888222,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "playlist_emb = endpoint.predict(instances=[TEST_INSTANCE])\n",
    "\n",
    "print(f\"neighbors retrieved in {round((time.process_time() - start),2)} seconds\")\n",
    "print(f\"Vector Dimensions: {len(playlist_emb.predictions[0])}\\n\")\n",
    "\n",
    "playlist_emb.predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77980d4f-ec22-47db-9af9-05d6fb97dad0",
   "metadata": {},
   "source": [
    "### prediction latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7a079e19-fcb2-4653-97a9-acf1d307e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.06 s  419 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c908c7c-545f-4145-9029-a9549ee288e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "endpoint.predict(instances=[[TEST_INSTANCE, TEST_INSTANCE]])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
