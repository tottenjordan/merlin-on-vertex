{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fb7941-cf7c-4ff4-aab3-86f68879e618",
   "metadata": {},
   "source": [
    "# Train and Deploy Merlin models with Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a796242f-4f0e-454e-aba0-5eb6ba87f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp\n",
    "# !pip install google-cloud-pipeline-components --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5337f359-59e6-4bff-a1cd-3504e500c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "# ! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "# ! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550909fb-6604-4907-8cb9-14395fd2b15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ID: hybrid-vertex\n",
      "PROJECT_NUM: 934903580331\n",
      "LOCATION: us-central1\n"
     ]
    }
   ],
   "source": [
    "GCP_PROJECTS = !gcloud config get-value project\n",
    "PROJECT_ID = GCP_PROJECTS[0]\n",
    "PROJECT_NUM = !gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUM = PROJECT_NUM[0]\n",
    "LOCATION = 'us-central1'\n",
    "\n",
    "print(f\"PROJECT_ID: {PROJECT_ID}\")\n",
    "print(f\"PROJECT_NUM: {PROJECT_NUM}\")\n",
    "print(f\"LOCATION: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e184436e-2656-4d6e-bb31-bc2d1147b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b42c134e-2fef-49e9-aaa2-c33906673e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abff2a0-3022-4d0e-9423-4cc067da146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'train_pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e50ebd1-4f72-41b1-89e1-3be35d62bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2d38e-459a-4ccd-9ae8-928a86ed2474",
   "metadata": {},
   "source": [
    "# Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5c12ae-40ef-485a-aa02-c0fc116ca33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/merlin-on-vertex'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98a7ed-ec46-43b6-aad0-18e4edc040fb",
   "metadata": {},
   "source": [
    "## Build Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55c8639e-d29a-4441-a315-1ce0b1c33ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/build_custom_image.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/build_custom_image.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"gcr.io/google.com/cloudsdktool/cloud-sdk:latest\",\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-build\"\n",
    "    ],\n",
    ")\n",
    "def build_custom_image(\n",
    "    project: str,\n",
    "    artifact_gcs_path: str,\n",
    "    docker_name: str,\n",
    "    app_dir_name: str,\n",
    "    custom_image_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('custom_image_uri', str),\n",
    "]):\n",
    "    # TODO: make output Artifact for image_uri\n",
    "    \"\"\"\n",
    "    custom pipeline component to build custom image using\n",
    "    Cloud Build, the training/serving application code, and dependencies\n",
    "    defined in the Dockerfile\n",
    "    \"\"\"\n",
    "    \n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    from google.cloud.devtools import cloudbuild_v1 as cloudbuild\n",
    "    from google.protobuf.duration_pb2 import Duration\n",
    "\n",
    "    # initialize client for cloud build\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    build_client = cloudbuild.services.cloud_build.CloudBuildClient()\n",
    "    \n",
    "    # parse step inputs to get path to Dockerfile and training application code\n",
    "    _gcs_dockerfile_path = os.path.join(artifact_gcs_path, f\"{docker_name}\") # Dockerfile.XXXXX\n",
    "    _gcs_script_dir_path = os.path.join(artifact_gcs_path, f\"{app_dir_name}/\") # \"trainer/\"\n",
    "    \n",
    "    logging.info(f\"_gcs_dockerfile_path: {_gcs_dockerfile_path}\")\n",
    "    logging.info(f\"_gcs_script_dir_path: {_gcs_script_dir_path}\")\n",
    "    \n",
    "    # define build steps to pull the training code and Dockerfile\n",
    "    # and build/push the custom training container image\n",
    "    build = cloudbuild.Build()\n",
    "    build.steps = [\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\"cp\", \"-r\", _gcs_script_dir_path, \".\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\"cp\", _gcs_dockerfile_path, \"Dockerfile\"],\n",
    "        },\n",
    "        # enabling Kaniko cache in a Docker build that caches intermediate\n",
    "        # layers and pushes image automatically to Container Registry\n",
    "        # https://cloud.google.com/build/docs/kaniko-cache\n",
    "        # {\n",
    "        #     \"name\": \"gcr.io/kaniko-project/executor:latest\",\n",
    "        #     # \"name\": \"gcr.io/kaniko-project/executor:v1.8.0\",        # TODO; downgraded to avoid error in build\n",
    "        #     # \"args\": [f\"--destination={training_image_uri}\", \"--cache=true\"],\n",
    "        #     \"args\": [f\"--destination={training_image_uri}\", \"--cache=false\"],\n",
    "        # },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "            \"args\": ['build','-t', f'{custom_image_uri}', '.'],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "            \"args\": ['push', f'{custom_image_uri}'], \n",
    "        },\n",
    "    ]\n",
    "    # override default timeout of 10min\n",
    "    timeout = Duration()\n",
    "    timeout.seconds = 7200\n",
    "    build.timeout = timeout\n",
    "\n",
    "    # create build\n",
    "    operation = build_client.create_build(project_id=project, build=build)\n",
    "    logging.info(\"IN PROGRESS:\")\n",
    "    logging.info(operation.metadata)\n",
    "\n",
    "    # get build status\n",
    "    result = operation.result()\n",
    "    logging.info(\"RESULT:\", result.status)\n",
    "\n",
    "    # return step outputs\n",
    "    return (\n",
    "        custom_image_uri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9cd2-58a1-4b75-a608-cbc1888ad921",
   "metadata": {},
   "source": [
    "## Train Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d882a90-2445-463e-9005-f83a87f78682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/train_merlin.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/train_merlin.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def train_merlin(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    train_image_uri: str,     # TODO: Artifact\n",
    "    tb_resource: str,\n",
    "    batch_size: int, \n",
    "    train_epochs: int,\n",
    "    train_dir: str,\n",
    "    valid_dir: str,\n",
    "    workflow_dir: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    "    service_account: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('merlin_model_gcs_dir', str),\n",
    "    ('query_tower_gcs_dir', str),\n",
    "    ('candidate_tower_gcs_uri', str),\n",
    "    ('candidate_embeddings_gcs_uri', str),\n",
    "]):\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # ====================================================\n",
    "    # Helper function for workerpool specs\n",
    "    # ====================================================\n",
    "    def prepare_worker_pool_specs(\n",
    "        image_uri,\n",
    "        # args,\n",
    "        cmd,\n",
    "        replica_count=1,\n",
    "        machine_type=\"n1-standard-16\",\n",
    "        accelerator_count=1,\n",
    "        accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "        reduction_server_count=0,\n",
    "        reduction_server_machine_type=\"n1-highcpu-16\",\n",
    "        reduction_server_image_uri=\"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\",\n",
    "    ):\n",
    "\n",
    "        if accelerator_count > 0:\n",
    "            machine_spec = {\n",
    "                \"machine_type\": machine_type,\n",
    "                \"accelerator_type\": accelerator_type,\n",
    "                \"accelerator_count\": accelerator_count,\n",
    "            }\n",
    "        else:\n",
    "            machine_spec = {\"machine_type\": machine_type}\n",
    "\n",
    "        container_spec = {\n",
    "            \"image_uri\": image_uri,\n",
    "            # \"args\": args,\n",
    "            \"command\": cmd,\n",
    "        }\n",
    "\n",
    "        chief_spec = {\n",
    "            \"replica_count\": 1,\n",
    "            \"machine_spec\": machine_spec,\n",
    "            \"container_spec\": container_spec,\n",
    "        }\n",
    "\n",
    "        worker_pool_specs = [chief_spec]\n",
    "        if replica_count > 1:\n",
    "            workers_spec = {\n",
    "                \"replica_count\": replica_count - 1,\n",
    "                \"machine_spec\": machine_spec,\n",
    "                \"container_spec\": container_spec,\n",
    "            }\n",
    "            worker_pool_specs.append(workers_spec)\n",
    "        if reduction_server_count > 1:\n",
    "            workers_spec = {\n",
    "                \"replica_count\": reduction_server_count,\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": reduction_server_machine_type,\n",
    "                },\n",
    "                \"container_spec\": {\"image_uri\": reduction_server_image_uri},\n",
    "            }\n",
    "            worker_pool_specs.append(workers_spec)\n",
    "\n",
    "        return worker_pool_specs\n",
    "    \n",
    "    # ====================================================\n",
    "    # Define device strategy\n",
    "    # ====================================================\n",
    "    # TODO: parameterize\n",
    "    \n",
    "    WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    \n",
    "    # ====================================================\n",
    "    # # DEFINE ARGS\n",
    "    # ====================================================\n",
    "    # TODO: parameterize\n",
    "    \n",
    "    BATCH_SIZE = 4096*4      # TODO: `batch_size * 4 ? jw\n",
    "    LEARNING_RATE = 0.001\n",
    "    LAYERS = \"[512, 256, 128]\"\n",
    "    \n",
    "    OUTPUT_BUCKET = 'jt-merlin-scaling'\n",
    "    \n",
    "    EXPERIMENT_RUN = f'{experiment_run}-{TIMESTAMP}'\n",
    "    \n",
    "    WORKER_CMD = [\n",
    "        'sh',\n",
    "        '-euc',\n",
    "        f'''pip freeze && python -m trainer.train_task --tb_name={tb_resource} --per_gpu_batch_size={batch_size} \\\n",
    "        --train_output_bucket={OUTPUT_BUCKET} --train_dir={train_dir} --valid_dir={valid_dir} --workflow_dir={workflow_dir} \\\n",
    "        --num_epochs={train_epochs} --learning_rate={LEARNING_RATE} --distribute={DISTRIBUTE_STRATEGY} \\\n",
    "        --experiment_name={experiment_name} --experiment_run={EXPERIMENT_RUN} --project={project} --location={location}'''\n",
    "    ]\n",
    "    \n",
    "    WORKER_POOL_SPECS = prepare_worker_pool_specs(\n",
    "        image_uri=train_image_uri,\n",
    "        # args=WORKER_ARGS,\n",
    "        cmd=WORKER_CMD,\n",
    "        replica_count=REPLICA_COUNT,\n",
    "        machine_type=WORKER_MACHINE_TYPE,\n",
    "        accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "        accelerator_type=ACCELERATOR_TYPE,\n",
    "        reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "        reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    "    )\n",
    "    # ==============================================================================\n",
    "    # Submit Train Job \n",
    "    # ==============================================================================\n",
    "    STAGING_BUCKET = f'gs://{OUTPUT_BUCKET}/{experiment_name}'\n",
    "    JOB_NAME = f'train-merlin-retrieval-{version}'\n",
    "    gpu_type = ACCELERATOR_TYPE.lower() # lowercase for labels\n",
    "\n",
    "    job = vertex_ai.CustomJob(\n",
    "        display_name=JOB_NAME,\n",
    "        worker_pool_specs=WORKER_POOL_SPECS,\n",
    "        staging_bucket=STAGING_BUCKET,\n",
    "        labels={\n",
    "            'gpu': f'{gpu_type}',\n",
    "            'gpu_per_replica' : f'{PER_MACHINE_ACCELERATOR_COUNT}',\n",
    "            'replica_cnt' : f'{REPLICA_COUNT}',\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    job.run(\n",
    "        sync=True, \n",
    "        service_account=service_account,\n",
    "        # tensorboard=EXPERIMENT_TB,\n",
    "        restart_job_on_worker_restart=False,\n",
    "        enable_web_access=True,\n",
    "    )\n",
    "    \n",
    "    # uris set during train script\n",
    "    WORKING_DIR_GCS_URI = f'gs://{OUTPUT_BUCKET}/{experiment_name}/{EXPERIMENT_RUN}'\n",
    "    MODEL_DIR = f\"{WORKING_DIR_GCS_URI}/model-dir\"\n",
    "    QUERY_TOWER_PATH = f\"{MODEL_DIR}/query-tower\"\n",
    "    CANDIDATE_TOWER_PATH = f\"{MODEL_DIR}/candidate-tower\"\n",
    "    EMBEDDINGS_PATH = f\"{MODEL_DIR}/candidate-embeddings\"\n",
    "    \n",
    "    logging.info(f'WORKING_DIR_GCS_URI: {WORKING_DIR_GCS_URI}')\n",
    "    logging.info(f'MODEL_DIR: {MODEL_DIR}')\n",
    "    logging.info(f'QUERY_TOWER_PATH: {QUERY_TOWER_PATH}')\n",
    "    logging.info(f'CANDIDATE_TOWER_PATH: {CANDIDATE_TOWER_PATH}')\n",
    "    logging.info(f'EMBEDDINGS_PATH: {EMBEDDINGS_PATH}')\n",
    "    \n",
    "    return (\n",
    "        f'{MODEL_DIR}',\n",
    "        f'{QUERY_TOWER_PATH}',\n",
    "        f'{CANDIDATE_TOWER_PATH}',\n",
    "        f'{EMBEDDINGS_PATH}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d6c711-328f-4779-bcec-91bcefff76dc",
   "metadata": {},
   "source": [
    "## Create ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf39168b-735f-447a-bcf4-d58474879c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str, \n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    ann_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    leaf_node_embedding_count: int,\n",
    "    leaf_nodes_to_search_percent: int, \n",
    "    ann_index_description: str,\n",
    "    # ann_index_labels: Dict, \n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('ann_index', Artifact),\n",
    "]):\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(f\"ENDPOINT: {ENDPOINT}\")\n",
    "    logging.info(f\"project: {project}\")\n",
    "    logging.info(f\"location: {location}\")\n",
    "    logging.info(f\"INDEX_DIR_GCS: {INDEX_DIR_GCS}\")\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "        \n",
    "    tree_ah_index = vertex_ai.MatchingEngineIndex.create_tree_ah_index(\n",
    "        display_name=f'{ann_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        leaf_node_embedding_count=leaf_node_embedding_count,\n",
    "        leaf_nodes_to_search_percent=leaf_nodes_to_search_percent,\n",
    "        description=ann_index_description,\n",
    "        # labels=ann_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed_time = round((end - start), 2)\n",
    "    logging.info(f'Elapsed time creating index: {elapsed_time} seconds\\n')\n",
    "    \n",
    "    ann_index_resource_uri = tree_ah_index.resource_name\n",
    "    logging.info(\"ann_index_resource_uri:\", ann_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{ann_index_resource_uri}',\n",
    "      tree_ah_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26d57a-354a-4083-86aa-cafdcbe284fa",
   "metadata": {},
   "source": [
    "## Create brute force index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78389c19-9a24-439d-aa43-ca5a06c3ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_brute_force_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_force_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_brute_force_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    emb_index_gcs_uri: str,\n",
    "    dimensions: int,\n",
    "    brute_force_index_display_name: str,\n",
    "    approximate_neighbors_count: int,\n",
    "    distance_measure_type: str,\n",
    "    brute_force_index_description: str,\n",
    "    # brute_force_index_labels: Dict,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('brute_force_index', Artifact),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    \n",
    "    ENDPOINT = \"{}-aiplatform.googleapis.com\".format(location)\n",
    "    NETWORK_NAME = vpc_network_name\n",
    "    INDEX_DIR_GCS = emb_index_gcs_uri\n",
    "    PARENT = \"projects/{}/locations/{}\".format(project, location)\n",
    "\n",
    "    logging.info(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "    logging.info(\"PROJECT_ID: {}\".format(project))\n",
    "    logging.info(\"REGION: {}\".format(location))\n",
    "    \n",
    "    # ==============================================================================\n",
    "    # Create Index \n",
    "    # ==============================================================================\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    brute_force_index = vertex_ai.MatchingEngineIndex.create_brute_force_index(\n",
    "        display_name=f'{brute_force_index_display_name}-{TIMESTAMP}',\n",
    "        contents_delta_uri=f'{emb_index_gcs_uri}/', # emb_index_gcs_uri,\n",
    "        dimensions=dimensions,\n",
    "        # approximate_neighbors_count=approximate_neighbors_count,\n",
    "        distance_measure_type=distance_measure_type,\n",
    "        description=brute_force_index_description,\n",
    "        # labels=brute_force_index_labels,\n",
    "        # sync=True,\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_force_index.resource_name\n",
    "    print(\"brute_force_index_resource_uri:\",brute_force_index_resource_uri) \n",
    "\n",
    "    return (\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      brute_force_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d56f08-c92a-405f-8432-9866add59005",
   "metadata": {},
   "source": [
    "## Create ANN index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0c7a4c-6270-43b8-83a9-e11f82aaaea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_ann_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_ann_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_ann_index_endpoint_vpc(\n",
    "    ann_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    ann_index_endpoint_display_name: str,\n",
    "    ann_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('ann_index_endpoint_resource_uri', str),\n",
    "    ('ann_index_endpoint', Artifact),\n",
    "    ('ann_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    ann_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{ann_index_endpoint_display_name}',\n",
    "        description=ann_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    ann_index_endpoint_resource_uri = ann_index_endpoint.resource_name\n",
    "    logging.info(f\"ann_index_endpoint_resource_uri: {ann_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "        f'{vpc_network_resource_uri}',\n",
    "        f'{ann_index_endpoint_resource_uri}',\n",
    "        ann_index_endpoint,\n",
    "        f'{ann_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12337261-4471-49de-af2d-7c09f5196fa5",
   "metadata": {},
   "source": [
    "## Create brute force index endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6478a8e7-da31-46f1-9f7b-22b90a38a002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/create_brute_index_endpoint_vpc.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/create_brute_index_endpoint_vpc.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def create_brute_index_endpoint_vpc(\n",
    "    bf_index_artifact: Input[Artifact],\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    vpc_network_name: str,\n",
    "    brute_index_endpoint_display_name: str,\n",
    "    brute_index_endpoint_description: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('vpc_network_resource_uri', str),\n",
    "    ('brute_index_endpoint_resource_uri', str),\n",
    "    ('brute_index_endpoint', Artifact),\n",
    "    ('brute_index_endpoint_display_name', str),\n",
    "]):\n",
    "\n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    vpc_network_resource_uri = f'projects/{project_number}/global/networks/{vpc_network_name}'\n",
    "    logging.info(f\"vpc_network_resource_uri: {vpc_network_resource_uri}\")\n",
    "\n",
    "    brute_index_endpoint = vertex_ai.MatchingEngineIndexEndpoint.create(\n",
    "        display_name=f'{brute_index_endpoint_display_name}',\n",
    "        description=brute_index_endpoint_description,\n",
    "        network=vpc_network_resource_uri,\n",
    "    )\n",
    "    brute_index_endpoint_resource_uri = brute_index_endpoint.resource_name\n",
    "    logging.info(f\"brute_index_endpoint_resource_uri: {brute_index_endpoint_resource_uri}\")\n",
    "\n",
    "    return (\n",
    "      f'{vpc_network_resource_uri}',\n",
    "      f'{brute_index_endpoint_resource_uri}',\n",
    "      brute_index_endpoint,\n",
    "      f'{brute_index_endpoint_display_name}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3875fbd6-a4f4-42f0-8186-65a8f4bc9156",
   "metadata": {},
   "source": [
    "## Deploy ANN Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af0825f-68a1-4baa-afce-2a9375c5c526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/deploy_ann_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_ann_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1'\n",
    "    ]\n",
    ")\n",
    "def deploy_ann_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    deployed_ann_index_name: str,\n",
    "    ann_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('ann_index_resource_uri', str),\n",
    "    ('deployed_ann_index_name', str),\n",
    "    ('deployed_ann_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    VERSION = version\n",
    "    \n",
    "    ann_index = vertex_ai.MatchingEngineIndex(\n",
    "      index_name=ann_index_resource_uri\n",
    "    )\n",
    "    ann_index_resource_uri = ann_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(\n",
    "      index_endpoint_resource_uri\n",
    "    )\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "      index=ann_index, \n",
    "      deployed_index_id=f'{deployed_ann_index_name}' #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    logging.info(f\"index_endpoint.deployed_indexes: {index_endpoint.deployed_indexes}\")\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{ann_index_resource_uri}',\n",
    "      f'{deployed_ann_index_name}',\n",
    "      ann_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376252ba-4728-4406-8e7f-aa54b2a4d240",
   "metadata": {},
   "source": [
    "## Deploy brute force Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6d9149f-fbaf-4703-8850-4bc975d266c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train_pipes/deploy_brute_index.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/deploy_brute_index.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def deploy_brute_index(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    deployed_brute_force_index_name: str,\n",
    "    brute_force_index_resource_uri: str,\n",
    "    index_endpoint_resource_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('index_endpoint_resource_uri', str),\n",
    "    ('brute_force_index_resource_uri', str),\n",
    "    ('deployed_brute_force_index_name', str),\n",
    "    ('deployed_brute_force_index', Artifact),\n",
    "]):\n",
    "  \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    brute_index = vertex_ai.MatchingEngineIndex(\n",
    "        index_name=brute_force_index_resource_uri\n",
    "    )\n",
    "    brute_force_index_resource_uri = brute_index.resource_name\n",
    "\n",
    "    index_endpoint = vertex_ai.MatchingEngineIndexEndpoint(index_endpoint_resource_uri)\n",
    "\n",
    "    index_endpoint = index_endpoint.deploy_index(\n",
    "        index=brute_index, \n",
    "        deployed_index_id=f'{deployed_brute_force_index_name}', #-{TIMESTAMP}'\n",
    "    )\n",
    "\n",
    "    logging.info(f\"index_endpoint.deployed_indexes: {index_endpoint.deployed_indexes}\")\n",
    "\n",
    "    return (\n",
    "      f'{index_endpoint_resource_uri}',\n",
    "      f'{brute_force_index_resource_uri}',\n",
    "      f'{deployed_brute_force_index_name}', #-{TIMESTAMP}',\n",
    "      brute_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576f6ed0-5fbd-4168-bba8-45b4d5899340",
   "metadata": {},
   "source": [
    "# Build & Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb337-7015-419e-aa3b-40f8bcda6db7",
   "metadata": {},
   "source": [
    "### pipe configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc7d180f-1158-4769-a583-1b2ca6969b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_TAG: merlin-train-deploy--v9\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_VERSION = 'v9' # pipeline code\n",
    "PIPELINE_TAG = f'merlin-train-deploy--{PIPELINE_VERSION}'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268a06a-1214-470b-ad73-3203c0010291",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdc191f5-b605-4b53-9f8d-7cf5dc2a9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_pipes import train_merlin, build_custom_image, \\\n",
    "                            create_ann_index, create_brute_force_index, create_ann_index_endpoint_vpc, \\\n",
    "                            create_brute_index_endpoint_vpc, deploy_ann_index, deploy_brute_index\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "    name=f'{PIPELINE_VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version:str,\n",
    "    vpc_network_name: str,\n",
    "    pipe_gcs_path: str,\n",
    "    training_image_uri: str,\n",
    "    serving_image_uri: str,\n",
    "    train_docker_name: str,\n",
    "    serving_docker_name: str,\n",
    "    tb_resource: str,\n",
    "    batch_size: int,\n",
    "    train_epochs: int,\n",
    "    train_dir: str,\n",
    "    valid_dir: str,\n",
    "    workflow_dir: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    "    service_account: str,\n",
    "):\n",
    "    \n",
    "    from kfp.v2.components import importer_node\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    # ========================================================================\n",
    "    # TODO: data processing steps\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build TRAIN Image\n",
    "    # ========================================================================\n",
    "    build_custom_train_image_op = (\n",
    "        build_custom_image.build_custom_image(\n",
    "            project=project,\n",
    "            artifact_gcs_path=f'{pipe_gcs_path}',\n",
    "            app_dir_name='trainer',\n",
    "            docker_name=train_docker_name,\n",
    "            custom_image_uri=training_image_uri,\n",
    "        )\n",
    "        .set_display_name(\"Build Train Image\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Train Merlin Towers\n",
    "    # ========================================================================\n",
    "    \n",
    "    train_merlin_op = (\n",
    "        train_merlin.train_merlin(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            train_image_uri=build_custom_train_image_op.outputs['custom_image_uri'],\n",
    "            tb_resource=tb_resource,\n",
    "            batch_size=batch_size,\n",
    "            train_epochs=train_epochs,\n",
    "            train_dir=train_dir,\n",
    "            valid_dir=valid_dir,\n",
    "            workflow_dir=workflow_dir,\n",
    "            experiment_name=experiment_name,\n",
    "            experiment_run=experiment_run,\n",
    "            service_account=service_account,\n",
    "        )\n",
    "        .set_display_name(\"Train Merlin Towers\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build SERVING Image\n",
    "    # ========================================================================\n",
    "    build_custom_serving_image_op = (\n",
    "        build_custom_image.build_custom_image(\n",
    "            project=project,\n",
    "            artifact_gcs_path=f'{pipe_gcs_path}',\n",
    "            app_dir_name='serving',\n",
    "            docker_name=serving_docker_name,\n",
    "            custom_image_uri=serving_image_uri,\n",
    "        )\n",
    "        .set_display_name(\"Build Serving Image\")\n",
    "        # .after(build_custom_train_image_op)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "       \n",
    "    # ========================================================================\n",
    "    # Import Trained Towers to Pipeline DAG\n",
    "    # ========================================================================\n",
    "    import_query_model_task = (\n",
    "        importer_node.importer(\n",
    "            artifact_uri=train_merlin_op.outputs['merlin_model_gcs_dir'],\n",
    "            artifact_class=artifact_types.UnmanagedContainerModel, #https://cloud.google.com/vertex-ai/docs/reference/rest/v1/ModelContainerSpec\n",
    "            metadata={'containerSpec':{'imageUri': build_custom_serving_image_op.outputs[\"custom_image_uri\"],\n",
    "                                      'command': [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port $AIP_HTTP_PORT\"]},\n",
    "                                      'healthRoute': '/health',\n",
    "                                      'predictRoute': '/predict',\n",
    "                                      'args': ['--gpus all'],\n",
    "                                      'env': [{'name': 'WORKFLOW_URI', 'value': workflow_dir}]\n",
    "                     }\n",
    "        )\n",
    "        .set_display_name(\"Import Query Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "    import_candidate_model_task = (\n",
    "        importer_node.importer(\n",
    "            artifact_uri=train_merlin_op.outputs['candidate_tower_gcs_uri'],\n",
    "            artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "        )\n",
    "        .set_display_name(\"Import Candidate Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    # ========================================================================\n",
    "    # Upload Models to Vertex AI Model Registry\n",
    "    # ========================================================================\n",
    "    \n",
    "    query_model_upload_op = (gcc_aip.ModelUploadOp(project=project, \n",
    "                                                  location=location, \n",
    "                                                  unmanaged_container_model=import_query_model_task.outputs[\"artifact\"],\n",
    "                                                  display_name=f'merlin-query-tower-{version}',\n",
    "                                                 )\n",
    "                             .set_display_name(\"Register Query Tower\")\n",
    "                             .set_caching_options(True)\n",
    "                            )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Deploy Model to Endpoint\n",
    "    # ========================================================================\n",
    "    endpoint_create_op = (\n",
    "        gcc_aip.EndpointCreateOp(\n",
    "            project=project,\n",
    "            display_name=f'query-tower-endpoint-{version}'\n",
    "        )\n",
    "        .after(query_model_upload_op)\n",
    "        .set_display_name(\"Create Query Endpoint\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    model_deploy_op = (\n",
    "        gcc_aip.ModelDeployOp(\n",
    "            endpoint=endpoint_create_op.outputs['endpoint'],\n",
    "            # endpoint=vertex_ai.Endpoint(endpoint_create_op.outputs['resourceUri']),\n",
    "            model=query_model_upload_op.outputs['model'],\n",
    "            deployed_model_display_name=f'deployed-query-tower-{version}',\n",
    "            dedicated_resources_machine_type=\"n1-standard-4\",\n",
    "            dedicated_resources_accelerator_type=\"NVIDIA_TESLA_T4\",\n",
    "            dedicated_resources_accelerator_count=1,\n",
    "            dedicated_resources_max_replica_count=1,\n",
    "            dedicated_resources_min_replica_count=1,\n",
    "            traffic_split={\"0\": 100}\n",
    "        )\n",
    "        .set_display_name(\"Deploy Query Tower\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Create ME indexes\n",
    "    # ========================================================================\n",
    "    \n",
    "    create_ann_index_op = (\n",
    "        create_ann_index.create_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=train_merlin_op.outputs['candidate_embeddings_gcs_uri'],\n",
    "            dimensions=128,\n",
    "            ann_index_display_name=f'ann_index_pipeline_test_{version}',\n",
    "            approximate_neighbors_count=50,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            leaf_node_embedding_count=500,\n",
    "            leaf_nodes_to_search_percent=7, \n",
    "            ann_index_description=\"testing ann index for Merlin deployment\",\n",
    "            # ann_index_labels=ann_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index\")\n",
    "        # .after(XXXX)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    create_brute_force_index_op = (\n",
    "        create_brute_force_index.create_brute_force_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            emb_index_gcs_uri=train_merlin_op.outputs['candidate_embeddings_gcs_uri'],\n",
    "            dimensions=128,\n",
    "            brute_force_index_display_name=f'bf_index_pipeline_test_{version}',\n",
    "            approximate_neighbors_count=50,\n",
    "            distance_measure_type=\"DOT_PRODUCT_DISTANCE\",\n",
    "            brute_force_index_description=\"testing bf index for Merlin deployment\",\n",
    "            # brute_force_index_labels=brute_force_index_labels,\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index\")\n",
    "        # .after(XXX)\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Create ME index endpoints\n",
    "    # ========================================================================\n",
    "    \n",
    "    create_ann_index_endpoint_vpc_op = (\n",
    "        create_ann_index_endpoint_vpc.create_ann_index_endpoint_vpc(\n",
    "            ann_index_artifact=create_ann_index_op.outputs['ann_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            ann_index_endpoint_display_name=f'ann-index=endpoint-{version}',\n",
    "            ann_index_endpoint_description='endpoint for ann index',\n",
    "        )\n",
    "        .set_display_name(\"Create ANN Index Endpoint\")\n",
    "        # .after(XXX)\n",
    "    )\n",
    "        \n",
    "    create_brute_index_endpoint_vpc_op = (\n",
    "        create_brute_index_endpoint_vpc.create_brute_index_endpoint_vpc(\n",
    "            bf_index_artifact=create_brute_force_index_op.outputs['brute_force_index'],\n",
    "            project=project,\n",
    "            project_number=project_number,\n",
    "            version=version,\n",
    "            location=location,\n",
    "            vpc_network_name=vpc_network_name,\n",
    "            brute_index_endpoint_display_name=f'bf-index-endpoint-{version}',\n",
    "            brute_index_endpoint_description='endpoint for brute force index',\n",
    "        )\n",
    "        .set_display_name(\"Create BF Index Endpoint\")\n",
    "        # .after(XXX)\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Deploy Indexes\n",
    "    # ========================================================================\n",
    "\n",
    "    deploy_ann_index_op = (\n",
    "        deploy_ann_index.deploy_ann_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            deployed_ann_index_name=f'deployed_ann_index_{version}',\n",
    "            ann_index_resource_uri=create_ann_index_op.outputs['ann_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_ann_index_endpoint_vpc_op.outputs['ann_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy ANN Index\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "\n",
    "    deploy_brute_index_op = (\n",
    "        deploy_brute_index.deploy_brute_index(\n",
    "            project=project,\n",
    "            location=location,\n",
    "            version=version,\n",
    "            deployed_brute_force_index_name=f'deployed_bf_index_{version}',\n",
    "            brute_force_index_resource_uri=create_brute_force_index_op.outputs['brute_force_index_resource_uri'],\n",
    "            index_endpoint_resource_uri=create_brute_index_endpoint_vpc_op.outputs['brute_index_endpoint_resource_uri'],\n",
    "        )\n",
    "        .set_display_name(\"Deploy BF Index\")\n",
    "        .set_caching_options(True)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0277936-8f7e-44f7-bd31-33a6d40d5ff1",
   "metadata": {},
   "source": [
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4ceb963-5fdc-4dc7-bbda-df85057753ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPE_GCS_DIR: gs://jt-merlin-scaling/pipelines_root/v9\n"
     ]
    }
   ],
   "source": [
    "BUCKET = 'jt-merlin-scaling'\n",
    "BUCKET_URI = f'gs://{BUCKET}'\n",
    "PIPELINE_ROOT = 'pipelines_root'\n",
    "PIPE_GCS_DIR = f'{BUCKET_URI}/{PIPELINE_ROOT}/{PIPELINE_VERSION}'\n",
    "print(f\"PIPE_GCS_DIR: {PIPE_GCS_DIR}\")\n",
    "\n",
    "SERVING_DOCKERNAME='merlin-retriever'\n",
    "TRAIN_DOCKERNAME='merlintf-22_09_v2'\n",
    "SERVING_SUB_DIR='serving'\n",
    "TRAIN_SUB_DIR='trainer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f05b2a36-97f1-4a14-b0d9-67b15f9aac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='custom_container_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d742c97c-07ea-425f-92d3-e47c533c4a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://custom_container_pipeline_spec.json [Content-Type=application/json]...\n",
      "/ [1 files][ 87.9 KiB/ 87.9 KiB]                                                \n",
      "Operation completed over 1 objects/87.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp custom_container_pipeline_spec.json $PIPE_GCS_DIR/pipeline_spec.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b1966bf-ec3b-4c14-aae2-8d7a580d9f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./src/Dockerfile.merlin-retriever [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  270.0 B/  270.0 B]                                                \n",
      "Operation completed over 1 objects/270.0 B.                                      \n",
      "Copying file://./src/Dockerfile.merlintf-22_09_v2 [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  353.0 B/  353.0 B]                                                \n",
      "Operation completed over 1 objects/353.0 B.                                      \n",
      "Copying file://./src/serving/requirements.txt [Content-Type=text/plain]...\n",
      "Copying file://./src/serving/instances.json [Content-Type=application/json]...  \n",
      "Copying file://./src/serving/app/predictor.py [Content-Type=text/x-python]...   \n",
      "Copying file://./src/serving/app/__init__.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/serving/app/prestart.sh [Content-Type=text/x-sh]...        \n",
      "Copying file://./src/serving/app/main.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/serving/app/.ipynb_checkpoints/predictor-checkpoint.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/serving/app/.ipynb_checkpoints/main-checkpoint.py [Content-Type=text/x-python]...\n",
      "/ [8/8 files][ 15.2 KiB/ 15.2 KiB] 100% Done                                    \n",
      "Operation completed over 8 objects/15.2 KiB.                                     \n",
      "Copying file://./src/trainer/two_tower_model.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/trainer/__init__.py [Content-Type=text/x-python]...        \n",
      "Copying file://./src/trainer/interactive_train.py [Content-Type=text/x-python]...\n",
      "Copying file://./src/trainer/train_task.py [Content-Type=text/x-python]...      \n",
      "Copying file://./src/trainer/.ipynb_checkpoints/train_task-checkpoint.py [Content-Type=text/x-python]...\n",
      "/ [5/5 files][ 39.1 KiB/ 39.1 KiB] 100% Done                                    \n",
      "Operation completed over 5 objects/39.1 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp ./$REPO_DOCKER_PATH_PREFIX/Dockerfile.$SERVING_DOCKERNAME $PIPE_GCS_DIR/\n",
    "!gsutil cp ./$REPO_DOCKER_PATH_PREFIX/Dockerfile.$TRAIN_DOCKERNAME $PIPE_GCS_DIR/\n",
    "\n",
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$SERVING_SUB_DIR $PIPE_GCS_DIR/\n",
    "!gsutil -m cp -r ./$REPO_DOCKER_PATH_PREFIX/$TRAIN_SUB_DIR $PIPE_GCS_DIR/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3a0bcea9-de27-44b6-bc89-23c33f492c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: save and load pipeline definition\n",
    "PIPELINES = {}\n",
    "def save_pipelines():\n",
    "    with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "        json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17686d4c-cb8a-43ef-801f-60c842f494a7",
   "metadata": {},
   "source": [
    "## Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af4b575-ed3b-4535-8fc4-4caae701ed22",
   "metadata": {},
   "source": [
    "## pipe args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3aecbc56-9e69-4965-bf0f-854acb5079f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT_NAME: pipes-2tower-merlin-tf-v9\n"
     ]
    }
   ],
   "source": [
    "EXPERIMENT_PREFIX = 'pipes'\n",
    "MODEL_NAME = '2tower'\n",
    "FRAMEWORK = 'merlin-tf'\n",
    "\n",
    "EXPERIMENT_NAME = f'{EXPERIMENT_PREFIX}-{MODEL_NAME}-{FRAMEWORK}-{PIPELINE_VERSION}'\n",
    "EXPERIMENT_RUN = f'run-v1'\n",
    "\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb8b2a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN_DOCKERFILE_NAME: Dockerfile.merlintf-22_09_v2\n",
      "SERVE_DOCKERFILE_NAME: Dockerfile.merlin-retriever\n",
      "\n",
      "EXPERIMENT_NAME: pipes-2tower-merlin-tf-v9\n",
      "EXPERIMENT_RUN: run-v1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VPC_NETWORK_NAME = 'ucaip-haystack-vpc-network'\n",
    "\n",
    "# TRAIN JOB CONFIG\n",
    "TENSORBOARD_RESOURCE = 'projects/934903580331/locations/us-central1/tensorboards/70659015247396864'\n",
    "BATCH_SIZE = 4096*4\n",
    "EPOCHS = 100\n",
    "\n",
    "# IMAGES\n",
    "TRAIN_IMAGE_URI = f'gcr.io/{PROJECT_ID}/merlin-tf-2tower-training-jtv1-22_09_v2'\n",
    "# SERVING_IMAGE_URI = f'gcr.io/{PROJECT_ID}/merlin-triton-serving-v9'\n",
    "SERVING_IMAGE_URI = f\"gcr.io/hybrid-vertex/merlin-vertex-serv-v11\"\n",
    "\n",
    "# DOCKERFILES\n",
    "TRAIN_DOCKERFILE_NAME = f'Dockerfile.{TRAIN_DOCKERNAME}'\n",
    "SERVE_DOCKERFILE_NAME = f'Dockerfile.{SERVING_DOCKERNAME}'\n",
    "\n",
    "# data and schema from nvtabular pipes\n",
    "DATA_DIR = 'gs://jt-merlin-scaling/nvt-last5-v1full/nvt-processed'\n",
    "TRAIN_DIR = f'{DATA_DIR}/train'\n",
    "VALID_DIR = f'{DATA_DIR}/valid'\n",
    "WORKFLOW_DIR = 'gs://jt-merlin-scaling/nvt-last5-v1full/nvt-analyzed'\n",
    "\n",
    "print(f\"TRAIN_DOCKERFILE_NAME: {TRAIN_DOCKERFILE_NAME}\")\n",
    "print(f\"SERVE_DOCKERFILE_NAME: {SERVE_DOCKERFILE_NAME}\\n\")\n",
    "print(f\"EXPERIMENT_NAME: {EXPERIMENT_NAME}\")\n",
    "print(f\"EXPERIMENT_RUN: {EXPERIMENT_RUN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e428e9b8-4a1c-4dcb-b941-a92d03af9ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/v9-merlin-train-deploy--v9-20221116183331?project=hybrid-vertex\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overwrite = True\n",
    "# overwrite = False\n",
    "\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "  project_id=PROJECT_ID,\n",
    "  region=LOCATION,\n",
    ")\n",
    "\n",
    "if not PIPELINES.get('train') or overwrite:\n",
    "    response = pipeline_client.create_run_from_job_spec(\n",
    "        job_spec_path='custom_container_pipeline_spec.json',\n",
    "        network=f'projects/{PROJECT_NUM}/global/networks/{VPC_NETWORK_NAME}', # set to same VPC as index\n",
    "        service_account=VERTEX_SA,\n",
    "        parameter_values={\n",
    "            'project': PROJECT_ID,\n",
    "            'project_number': PROJECT_NUM,\n",
    "            'location': LOCATION,\n",
    "            'vpc_network_name': VPC_NETWORK_NAME,\n",
    "            'version': PIPELINE_VERSION,\n",
    "            'pipe_gcs_path': PIPE_GCS_DIR,\n",
    "            'training_image_uri': TRAIN_IMAGE_URI,\n",
    "            'serving_image_uri': SERVING_IMAGE_URI,\n",
    "            'train_docker_name': TRAIN_DOCKERFILE_NAME,\n",
    "            'serving_docker_name': SERVE_DOCKERFILE_NAME,\n",
    "            'tb_resource': TENSORBOARD_RESOURCE,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'train_epochs': EPOCHS,\n",
    "            'train_dir': TRAIN_DIR,\n",
    "            'valid_dir': VALID_DIR,\n",
    "            'workflow_dir': WORKFLOW_DIR,\n",
    "            'experiment_name': EXPERIMENT_NAME,\n",
    "            'experiment_run': EXPERIMENT_RUN,\n",
    "            'service_account': VERTEX_SA,\n",
    "        },\n",
    "        pipeline_root=f'{PIPE_GCS_DIR}',\n",
    "    )\n",
    "    PIPELINES['train'] = response['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e8da0d3-7f41-4267-8ed2-4332bbb4dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = vertex_ai.Endpoint('projects/934903580331/locations/us-central1/endpoints/8515115024753098752')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f6c7f215-6114-47a3-ad28-b9e0e6fbe397",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_INSTANCE = {'collaborative': 'false',\n",
    "                 'album_name_pl': [\"There's Really A Wolf\", 'Late Nights: The Album',\n",
    "                       'American Teen', 'Crazy In Love', 'Pony'], \n",
    "                 'artist_genres_pl': [\"'hawaiian hip hop', 'rap'\",\n",
    "                       \"'chicago rap', 'dance pop', 'pop', 'pop rap', 'r&b', 'southern hip hop', 'trap', 'urban contemporary'\",\n",
    "                       \"'pop', 'pop r&b'\", \"'dance pop', 'pop', 'r&b'\",\n",
    "                       \"'chill r&b', 'pop', 'pop r&b', 'r&b', 'urban contemporary'\"], \n",
    "                 'artist_name_pl': ['Russ', 'Jeremih', 'Khalid', 'Beyonc\\xc3\\xa9',\n",
    "                       'William Singe'], \n",
    "                 'artist_pop_can': 82.0, \n",
    "                 'description_pl': '', \n",
    "                 'duration_ms_songs_pl': [237506.0, 217200.0, 219080.0, 226400.0, 121739.0], \n",
    "                 'n_songs_pl': 8.0, \n",
    "                 'name': 'Lit Tunes ', \n",
    "                 'num_albums_pl': 8.0, \n",
    "                 'num_artists_pl': 8.0, \n",
    "                 'track_name_pl': ['Losin Control', 'Paradise', 'Location',\n",
    "                       'Crazy In Love - Remix', 'Pony'], \n",
    "                 'track_pop_pl': [79.0, 58.0, 83.0, 71.0, 57.0],\n",
    "                 'duration_ms_seed_pl': 51023.1,\n",
    "                 'pid': 1,\n",
    "                 'track_uri_pl': ['spotify:track:4cxMGhkinTocPSVVKWIw0d',\n",
    "                       'spotify:track:1wNEBPo3nsbGCZRryI832I',\n",
    "                       'spotify:track:152lZdxL1OR0ZMW6KquMif',\n",
    "                       'spotify:track:2f4IuijXLxYOeBncS60GUD',\n",
    "                       'spotify:track:4Lj8paMFwyKTGfILLELVxt']\n",
    "                     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fbb385c9-4326-4503-a1f8-f87a511e3396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.4707373678684235, 0.8641103506088257, 0.0, 0.0, 1.018792748451233, 0.09464387595653534, 0.5575847029685974, 0.7692021131515503, 2.001033544540405, 3.422805786132812, 0.5328009128570557, 0.7689167261123657, 0.0, 1.141236186027527, 1.746711254119873, 0.6004542112350464, 0.4158501327037811, 0.0, 0.4438650012016296, 1.380507230758667, 0.1513499319553375, 0.183375671505928, 0.6494946479797363, 0.922292172908783, 0.0, 2.127224206924438, 0.0, 2.229432582855225, 0.3340595066547394, 0.4078029990196228, 0.1877781450748444, 1.94303035736084, 1.281924962997437, 0.0, 0.2793006598949432, 0.7752009034156799, 0.4282656610012054, 0.2450124770402908, 0.7832157015800476, 1.133267641067505, 0.9308550357818604, 0.0, 0.0, 0.0, 0.2122098505496979, 0.0, 0.953433632850647, 0.5627561807632446, 1.377547264099121, 0.0, 0.0, 0.0009004436433315277, 0.0, 0.4524123966693878, 2.027101755142212, 0.0, 0.0, 0.0, 4.159066200256348, 0.04837673902511597, 0.1159927695989609, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2072594165802, 0.6499670743942261, 0.0, 0.971100926399231, 0.6291776299476624, 1.977836608886719, 0.0, 0.5743507146835327, 0.0, 0.0, 0.6910903453826904, 1.5559983253479, 1.131049275398254, 1.242529511451721, 0.102000504732132, 0.0, 0.0, 0.0, 0.7631422281265259, 0.0, 0.0, 0.0, 4.146707534790039, 0.0, 0.0, 0.0, 0.8886046409606934, 0.1787907332181931, 0.07489252835512161, 0.0, 0.0, 4.921977519989014, 0.6450470089912415, 0.0, 1.409379482269287, 1.633713006973267, 0.0, 0.293467253446579, 1.88668167591095, 0.0, 0.1390771567821503, 2.997836589813232, 0.6496191024780273, 5.591050624847412, 0.6520617604255676, 0.0, 1.202766180038452, 0.193142756819725, 0.0, 0.0, 0.3888993263244629, 2.600800275802612, 1.660108327865601, 0.0, 0.0, 0.0, 1.870926737785339, 0.0, 0.568323016166687, 1.645790576934814, 2.226940393447876, 0.0]], deployed_model_id='5432735331352838144', model_version_id='1', model_resource_name='projects/934903580331/locations/us-central1/models/7891287311525085184', explanations=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.predict([TEST_INSTANCE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf01a5-8c6a-493f-811f-b6e3122eaab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m99",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m99"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
