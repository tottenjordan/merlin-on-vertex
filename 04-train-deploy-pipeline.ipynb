{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20fb7941-cf7c-4ff4-aab3-86f68879e618",
   "metadata": {},
   "source": [
    "# Train and Deploy Merlin models with Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a796242f-4f0e-454e-aba0-5eb6ba87f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kfp\n",
    "# !pip install google-cloud-pipeline-components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5337f359-59e6-4bff-a1cd-3504e500c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "# ! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\"\n",
    "# ! python3 -c \"import google.cloud.aiplatform; print('aiplatform SDK version: {}'.format(google.cloud.aiplatform.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e184436e-2656-4d6e-bb31-bc2d1147b0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'hybrid-vertex' \n",
    "LOCATION = 'us-central1' \n",
    "VERTEX_SA = '934903580331-compute@developer.gserviceaccount.com'\n",
    "\n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b42c134e-2fef-49e9-aaa2-c33906673e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "import pandas as pd\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud import storage\n",
    "\n",
    "# Pipelines\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "\n",
    "# Kubeflow SDK\n",
    "# TODO: fix these\n",
    "from kfp.v2 import dsl\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component)\n",
    "\n",
    "storage_client = storage.Client(project=PROJECT_ID)\n",
    "\n",
    "vertex_ai.init(project=PROJECT_ID,location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6886f62a-b44c-48f4-9647-fe1ad60fb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "VERSION = 'v1'  # component code\n",
    "RUN = f'pipe-run-{TIMESTAMP}'\n",
    "PIPELINE_ROOT = 'pipelines_root'\n",
    "BUCKET = 'jt-scaling-merlin'\n",
    "BUCKET_URI = f'gs://{BUCKET}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abff2a0-3022-4d0e-9423-4cc067da146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_DOCKER_PATH_PREFIX = 'src'\n",
    "PIPELINES_SUB_DIR = 'train_pipes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e50ebd1-4f72-41b1-89e1-3be35d62bdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}\n",
    "! mkdir {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f2d38e-459a-4ccd-9ae8-928a86ed2474",
   "metadata": {},
   "source": [
    "# Pipeline Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd5c12ae-40ef-485a-aa02-c0fc116ca33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/jt-merlin/merlin-on-vertex'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac98a7ed-ec46-43b6-aad0-18e4edc040fb",
   "metadata": {},
   "source": [
    "## Build Custom Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c8639e-d29a-4441-a315-1ce0b1c33ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/build_custom_image.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"gcr.io/google.com/cloudsdktool/cloud-sdk:latest\",\n",
    "    packages_to_install=[\n",
    "        \"google-cloud-build\"\n",
    "    ],\n",
    ")\n",
    "def build_custom_image(\n",
    "    project: str,\n",
    "    artifact_gcs_path: str,\n",
    "    docker_name: str,\n",
    "    app_dir_name: str,\n",
    "    custom_image_uri: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('custom_image_uri', str),\n",
    "]):\n",
    "    # TODO: make output Artifact for image_uri\n",
    "    \"\"\"\n",
    "    custom pipeline component to build custom image using\n",
    "    Cloud Build, the training/serving application code, and dependencies\n",
    "    defined in the Dockerfile\n",
    "    \"\"\"\n",
    "    \n",
    "    import logging\n",
    "    import os\n",
    "\n",
    "    from google.cloud.devtools import cloudbuild_v1 as cloudbuild\n",
    "    from google.protobuf.duration_pb2 import Duration\n",
    "\n",
    "    # initialize client for cloud build\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    build_client = cloudbuild.services.cloud_build.CloudBuildClient()\n",
    "    \n",
    "    # parse step inputs to get path to Dockerfile and training application code\n",
    "    _gcs_dockerfile_path = os.path.join(artifact_gcs_path, f\"{docker_name}\") # Dockerfile.XXXXX\n",
    "    _gcs_script_dir_path = os.path.join(artifact_gcs_path, f\"{app_dir_name}/\") # \"trainer/\"\n",
    "    \n",
    "    logging.info(f\"_gcs_dockerfile_path: {_gcs_dockerfile_path}\")\n",
    "    logging.info(f\"_gcs_script_dir_path: {_gcs_script_dir_path}\")\n",
    "    \n",
    "    # define build steps to pull the training code and Dockerfile\n",
    "    # and build/push the custom training container image\n",
    "    build = cloudbuild.Build()\n",
    "    build.steps = [\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\"cp\", \"-r\", _gcs_script_dir_path, \".\"],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/gsutil\",\n",
    "            \"args\": [\"cp\", _gcs_dockerfile_path, \"Dockerfile\"],\n",
    "        },\n",
    "        # enabling Kaniko cache in a Docker build that caches intermediate\n",
    "        # layers and pushes image automatically to Container Registry\n",
    "        # https://cloud.google.com/build/docs/kaniko-cache\n",
    "        # {\n",
    "        #     \"name\": \"gcr.io/kaniko-project/executor:latest\",\n",
    "        #     # \"name\": \"gcr.io/kaniko-project/executor:v1.8.0\",        # TODO; downgraded to avoid error in build\n",
    "        #     # \"args\": [f\"--destination={training_image_uri}\", \"--cache=true\"],\n",
    "        #     \"args\": [f\"--destination={training_image_uri}\", \"--cache=false\"],\n",
    "        # },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "            \"args\": ['build','-t', f'{custom_image_uri}', '.'],\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"gcr.io/cloud-builders/docker\",\n",
    "            \"args\": ['push', f'{custom_image_uri}'], \n",
    "        },\n",
    "    ]\n",
    "    # override default timeout of 10min\n",
    "    timeout = Duration()\n",
    "    timeout.seconds = 7200\n",
    "    build.timeout = timeout\n",
    "\n",
    "    # create build\n",
    "    operation = build_client.create_build(project_id=project, build=build)\n",
    "    logging.info(\"IN PROGRESS:\")\n",
    "    logging.info(operation.metadata)\n",
    "\n",
    "    # get build status\n",
    "    result = operation.result()\n",
    "    logging.info(\"RESULT:\", result.status)\n",
    "\n",
    "    # return step outputs\n",
    "    return (\n",
    "        custom_image_uri,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad9cd2-58a1-4b75-a608-cbc1888ad921",
   "metadata": {},
   "source": [
    "## Train Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d882a90-2445-463e-9005-f83a87f78682",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {REPO_DOCKER_PATH_PREFIX}/{PIPELINES_SUB_DIR}/train_merlin.py\n",
    "\n",
    "import kfp\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional, List\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, component, Metrics)\n",
    "\n",
    "@kfp.v2.dsl.component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\n",
    "        'google-cloud-aiplatform==1.18.1',\n",
    "        # 'google-cloud-storage',\n",
    "    ],\n",
    ")\n",
    "def train_merlin(\n",
    "    project: str,\n",
    "    location: str,\n",
    "    version: str,\n",
    "    train_image_uri: str,     # TODO: Artifact\n",
    "    tb_resource: str,\n",
    "    batch_size: str, \n",
    "    train_epochs: int,\n",
    "    train_dir: str,\n",
    "    valid_dir: str,\n",
    "    workflow_dir: str,\n",
    "    experiment_name: str,\n",
    "    experiment_run: str,\n",
    "    service_account: str,\n",
    ") -> NamedTuple('Outputs', [\n",
    "    ('merlin_model_gcs_dir', str),\n",
    "    ('query_tower_gcs_dir', str),\n",
    "    ('candidate_tower_gcs_uri', str),\n",
    "    ('candidate_embeddings_gcs_uri', str),\n",
    "]):\n",
    "    \n",
    "    import logging\n",
    "    from google.cloud import aiplatform as vertex_ai\n",
    "    from datetime import datetime\n",
    "    import time\n",
    "\n",
    "    vertex_ai.init(\n",
    "        project=project,\n",
    "        location=location,\n",
    "    )\n",
    "    \n",
    "    TIMESTAMP = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    # ====================================================\n",
    "    # Helper function for workerpool specs\n",
    "    # ====================================================\n",
    "    def prepare_worker_pool_specs(\n",
    "        image_uri,\n",
    "        # args,\n",
    "        cmd,\n",
    "        replica_count=1,\n",
    "        machine_type=\"n1-standard-16\",\n",
    "        accelerator_count=1,\n",
    "        accelerator_type=\"ACCELERATOR_TYPE_UNSPECIFIED\",\n",
    "        reduction_server_count=0,\n",
    "        reduction_server_machine_type=\"n1-highcpu-16\",\n",
    "        reduction_server_image_uri=\"us-docker.pkg.dev/vertex-ai-restricted/training/reductionserver:latest\",\n",
    "    ):\n",
    "\n",
    "        if accelerator_count > 0:\n",
    "            machine_spec = {\n",
    "                \"machine_type\": machine_type,\n",
    "                \"accelerator_type\": accelerator_type,\n",
    "                \"accelerator_count\": accelerator_count,\n",
    "            }\n",
    "        else:\n",
    "            machine_spec = {\"machine_type\": machine_type}\n",
    "\n",
    "        container_spec = {\n",
    "            \"image_uri\": image_uri,\n",
    "            # \"args\": args,\n",
    "            \"command\": cmd,\n",
    "        }\n",
    "\n",
    "        chief_spec = {\n",
    "            \"replica_count\": 1,\n",
    "            \"machine_spec\": machine_spec,\n",
    "            \"container_spec\": container_spec,\n",
    "        }\n",
    "\n",
    "        worker_pool_specs = [chief_spec]\n",
    "        if replica_count > 1:\n",
    "            workers_spec = {\n",
    "                \"replica_count\": replica_count - 1,\n",
    "                \"machine_spec\": machine_spec,\n",
    "                \"container_spec\": container_spec,\n",
    "            }\n",
    "            worker_pool_specs.append(workers_spec)\n",
    "        if reduction_server_count > 1:\n",
    "            workers_spec = {\n",
    "                \"replica_count\": reduction_server_count,\n",
    "                \"machine_spec\": {\n",
    "                    \"machine_type\": reduction_server_machine_type,\n",
    "                },\n",
    "                \"container_spec\": {\"image_uri\": reduction_server_image_uri},\n",
    "            }\n",
    "            worker_pool_specs.append(workers_spec)\n",
    "\n",
    "        return worker_pool_specs\n",
    "    \n",
    "    # ====================================================\n",
    "    # Define device strategy\n",
    "    # ====================================================\n",
    "    # TODO: parameterize\n",
    "    \n",
    "    WORKER_MACHINE_TYPE = 'a2-highgpu-1g'\n",
    "    REPLICA_COUNT = 1\n",
    "    ACCELERATOR_TYPE = 'NVIDIA_TESLA_A100'\n",
    "    PER_MACHINE_ACCELERATOR_COUNT = 1\n",
    "    REDUCTION_SERVER_COUNT = 0                                                      \n",
    "    REDUCTION_SERVER_MACHINE_TYPE = \"n1-highcpu-16\"\n",
    "    DISTRIBUTE_STRATEGY = 'single'\n",
    "    \n",
    "    # ====================================================\n",
    "    # # DEFINE ARGS\n",
    "    # ====================================================\n",
    "    # TODO: parameterize\n",
    "    \n",
    "    BATCH_SIZE = 4096*4      # TODO: `batch_size * 4 ? jw\n",
    "    LEARNING_RATE = 0.001\n",
    "    LAYERS = \"[512, 256, 128]\"\n",
    "    \n",
    "    OUTPUT_BUCKET = 'jt-merlin-scaling'\n",
    "    \n",
    "    EXPERIMENT_RUN = f'{experiment_run}-{TIMESTAMP}'\n",
    "    \n",
    "    WORKER_CMD = [\n",
    "        'sh',\n",
    "        '-euc',\n",
    "        f'''pip freeze && python -m trainer.train_task --tb_name={tb_resource} --per_gpu_batch_size={batch_size} \\\n",
    "        --train_output_bucket={OUTPUT_BUCKET} --train_dir={train_dir} --valid_dir={valid_dir} --workflow_dir={workflow_dir} \\\n",
    "        --num_epochs={train_epochs} --learning_rate={LEARNING_RATE} --distribute={DISTRIBUTE_STRATEGY} \\\n",
    "        --experiment_name={experiment_name} --experiment_run={EXPERIMENT_RUN} --project={project} --location={location}'''\n",
    "    ]\n",
    "    \n",
    "    WORKER_POOL_SPECS = prepare_worker_pool_specs(\n",
    "        image_uri=train_image_uri,\n",
    "        # args=WORKER_ARGS,\n",
    "        cmd=WORKER_CMD,\n",
    "        replica_count=REPLICA_COUNT,\n",
    "        machine_type=WORKER_MACHINE_TYPE,\n",
    "        accelerator_count=PER_MACHINE_ACCELERATOR_COUNT,\n",
    "        accelerator_type=ACCELERATOR_TYPE,\n",
    "        reduction_server_count=REDUCTION_SERVER_COUNT,\n",
    "        reduction_server_machine_type=REDUCTION_SERVER_MACHINE_TYPE,\n",
    "    )\n",
    "    # ==============================================================================\n",
    "    # Submit Train Job \n",
    "    # ==============================================================================\n",
    "    STAGING_BUCKET = f'gs://{OUTPUT_BUCKET}/{experiment_name}'\n",
    "    JOB_NAME = f'train-merlin-retrieval-{version}'\n",
    "    gpu_type = ACCELERATOR_TYPE.lower() # lowercase for labels\n",
    "\n",
    "    job = vertex_ai.CustomJob(\n",
    "        display_name=JOB_NAME,\n",
    "        worker_pool_specs=WORKER_POOL_SPECS,\n",
    "        staging_bucket=STAGING_BUCKET,\n",
    "        labels={\n",
    "            'gpu': f'{gpu_type}',\n",
    "            'gpu_per_replica' : f'{PER_MACHINE_ACCELERATOR_COUNT}',\n",
    "            'replica_cnt' : f'{REPLICA_COUNT}',\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    job.run(\n",
    "        sync=True, \n",
    "        service_account=service_account,\n",
    "        # tensorboard=EXPERIMENT_TB,\n",
    "        restart_job_on_worker_restart=False,\n",
    "        enable_web_access=True,\n",
    "    )\n",
    "    \n",
    "    # uris set during train script\n",
    "    WORKING_DIR_GCS_URI = f'gs://{OUTPUT_BUCKET}/{experiment_name}/{EXPERIMENT_RUN}'\n",
    "    MODEL_DIR = f\"{WORKING_DIR_GCS_URI}/model-dir\"\n",
    "    QUERY_TOWER_PATH = f\"{MODEL_DIR}/query-tower\"\n",
    "    CANDIDATE_TOWER_PATH = f\"{MODEL_DIR}/candidate-tower\"\n",
    "    EMBEDDINGS_PATH = f\"{MODEL_DIR}/candidate-embeddings\"\n",
    "    \n",
    "    logging.info(f'WORKING_DIR_GCS_URI: {WORKING_DIR_GCS_URI}')\n",
    "    logging.info(f'MODEL_DIR: {MODEL_DIR}')\n",
    "    logging.info(f'QUERY_TOWER_PATH: {QUERY_TOWER_PATH}')\n",
    "    logging.info(f'CANDIDATE_TOWER_PATH: {CANDIDATE_TOWER_PATH}')\n",
    "    logging.info(f'EMBEDDINGS_PATH: {EMBEDDINGS_PATH}')\n",
    "    \n",
    "    return (\n",
    "        f'{MODEL_DIR}',\n",
    "        f'{QUERY_TOWER_PATH}',\n",
    "        f'{CANDIDATE_TOWER_PATH}',\n",
    "        f'{EMBEDDINGS_PATH}',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22943c66-4fb9-41c9-8aff-3ed3d49ab1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43badfc0-d7c0-4e2e-b60d-9d5a85d7c89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "576f6ed0-5fbd-4168-bba8-45b4d5899340",
   "metadata": {},
   "source": [
    "# Build & Compile Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6cb337-7015-419e-aa3b-40f8bcda6db7",
   "metadata": {},
   "source": [
    "### pipe configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d180f-1158-4769-a583-1b2ca6969b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_VERSION = 'v1' # pipeline code\n",
    "PIPELINE_TAG = f'retail-visual-similarity-{PIPELINE_VERSION}'\n",
    "print(\"PIPELINE_TAG:\", PIPELINE_TAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268a06a-1214-470b-ad73-3203c0010291",
   "metadata": {},
   "source": [
    "## Build pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc191f5-b605-4b53-9f8d-7cf5dc2a9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train_pipes import XXXX\n",
    "\n",
    "@kfp.v2.dsl.pipeline(\n",
    "    name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "    project: str,\n",
    "    project_number: str,\n",
    "    location: str,\n",
    "    version:str,\n",
    "):\n",
    "    \n",
    "    from kfp.v2.components import importer_node\n",
    "    from google_cloud_pipeline_components.types import artifact_types\n",
    "    # ========================================================================\n",
    "    # TODO: data processing steps\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build TRAIN Image\n",
    "    # ========================================================================\n",
    "    build_custom_train_image_op = (\n",
    "        build_custom_image(\n",
    "            project=PROJECT_ID,\n",
    "            gcs_train_script_path=gcs_train_script_path,\n",
    "            training_image_uri=TRAIN_IMAGE,\n",
    "        )\n",
    "        .set_display_name(\"Build custom train image\")\n",
    "        .set_caching_options(True)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Train Merlin Towers\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Build SERVING Image\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Import Trained Towers to Pipeline DAG\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Upload Models to Vertex AI Model Registry\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Deploy Model to Endpoint\n",
    "    # ========================================================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ========================================================================\n",
    "    # Vertex Matching Engine Steps\n",
    "    # ========================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbf5613-c61d-4446-890c-6129b5958916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_IMAGE_ID = json.dumps(str(build_custom_train_image_op.outputs['training_image_uri']).replace(\"'\",'\"'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab2051-453b-442f-9310-f6f9e6370057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   import_unmanaged_query_model_task = (\n",
    "#       importer_node.importer(\n",
    "#           artifact_uri=QUERY_MODEL_DIR,\n",
    "#           artifact_class=artifact_types.UnmanagedContainerModel,\n",
    "#           metadata={\n",
    "#               'containerSpec': {\n",
    "#                   'imageUri': 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest',\n",
    "#               },\n",
    "#           },\n",
    "#       )\n",
    "#       .set_display_name(\"Import Query Tower\")\n",
    "#       .after(run_train_task_op)\n",
    "#   )\n",
    "\n",
    "#   query_model_upload_op = (\n",
    "#       gcc_aip.ModelUploadOp(\n",
    "#           project=project,\n",
    "#           location=location,\n",
    "#           display_name=QUERY_MODEL_DISPLAY_NAME,\n",
    "#           unmanaged_container_model=import_unmanaged_query_model_task.outputs[\"artifact\"],\n",
    "#           labels={\"version\": VERSION, \"tower\": \"query\", \"model_endpoint_name\": MODEL_ENDPOINT_NAME}, # replace with cfg.MODEL_ENDPOINT_NAME '2tower-recsys-pipe-v4-model-endpoint'\n",
    "#       )\n",
    "#       # .after(import_unmanaged_query_model_task)\n",
    "#       .set_display_name(\"Upload Query Tower to Vertex\")\n",
    "#   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0277936-8f7e-44f7-bd31-33a6d40d5ff1",
   "metadata": {},
   "source": [
    "## Compile Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1966bf-ec3b-4c14-aae2-8d7a580d9f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0bcea9-de27-44b6-bc89-23c33f492c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17686d4c-cb8a-43ef-801f-60c842f494a7",
   "metadata": {},
   "source": [
    "## Submit Pipeline Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428e9b8-4a1c-4dcb-b941-a92d03af9ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
